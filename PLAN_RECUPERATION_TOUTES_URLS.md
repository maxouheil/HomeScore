# Plan pour rÃ©cupÃ©rer toutes les URLs d'appartements depuis l'alerte Jinka

## ğŸ¯ Objectif
RÃ©cupÃ©rer **toutes** les URLs d'appartements de l'alerte Jinka (pas seulement les 17 premiers visibles).

## ğŸ“‹ StratÃ©gies possibles

### Option 1: Scroll infini (Lazy Loading) â­ RECOMMANDÃ‰E
Le dashboard Jinka charge probablement les appartements au fur et Ã  mesure du scroll (lazy loading).

**Ã‰tapes:**
1. Se connecter Ã  Jinka
2. Aller au dashboard de l'alerte
3. Scroller progressivement jusqu'en bas de la page
4. Attendre le chargement des nouveaux appartements
5. RÃ©pÃ©ter jusqu'Ã  ce qu'il n'y ait plus de nouveaux appartements
6. Extraire toutes les URLs une fois tout chargÃ©

**Avantages:**
- Simple Ã  implÃ©menter
- Fonctionne avec la plupart des sites modernes
- Pas besoin de gÃ©rer la pagination

**Code Ã  implÃ©menter:**
```python
async def scroll_to_load_all_apartments(page):
    """Scroll progressivement pour charger tous les appartements"""
    last_count = 0
    stable_count = 0
    max_stable = 3  # Si le nombre ne change pas 3 fois, on arrÃªte
    
    while stable_count < max_stable:
        # Scroller progressivement
        await page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
        await asyncio.sleep(2)  # Attendre le chargement
        
        # Compter les appartements actuels
        current_count = await page.locator('a[href*="ad="]').count()
        
        if current_count == last_count:
            stable_count += 1
        else:
            stable_count = 0
            print(f"   ğŸ“Š {current_count} appartements chargÃ©s...")
        
        last_count = current_count
        
        # SÃ©curitÃ©: limite max (ex: 500 appartements)
        if current_count > 500:
            break
    
    return last_count
```

---

### Option 2: Pagination par paramÃ¨tre URL
Si Jinka utilise des pages avec paramÃ¨tre `?page=2`, `?page=3`, etc.

**Ã‰tapes:**
1. Essayer d'accÃ©der Ã  `dashboard_url?page=1`, `?page=2`, etc.
2. Pour chaque page, extraire les URLs
3. ArrÃªter quand une page est vide

**Code Ã  implÃ©menter:**
```python
async def extract_urls_from_all_pages(scraper, dashboard_url):
    """Extrait les URLs de toutes les pages"""
    all_urls = []
    page = 1
    
    while True:
        # Construire l'URL de la page
        if '?' in dashboard_url:
            page_url = f"{dashboard_url}&page={page}"
        else:
            page_url = f"{dashboard_url}?page={page}"
        
        await scraper.page.goto(page_url)
        await scraper.page.wait_for_timeout(3000)
        
        # Extraire les URLs de cette page
        page_urls = await extract_urls_from_page(scraper.page)
        
        if not page_urls:
            break  # Plus d'appartements
        
        all_urls.extend(page_urls)
        print(f"   Page {page}: {len(page_urls)} appartements")
        
        page += 1
        
        # SÃ©curitÃ©: limite max de pages
        if page > 50:
            break
    
    return all_urls
```

---

### Option 3: Bouton "Voir plus" / "Charger plus"
Si Jinka a un bouton pour charger plus d'appartements.

**Ã‰tapes:**
1. Chercher le bouton "Voir plus", "Charger plus", "Load more", etc.
2. Cliquer dessus jusqu'Ã  ce qu'il disparaisse
3. Extraire toutes les URLs

**Code Ã  implÃ©menter:**
```python
async def click_load_more_until_done(page):
    """Clique sur 'Voir plus' jusqu'Ã  ce qu'il n'y en ait plus"""
    max_clicks = 100
    click_count = 0
    
    while click_count < max_clicks:
        # Chercher le bouton
        load_more_selectors = [
            'button:has-text("Voir plus")',
            'button:has-text("Charger plus")',
            'button:has-text("Load more")',
            'a:has-text("Voir plus")',
            '[data-testid="load-more"]',
            '.load-more',
            'button[class*="load"]'
        ]
        
        button_found = False
        for selector in load_more_selectors:
            button = page.locator(selector).first
            if await button.count() > 0:
                # VÃ©rifier si visible
                is_visible = await button.is_visible()
                if is_visible:
                    await button.click()
                    await asyncio.sleep(2)
                    click_count += 1
                    button_found = True
                    print(f"   ğŸ”˜ Clic {click_count} sur 'Voir plus'")
                    break
        
        if not button_found:
            break  # Plus de bouton
    
    return click_count
```

---

## ğŸ› ï¸ ImplÃ©mentation recommandÃ©e

### Nouveau script: `extract_all_apartment_urls.py`

**FonctionnalitÃ©s:**
1. **MÃ©thode hybride** : Combine scroll + recherche de bouton + pagination
2. **Extraction robuste** : Plusieurs mÃ©thodes pour trouver les URLs
3. **Sauvegarde** : Sauvegarde toutes les URLs dans `data/all_apartment_urls.json`
4. **Rapport** : Affiche le nombre total d'appartements trouvÃ©s

**Structure:**
```python
async def extract_all_apartment_urls():
    """
    Extrait TOUTES les URLs d'appartements depuis le dashboard Jinka
    """
    # 1. Setup + Login
    # 2. Aller au dashboard
    # 3. Essayer scroll infini
    # 4. Essayer bouton "Voir plus"
    # 5. Essayer pagination
    # 6. Extraire toutes les URLs (dÃ©dupliquer)
    # 7. Sauvegarder dans JSON
    # 8. Retourner la liste
```

---

## ğŸ“ Checklist d'implÃ©mentation

- [ ] CrÃ©er `extract_all_apartment_urls.py`
- [ ] ImplÃ©menter la mÃ©thode de scroll infini
- [ ] ImplÃ©menter la dÃ©tection de bouton "Voir plus"
- [ ] ImplÃ©menter la pagination par URL
- [ ] Ajouter la dÃ©duplication des URLs
- [ ] Sauvegarder dans `data/all_apartment_urls.json`
- [ ] Ajouter des logs dÃ©taillÃ©s
- [ ] GÃ©rer les erreurs et timeouts
- [ ] Tester avec l'alerte rÃ©elle

---

## ğŸ” MÃ©thodes d'extraction des URLs

### MÃ©thode 1: Regex sur le HTML
```python
import re
page_content = await page.content()
url_pattern = r'href="(/alert_result\?token=[^&]+&ad=\d+[^"]*)"'
urls = re.findall(url_pattern, page_content)
```

### MÃ©thode 2: SÃ©lecteurs Playwright
```python
links = page.locator('a[href*="alert_result"][href*="ad="]')
count = await links.count()
urls = []
for i in range(count):
    href = await links.nth(i).get_attribute('href')
    if href:
        urls.append(href)
```

### MÃ©thode 3: JavaScript injection
```python
urls = await page.evaluate('''
    () => {
        const links = Array.from(document.querySelectorAll('a[href*="ad="]'));
        return links.map(link => link.href).filter(href => href.includes('alert_result'));
    }
''')
```

---

## ğŸ¯ RÃ©sultat attendu

Un fichier `data/all_apartment_urls.json` contenant toutes les URLs:
```json
[
  "https://www.jinka.fr/alert_result?token=26c2ec3064303aa68ffa43f7c6518733&ad=90129925&from=dashboard_card&from_alert_filter=all&from_alert_page=1",
  "https://www.jinka.fr/alert_result?token=26c2ec3064303aa68ffa43f7c6518733&ad=78267327&from=dashboard_card&from_alert_filter=all&from_alert_page=1",
  ...
]
```

---

## ğŸš€ Prochaines Ã©tapes

1. **CrÃ©er le script** `extract_all_apartment_urls.py`
2. **Tester** avec ton alerte Jinka
3. **VÃ©rifier** le nombre d'appartements trouvÃ©s
4. **Utiliser** ces URLs pour le scraping complet

---

## âš ï¸ Notes importantes

- **Rate limiting** : Ajouter des pauses entre les actions pour Ã©viter de surcharger le serveur
- **Timeouts** : Configurer des timeouts appropriÃ©s pour le chargement
- **DÃ©duplication** : Toujours dÃ©dupliquer les URLs avant de sauvegarder
- **Erreurs** : GÃ©rer les cas oÃ¹ le chargement Ã©choue ou prend trop de temps






