#!/usr/bin/env python3
"""
Scraper Jinka pour extraire les donnÃ©es des appartements
"""

import asyncio
import json
import math
import os
import re
import sys
from datetime import datetime
from playwright.async_api import async_playwright
from dotenv import load_dotenv
from extract_exposition import ExpositionExtractor

load_dotenv()

class JinkaScraper:
    def __init__(self):
        self.browser = None
        self.context = None
        self.page = None
        self.apartments = []
        self.exposition_extractor = ExpositionExtractor()
        
    async def setup(self):
        """Initialise le navigateur et la page"""
        playwright = await async_playwright().start()
        self.browser = await playwright.chromium.launch(headless=False)  # Mode visible
        self.context = await self.browser.new_context()
        self.page = await self.context.new_page()
        
    async def login(self):
        """Se connecte Ã  Jinka via Google"""
        print("ğŸ” Connexion Ã  Jinka...")
        
        try:
            await self.page.goto('https://www.jinka.fr/sign/in')
            await self.page.wait_for_load_state('networkidle')
            
            # Cliquer sur "Continuer avec Google"
            google_button = self.page.locator('button:has-text("Continuer avec Google")')
            if await google_button.count() > 0:
                await google_button.click()
                await self.page.wait_for_load_state('networkidle')
                await self.page.wait_for_timeout(2000)
                
                # Saisir l'email
                email_input = self.page.locator('input[type="email"]')
                if await email_input.count() > 0:
                    await email_input.fill(os.getenv('JINKA_EMAIL'))
                    await self.page.keyboard.press('Enter')
                    await self.page.wait_for_timeout(2000)
                
                # Saisir le mot de passe
                password_input = self.page.locator('input[type="password"]')
                if await password_input.count() > 0:
                    await password_input.fill(os.getenv('JINKA_PASSWORD'))
                    await self.page.keyboard.press('Enter')
                    await self.page.wait_for_load_state('networkidle')
                    
                print("âœ… Connexion rÃ©ussie")
                return True
            else:
                print("âŒ Bouton Google non trouvÃ©")
                return False
                
        except Exception as e:
            print(f"âŒ Erreur de connexion: {e}")
            return False
    
    async def scrape_alert_page(self, alert_url):
        """Scrape une page d'alerte Jinka"""
        print(f"ğŸ  Scraping de l'alerte: {alert_url}")
        
        try:
            await self.page.goto(alert_url)
            await self.page.wait_for_load_state('networkidle')
            await self.page.wait_for_timeout(2000)
            
            # Attendre que la page se charge complÃ¨tement
            await self.page.wait_for_timeout(3000)
            
            # Essayer diffÃ©rents sÃ©lecteurs pour les cartes d'appartements
            selectors = [
                'a[href*="alert_result"][href*="ad="]',  # Liens avec alert_result ET ad=
                'a[href*="alert_result"]',
                'a[href*="ad="]',
                'a.sc-bdVaJa.csp.sc-cJSrbW.doPXAe',  # SÃ©lecteur exact d'aprÃ¨s l'image
                'a.sc-bdVaJa',  # SÃ©lecteur plus large
                '.apartment-card',
                '[data-testid="apartment-card"]',
                'a[href*="/alert_result"]'
            ]
            
            apartment_links = None
            count = 0
            
            for selector in selectors:
                try:
                    apartment_links = self.page.locator(selector)
                    count = await apartment_links.count()
                    if count > 0:
                        print(f"ğŸ“‹ {count} appartements trouvÃ©s avec sÃ©lecteur: {selector}")
                        break
                except:
                    continue
            
            if count == 0:
                print("ğŸ” Aucun appartement trouvÃ©, debug de la page...")
                # Debug: afficher le contenu de la page
                page_content = await self.page.content()
                print(f"ğŸ“„ Taille de la page: {len(page_content)} caractÃ¨res")
                
                # Chercher tous les liens
                all_links = self.page.locator('a')
                all_links_count = await all_links.count()
                print(f"ğŸ”— Total de liens sur la page: {all_links_count}")
                
                # Afficher les premiers liens trouvÃ©s
                for i in range(min(5, all_links_count)):
                    href = await all_links.nth(i).get_attribute('href')
                    print(f"   Lien {i+1}: {href}")
                
                return False
            
            # Extraire les URLs des appartements
            apartment_urls = []
            for i in range(count):
                href = await apartment_links.nth(i).get_attribute('href')
                print(f"   Lien {i+1}: href='{href}'")
                
                # Chercher les liens avec id= (format loueragile://) ou ad=
                if href and ('id=' in href or 'ad=' in href):
                    # Extraire l'ID de l'appartement
                    apartment_id = None
                    if 'id=' in href:
                        import re
                        match = re.search(r'id=(\d+)', href)
                        if match:
                            apartment_id = match.group(1)
                    elif 'ad=' in href:
                        import re
                        match = re.search(r'ad=(\d+)', href)
                        if match:
                            apartment_id = match.group(1)
                    
                    if apartment_id:
                        # Construire l'URL standard Jinka
                        full_url = f"https://www.jinka.fr/alert_result?token=26c2ec3064303aa68ffa43f7c6518733&ad={apartment_id}&from=dashboard_card&from_alert_filter=all&from_alert_page=1"
                        apartment_urls.append(full_url)
                        print(f"   âœ… Appartement {i+1} (ID: {apartment_id}): {full_url}")
                    else:
                        print(f"   âŒ Lien {i+1} ignorÃ©: impossible d'extraire l'ID")
                else:
                    print(f"   âŒ Lien {i+1} ignorÃ©: pas de paramÃ¨tre 'id=' ou 'ad='")
            
            print(f"ğŸ”— {len(apartment_urls)} URLs d'appartements extraites")
            
            # Scraper chaque appartement
            for i, url in enumerate(apartment_urls):
                print(f"ğŸ  Scraping appartement {i+1}/{len(apartment_urls)}")
                apartment_data = await self.scrape_apartment(url)
                if apartment_data:
                    self.apartments.append(apartment_data)
                    await self.save_apartment(apartment_data)
                
                # Pause entre les requÃªtes
                await self.page.wait_for_timeout(1000)
            
            return True
            
        except Exception as e:
            print(f"âŒ Erreur scraping alerte: {e}")
            return False
    
    async def scrape_apartment(self, url):
        """Scrape les dÃ©tails d'un appartement"""
        try:
            await self.page.goto(url)
            await self.page.wait_for_load_state('networkidle')
            await self.page.wait_for_timeout(2000)
            
            # Extraire l'ID de l'appartement
            apartment_id = self.extract_apartment_id(url)
            
            # Extraire les donnÃ©es
            description = await self.extract_description()
            caracteristiques = await self.extract_caracteristiques()
            photos = await self.extract_photos()
            
            data = {
                'id': apartment_id,
                'url': url,
                'scraped_at': datetime.now().isoformat(),
                'titre': await self.extract_titre(),
                'prix': await self.extract_prix(),
                'prix_m2': await self.extract_prix_m2(),
                'localisation': await self.extract_localisation(),
                'coordinates': await self.extract_coordinates(),
                'map_info': await self.extract_map_info(),
                'surface': await self.extract_surface(),
                'pieces': await self.extract_pieces(),
                'date': await self.extract_date(),
                'transports': await self.extract_transports(),
                'description': description,
                'photos': photos,
                'caracteristiques': caracteristiques,
                'agence': await self.extract_agence(),
                'style_haussmannien': await self.extract_style_haussmannien()
            }
            
            # Ajouter l'analyse d'exposition contextuelle
            data['exposition'] = self.exposition_extractor.extract_exposition_ultimate(data)
            
            print(f"âœ… Appartement {apartment_id} scrapÃ©")
            return data
            
        except Exception as e:
            print(f"âŒ Erreur scraping appartement {url}: {e}")
            return None
    
    def extract_apartment_id(self, url):
        """Extrait l'ID de l'appartement depuis l'URL"""
        match = re.search(r'ad=(\d+)', url)
        return match.group(1) if match else "unknown"
    
    async def extract_titre(self):
        """Extrait le titre de l'appartement"""
        try:
            # Chercher le titre dans diffÃ©rents sÃ©lecteurs possibles
            selectors = ['h1', '.title', '[data-testid="title"]', 'h2']
            for selector in selectors:
                element = self.page.locator(selector).first
                if await element.count() > 0:
                    text = await element.text_content()
                    if text and len(text.strip()) > 5:
                        return text.strip()
            return "Titre non trouvÃ©"
        except:
            return "Titre non trouvÃ©"
    
    async def extract_prix(self):
        """Extrait le prix principal"""
        try:
            # SÃ©lecteur pour le prix principal
            price_element = self.page.locator('.hmmXKG, [class*="price"], .price').first
            if await price_element.count() > 0:
                text = await price_element.text_content()
                # Nettoyer le prix
                price = re.search(r'[\d\s]+â‚¬', text or '')
                return price.group(0).strip() if price else "Prix non trouvÃ©"
            return "Prix non trouvÃ©"
        except:
            return "Prix non trouvÃ©"
    
    async def extract_prix_m2(self):
        """Extrait le prix au mÂ²"""
        try:
            # Chercher le prix au mÂ² prÃ¨s du prix principal
            price_elements = self.page.locator('text=/â‚¬\/mÂ²/')
            if await price_elements.count() > 0:
                text = await price_elements.first.text_content()
                return text.strip() if text else "Prix/mÂ² non trouvÃ©"
            return "Prix/mÂ² non trouvÃ©"
        except:
            return "Prix/mÂ² non trouvÃ©"
    
    async def extract_localisation(self):
        """Extrait la localisation (adresse exacte si possible)"""
        try:
            # RÃ©cupÃ©rer tout le contenu de la page
            page_text = await self.page.text_content('body')
            
            # Chercher l'adresse exacte avec diffÃ©rents patterns
            address_patterns = [
                r'(\d+[,\s]*[a-zA-Z\s]*[Rr]ue[^,\n]*)',
                r'(\d+[,\s]*[a-zA-Z\s]*[Aa]venue[^,\n]*)',
                r'(\d+[,\s]*[a-zA-Z\s]*[Bb]oulevard[^,\n]*)',
                r'(\d+[,\s]*[a-zA-Z\s]*[Pp]lace[^,\n]*)',
                r'(\d+[,\s]*[a-zA-Z\s]*[Cc]ours[^,\n]*)',
                r'(\d+[,\s]*[a-zA-Z\s]*[Vv]illa[^,\n]*)',
                r'(\d+[,\s]*[a-zA-Z\s]*[Ii]mpasse[^,\n]*)',
                r'(\d+[,\s]*[a-zA-Z\s]*[Aa]llÃ©e[^,\n]*)',
                r'(\d+[,\s]*[a-zA-Z\s]*[Pp]assage[^,\n]*)',
                r'(\d+[,\s]*[a-zA-Z\s]*[Cc]hemin[^,\n]*)'
            ]
            
            adresses_trouvees = []
            for pattern in address_patterns:
                matches = re.findall(pattern, page_text, re.IGNORECASE)
                for match in matches:
                    # Nettoyer l'adresse
                    clean_addr = re.sub(r'\s+', ' ', match.strip())
                    if len(clean_addr) > 5 and clean_addr not in adresses_trouvees:
                        adresses_trouvees.append(clean_addr)
            
            if adresses_trouvees:
                return adresses_trouvees[0]  # Retourner la premiÃ¨re adresse trouvÃ©e
            
            # Fallback 1: chercher juste l'arrondissement
            selectors = ['text=/Paris \d+e/', 'text=/750\d+/', '[class*="location"]']
            for selector in selectors:
                element = self.page.locator(selector).first
                if await element.count() > 0:
                    text = await element.text_content()
                    if text and 'Paris' in text:
                        return text.strip()
            
            # Fallback 2: utiliser les stations de mÃ©tro comme localisation
            try:
                transports = await self.extract_transports()
                if transports:
                    # Prendre les 2 premiÃ¨res stations comme localisation
                    stations_str = ", ".join(transports[:2])
                    return f"Proche de {stations_str}"
            except Exception as e:
                print(f"  âš ï¸ Erreur fallback stations: {e}")
            
            return "Localisation non trouvÃ©e"
        except:
            return "Localisation non trouvÃ©e"
    
    async def extract_surface(self):
        """Extrait la surface"""
        try:
            # Chercher la surface dans diffÃ©rents formats
            surface_elements = self.page.locator('text=/\d+\s*mÂ²/')
            if await surface_elements.count() > 0:
                text = await surface_elements.first.text_content()
                return text.strip() if text else "Surface non trouvÃ©e"
            return "Surface non trouvÃ©e"
        except:
            return "Surface non trouvÃ©e"
    
    async def extract_pieces(self):
        """Extrait le nombre de piÃ¨ces"""
        try:
            # Chercher les piÃ¨ces dans diffÃ©rents formats
            pieces_elements = self.page.locator('text=/\d+\s*piÃ¨ces?/')
            if await pieces_elements.count() > 0:
                text = await pieces_elements.first.text_content()
                return text.strip() if text else "PiÃ¨ces non trouvÃ©es"
            return "PiÃ¨ces non trouvÃ©es"
        except:
            return "PiÃ¨ces non trouvÃ©es"
    
    async def extract_date(self):
        """Extrait la date de publication"""
        try:
            # Chercher la date
            date_elements = self.page.locator('text=/le \d+ \w+ Ã /')
            if await date_elements.count() > 0:
                text = await date_elements.first.text_content()
                return text.strip() if text else "Date non trouvÃ©e"
            return "Date non trouvÃ©e"
        except:
            return "Date non trouvÃ©e"
    
    async def extract_transports(self):
        """Extrait les transports proches (stations de mÃ©tro)"""
        try:
            transports = []
            
            # MÃ©thode 1: Chercher la section "Proche des stations"
            try:
                # Chercher le titre "Proche des stations"
                stations_section = self.page.locator('h3:has-text("Proche des stations")').first
                if await stations_section.count() > 0:
                    # Chercher la liste des stations qui suit
                    stations_list = await stations_section.locator('xpath=following-sibling::ul//li').all()
                    for station_element in stations_list:
                        station_text = await station_element.text_content()
                        if station_text:
                            # Nettoyer le texte (enlever les numÃ©ros de ligne)
                            station_name = re.sub(r'\s+\d+\s*$', '', station_text.strip())
                            if station_name and len(station_name) > 2:
                                transports.append(station_name)
            except Exception as e:
                print(f"  âš ï¸ Erreur extraction section stations: {e}")
            
            # MÃ©thode 2: Chercher les images de mÃ©tro et extraire les noms
            try:
                metro_images = await self.page.locator('img[src*="subway"], img[alt*="metro"]').all()
                for img in metro_images:
                    # Chercher le texte de la station dans le mÃªme conteneur
                    parent = img.locator('..')
                    station_text = await parent.text_content()
                    if station_text:
                        # Extraire le nom de la station (avant les icÃ´nes)
                        station_name = re.split(r'\s+\d+\s*', station_text)[0].strip()
                        if station_name and len(station_name) > 2 and station_name not in transports:
                            transports.append(station_name)
            except Exception as e:
                print(f"  âš ï¸ Erreur extraction images mÃ©tro: {e}")
            
            # MÃ©thode 3: Fallback - chercher les patterns de stations
            if not transports:
                try:
                    transport_elements = self.page.locator('text=/[A-Za-z]+\s+\d+/')
                    for i in range(await transport_elements.count()):
                        text = await transport_elements.nth(i).text_content()
                        if text and re.match(r'[A-Za-z]+\s+\d+', text.strip()):
                            transports.append(text.strip())
                except Exception as e:
                    print(f"  âš ï¸ Erreur extraction fallback: {e}")
            
            # Nettoyer et dÃ©dupliquer
            transports = list(dict.fromkeys(transports))  # Supprimer les doublons
            return transports[:10]  # Limiter Ã  10 transports
            
        except Exception as e:
            print(f"  âš ï¸ Erreur extraction transports: {e}")
            return []
    
    async def extract_description(self):
        """Extrait la description dÃ©taillÃ©e"""
        try:
            # Essayer diffÃ©rents sÃ©lecteurs pour la description
            description_selectors = [
                '.fz-16.sc-bxivhb.fcnykg',
                '[class*="description"]',
                'p:has-text("Globalstone")',
                'text=/Globalstone/',
                'div:has-text("Globalstone")',
                'section:has-text("Globalstone")'
            ]
            
            for selector in description_selectors:
                try:
                    element = self.page.locator(selector).first
                    if await element.count() > 0:
                        text = await element.text_content()
                        if text and len(text.strip()) > 50:  # S'assurer qu'on a une vraie description
                            return text.strip()
                except:
                    continue
            
            return "Description non trouvÃ©e"
        except:
            return "Description non trouvÃ©e"
    
    async def extract_map_info(self):
        """Extrait les informations de la carte (rues, quartier, mÃ©tros)"""
        try:
            print("   ğŸ—ºï¸ Analyse de la carte...")
            
            # Prendre un screenshot de la carte pour analyse
            map_element = self.page.locator('.leaflet-container, [class*="map"], [class*="carte"]').first
            if await map_element.count() > 0:
                # Attendre que la carte se charge
                await self.page.wait_for_timeout(3000)
                
                # Prendre un screenshot de la carte
                screenshot_path = f"data/screenshots/map_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
                os.makedirs("data/screenshots", exist_ok=True)
                await map_element.screenshot(path=screenshot_path)
                print(f"   ğŸ“¸ Screenshot de la carte sauvegardÃ©: {screenshot_path}")
            
            # Extraire le texte visible sur la carte
            map_text = ""
            try:
                map_text = await map_element.text_content()
            except:
                pass
            
            # Chercher des noms de rues dans le contenu de la page
            page_content = await self.page.text_content('body')
            
            # Patterns pour identifier les rues et quartiers
            street_patterns = [
                r'Rue\s+[A-Za-z\s\-\']+',
                r'Avenue\s+[A-Za-z\s\-\']+',
                r'Boulevard\s+[A-Za-z\s\-\']+',
                r'Place\s+[A-Za-z\s\-\']+',
                r'Cours\s+[A-Za-z\s\-\']+',
                r'Villa\s+[A-Za-z\s\-\']+',
                r'Impasse\s+[A-Za-z\s\-\']+',
                r'AllÃ©e\s+[A-Za-z\s\-\']+',
                r'Passage\s+[A-Za-z\s\-\']+',
                r'Chemin\s+[A-Za-z\s\-\']+'
            ]
            
            metro_patterns = [
                r'[A-Za-z\s\-\']+\s*\(mÃ©tro\)',
                r'Station\s+[A-Za-z\s\-\']+',
                r'MÃ©tro\s+[A-Za-z\s\-\']+'
            ]
            
            # Extraire les rues
            streets_found = []
            for pattern in street_patterns:
                matches = re.findall(pattern, page_content, re.IGNORECASE)
                for match in matches:
                    clean_street = re.sub(r'\s+', ' ', match.strip())
                    if len(clean_street) > 5 and clean_street not in streets_found:
                        streets_found.append(clean_street)
            
            # Extraire les mÃ©tros
            metros_found = []
            for pattern in metro_patterns:
                matches = re.findall(pattern, page_content, re.IGNORECASE)
                for match in matches:
                    clean_metro = re.sub(r'\s+', ' ', match.strip())
                    if len(clean_metro) > 3 and clean_metro not in metros_found:
                        metros_found.append(clean_metro)
            
            # Identifier le quartier basÃ© sur les rues trouvÃ©es
            quartier = self.identify_quartier(streets_found, metros_found)
            
            map_info = {
                "streets": streets_found[:10],  # Limiter Ã  10 rues
                "metros": metros_found[:5],     # Limiter Ã  5 mÃ©tros
                "quartier": quartier,
                "screenshot": screenshot_path if 'screenshot_path' in locals() else None
            }
            
            print(f"   ğŸ˜ï¸ Quartier identifiÃ©: {quartier}")
            print(f"   ğŸ›£ï¸ Rues trouvÃ©es: {len(streets_found)}")
            print(f"   ğŸš‡ MÃ©tros trouvÃ©s: {len(metros_found)}")
            
            return map_info
            
        except Exception as e:
            print(f"   âŒ Erreur analyse carte: {e}")
            return {"streets": [], "metros": [], "quartier": "Non identifiÃ©", "error": str(e)}
    
    def identify_quartier(self, streets, metros):
        """Identifie le quartier basÃ© sur les rues et mÃ©tros trouvÃ©s"""
        # Quartiers du 19e avec leurs rues caractÃ©ristiques
        quartiers_19e = {
            "Buttes-Chaumont": ["Rue Botzaris", "Avenue SecrÃ©tan", "Rue Manin", "Rue de CrimÃ©e", "Botzaris", "SecrÃ©tan", "Manin", "CrimÃ©e"],
            "Place des FÃªtes": ["Rue Carducci", "Rue MÃ©lingue", "Rue des Alouettes", "Rue de la Villette", "Carducci", "MÃ©lingue", "Alouettes", "Villette"],
            "Jourdain": ["Rue de Belleville", "Rue Pelleport", "Rue de MouzaÃ¯a", "Rue Compans", "Belleville", "Pelleport", "MouzaÃ¯a", "Compans"],
            "PyrÃ©nÃ©es": ["Rue Pradier", "Rue Clavel", "Rue RÃ©beval", "Rue Levert", "Pradier", "Clavel", "RÃ©beval", "Levert"],
            "Belleville": ["Rue de Belleville", "Rue du Faubourg du Temple", "Boulevard de la Villette", "Belleville", "Faubourg du Temple", "Villette"],
            "Canal de l'Ourcq": ["Quai de la Loire", "Quai de la Seine", "Rue de l'Ourcq", "Loire", "Seine", "Ourcq"]
        }
        
        # MÃ©tros caractÃ©ristiques
        metros_quartiers = {
            "Place des FÃªtes": ["Place des FÃªtes", "Place des Fetes"],
            "Jourdain": ["Jourdain"],
            "PyrÃ©nÃ©es": ["PyrÃ©nÃ©es", "Pyrenees"],
            "Buttes-Chaumont": ["Botzaris", "CrimÃ©e", "CrimÃ©e"],
            "Belleville": ["Belleville", "Couronnes"]
        }
        
        # Compter les correspondances
        quartier_scores = {}
        
        for quartier, rues_quartier in quartiers_19e.items():
            score = 0
            for rue in streets:
                for rue_quartier in rues_quartier:
                    if rue_quartier.lower() in rue.lower():
                        score += 1
            quartier_scores[quartier] = score
        
        # Ajouter les scores des mÃ©tros
        for quartier, metros_quartier in metros_quartiers.items():
            for metro in metros:
                for metro_quartier in metros_quartier:
                    if metro_quartier.lower() in metro.lower():
                        quartier_scores[quartier] = quartier_scores.get(quartier, 0) + 2
        
        # Retourner le quartier avec le plus haut score
        if quartier_scores:
            best_quartier = max(quartier_scores, key=quartier_scores.get)
            if quartier_scores[best_quartier] > 0:
                return f"{best_quartier} (score: {quartier_scores[best_quartier]})"
        
        return "Quartier non identifiÃ©"
    
    def analyze_screenshot_for_quartier(self, screenshot_path):
        """Analyse le screenshot pour identifier le quartier (mÃ©thode basique)"""
        try:
            if not os.path.exists(screenshot_path):
                return "Screenshot non trouvÃ©"
            
            # Pour l'instant, on retourne une analyse basÃ©e sur la description
            # Dans une version avancÃ©e, on pourrait utiliser OCR ou vision par ordinateur
            return "Analyse manuelle requise - voir screenshot"
            
        except Exception as e:
            return f"Erreur analyse: {e}"
    
    async def extract_coordinates(self):
        """Extrait les coordonnÃ©es GPS depuis la carte Leaflet"""
        try:
            # Chercher les Ã©lÃ©ments de la carte Leaflet avec diffÃ©rents sÃ©lecteurs
            leaflet_selectors = [
                '.leaflet-proxy',
                '.leaflet-map-pane', 
                '.leaflet-container',
                '[class*="leaflet"]'
            ]
            
            coordinates = None
            for selector in leaflet_selectors:
                elements = self.page.locator(selector)
                count = await elements.count()
                
                for i in range(count):
                    element = elements.nth(i)
                    style = await element.get_attribute('style')
                    
                    if style and 'translate3d' in style:
                        print(f"   ğŸ” Style trouvÃ©: {style[:100]}...")
                        
                        # Extraire les coordonnÃ©es du transform avec regex plus robuste
                        import re
                        patterns = [
                            r'translate3d\(([^,]+),\s*([^,]+),\s*([^)]+)\)',
                            r'translate3d\(([^,]+),\s*([^,]+),\s*([^)]+)\)',
                            r'transform:\s*translate3d\(([^,]+),\s*([^,]+),\s*([^)]+)\)'
                        ]
                        
                        for pattern in patterns:
                            match = re.search(pattern, style)
                            if match:
                                try:
                                    x_str = match.group(1).strip()
                                    y_str = match.group(2).strip()
                                    scale_str = match.group(3).strip()
                                    
                                    print(f"   ğŸ“ CoordonnÃ©es brutes: x={x_str}, y={y_str}, scale={scale_str}")
                                    
                                    # Nettoyer et convertir les valeurs
                                    x = float(x_str.replace('px', '').replace('e+', 'e'))
                                    y = float(y_str.replace('px', '').replace('e+', 'e'))
                                    scale = float(scale_str.replace('px', '')) if scale_str != '0px' else 1.0
                                    
                                    # VÃ©rifier que les valeurs sont valides (pas 0)
                                    if abs(x) > 1000 and abs(y) > 1000:  # CoordonnÃ©es Web Mercator valides
                                        # Convertir les coordonnÃ©es Web Mercator en lat/lng
                                        lon = (x / 20037508.34) * 180
                                        lat = (y / 20037508.34) * 180
                                        lat = 180 / 3.14159265359 * (2 * math.atan(math.exp(lat * 3.14159265359 / 180)) - 3.14159265359 / 2)
                                        
                                        coordinates = {
                                            "latitude": round(lat, 6),
                                            "longitude": round(lon, 6),
                                            "raw_x": x,
                                            "raw_y": y,
                                            "scale": scale
                                        }
                                        print(f"   âœ… CoordonnÃ©es converties: {lat:.6f}, {lon:.6f}")
                                        break
                                    else:
                                        print(f"   âš ï¸ CoordonnÃ©es invalides (trop petites): x={x}, y={y}")
                                        
                                except ValueError as ve:
                                    print(f"   âŒ Erreur de conversion: {ve}")
                                    continue
                        
                        if coordinates:
                            break
                
                if coordinates:
                    break
            
            if not coordinates:
                print("   âŒ Aucune coordonnÃ©e valide trouvÃ©e")
                return {"latitude": None, "longitude": None, "error": "No valid coordinates found"}
            
            return coordinates
            
        except Exception as e:
            print(f"   âŒ Erreur gÃ©nÃ©rale: {e}")
            return {"latitude": None, "longitude": None, "error": str(e)}
    
    async def extract_style_haussmannien(self):
        """Extrait les Ã©lÃ©ments de style haussmannien"""
        try:
            # RÃ©cupÃ©rer la description
            description = await self.extract_description()
            if description == "Description non trouvÃ©e":
                return {"score": 0, "elements": [], "keywords": []}
            
            # Mots-clÃ©s haussmanniens Ã©tendus
            haussmann_keywords = {
                'architectural': [
                    'haussmannien', 'haussmannienne', 'haussmann',
                    'moulures', 'moulure', 'moulurÃ©', 'moulurÃ©e',
                    'cheminÃ©e', 'cheminÃ©es', 'cheminÃ©e de marbre',
                    'parquet', 'parquets', 'parquet d\'origine', 'parquet ancien',
                    'corniches', 'corniche', 'corniche moulurÃ©e',
                    'rosaces', 'rosace', 'rosace de plafond',
                    'balcon', 'balcons', 'balcon en fer forgÃ©', 'balcon forgÃ©',
                    'fer forgÃ©', 'fer forgÃ©e', 'grille en fer forgÃ©',
                    'hauteur sous plafond', 'haut plafond', 'plafond haut',
                    'escalier', 'escaliers', 'escalier d\'honneur'
                ],
                'caractÃ¨re': [
                    'caractÃ¨re', 'caractÃ¨res', 'caractÃ©ristique',
                    'restaurÃ©', 'restaurÃ©e', 'rÃ©novÃ©', 'rÃ©novÃ©e',
                    'authentique', 'authentiques', 'original', 'originale',
                    'Ã©poque', 'pÃ©riode', 'Ã©poque haussmannienne',
                    'ancien', 'ancienne', 'ancien immeuble',
                    'vieux', 'vieille', 'vieux immeuble',
                    'charme', 'charmant', 'charmante',
                    'prestige', 'prestigieux', 'prestigieuse',
                    'noble', 'noblesse', 'noblesse des matÃ©riaux'
                ],
                'matÃ©riaux': [
                    'marbre', 'marbres', 'marbre de carrare',
                    'bois', 'bois noble', 'bois prÃ©cieux',
                    'pierre', 'pierres', 'pierre de taille',
                    'stuc', 'stucs', 'stuc dÃ©coratif',
                    'plÃ¢tre', 'plÃ¢tres', 'plÃ¢tre moulÃ©',
                    'mÃ©tal', 'mÃ©taux', 'mÃ©tal forgÃ©'
                ],
                'dÃ©tails': [
                    'moulure', 'moulures', 'moulure de plafond',
                    'dÃ©coration', 'dÃ©coratif', 'dÃ©corative',
                    'ornement', 'ornements', 'ornemental',
                    'dÃ©tail', 'dÃ©tails', 'dÃ©tail architectural',
                    'finesse', 'finesses', 'finitions',
                    'Ã©lÃ©gance', 'Ã©lÃ©gant', 'Ã©lÃ©gante'
                ]
            }
            
            # Chercher les mots-clÃ©s par catÃ©gorie
            found_by_category = {}
            total_found = 0
            all_keywords = []
            
            for category, keywords in haussmann_keywords.items():
                found_in_category = []
                for keyword in keywords:
                    if keyword.lower() in description.lower():
                        found_in_category.append(keyword)
                        all_keywords.append(keyword)
                        total_found += 1
                
                if found_in_category:
                    found_by_category[category] = found_in_category
            
            # Calculer un score de style
            style_score = min(100, (total_found * 10) + 20)  # 10 points par mot-clÃ© + 20 de base
            
            return {
                "score": style_score,
                "elements": found_by_category,
                "keywords": all_keywords,
                "total_found": total_found
            }
            
        except Exception as e:
            return {"score": 0, "elements": [], "keywords": [], "error": str(e)}
    
    async def extract_photos(self):
        """Extrait les URLs des photos d'appartement depuis la div spÃ©cifique"""
        try:
            print("   ğŸ“¸ Extraction des photos d'appartement...")
            
            photos = []
            
            # Cibler spÃ©cifiquement la div avec les classes sc-gPEVay jnWxBz
            gallery_div = self.page.locator('div.sc-gPEVay.jnWxBz')
            
            if await gallery_div.count() > 0:
                print("      ğŸ¯ Div galerie trouvÃ©e, extraction des images...")
                
                # Chercher toutes les images dans cette div
                images = await gallery_div.locator('img').all()
                
                for img in images:
                    try:
                        src = await img.get_attribute('src')
                        alt = await img.get_attribute('alt')
                        
                        if src and ('loueragile' in src or 'upload_pro_ad' in src or 'jinka' in src or 'media.apimo.pro' in src):
                            photos.append({
                                'url': src,
                                'alt': alt or 'appartement',
                                'selector': 'gallery_div'
                            })
                            print(f"      ğŸ“¸ Photo galerie: {src[:60]}...")
                    except Exception as e:
                        continue
            else:
                print("      âš ï¸ Div galerie non trouvÃ©e, recherche alternative...")
                
                # Fallback: chercher avec les anciens sÃ©lecteurs
                selectors = [
                    'img[alt*="logement"]',
                    'img[alt*="appartement"]', 
                    'img[src*="loueragile-media"]',
                    'img[src*="upload_pro_ad"]'
                ]
                
                for selector in selectors:
                    try:
                        elements = await self.page.query_selector_all(selector)
                        for element in elements:
                            src = await element.get_attribute('src')
                            alt = await element.get_attribute('alt')
                            if src and ('loueragile' in src or 'upload_pro_ad' in src or 'jinka' in src):
                                photos.append({
                                    'url': src,
                                    'alt': alt or 'appartement',
                                    'selector': selector
                                })
                                print(f"      ğŸ“¸ Photo fallback: {src[:60]}...")
                    except Exception as e:
                        continue
            
            # DÃ©dupliquer
            unique_photos = []
            seen_urls = set()
            for photo in photos:
                if photo['url'] not in seen_urls:
                    unique_photos.append(photo)
                    seen_urls.add(photo['url'])
            
            print(f"   âœ… {len(unique_photos)} photos d'appartement trouvÃ©es")
            return unique_photos[:10]  # Max 10 photos
            
        except Exception as e:
            print(f"   âŒ Erreur extraction photos: {e}")
            return []
    
    async def extract_caracteristiques(self):
        """Extrait les caractÃ©ristiques"""
        try:
            # Chercher la section caractÃ©ristiques
            char_elements = self.page.locator('h3:has-text("CaractÃ©ristiques") + *')
            if await char_elements.count() > 0:
                text = await char_elements.first.text_content()
                return text.strip() if text else "CaractÃ©ristiques non trouvÃ©es"
            return "CaractÃ©ristiques non trouvÃ©es"
        except:
            return "CaractÃ©ristiques non trouvÃ©es"
    
    async def extract_agence(self):
        """Extrait les informations de l'agence"""
        try:
            # Chercher le nom de l'agence
            agence_elements = self.page.locator('text=/[A-Z][A-Z\s]+/')
            for i in range(await agence_elements.count()):
                text = await agence_elements.nth(i).text_content()
                if text and len(text.strip()) > 3 and text.isupper():
                    return text.strip()
            return "Agence non trouvÃ©e"
        except:
            return "Agence non trouvÃ©e"
    
    async def save_apartment(self, apartment_data):
        """Sauvegarde les donnÃ©es d'un appartement"""
        try:
            os.makedirs('data/appartements', exist_ok=True)
            filename = f"data/appartements/{apartment_data['id']}.json"
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(apartment_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ Appartement {apartment_data['id']} sauvegardÃ©")
            
        except Exception as e:
            print(f"âŒ Erreur sauvegarde: {e}")
    
    async def cleanup(self):
        """Ferme le navigateur"""
        if self.browser:
            await self.browser.close()

async def main():
    """Fonction principale"""
    if len(sys.argv) < 2:
        print("Usage: python scrape_jinka.py <URL_ALERTE>")
        print("Exemple: python scrape_jinka.py 'https://www.jinka.fr/alert_result?token=...'")
        return
    
    alert_url = sys.argv[1]
    
    scraper = JinkaScraper()
    
    try:
        await scraper.setup()
        
        if await scraper.login():
            await scraper.scrape_alert_page(alert_url)
            print(f"âœ… Scraping terminÃ©: {len(scraper.apartments)} appartements")
        else:
            print("âŒ Ã‰chec de la connexion")
    
    except Exception as e:
        print(f"âŒ Erreur: {e}")
    
    finally:
        await scraper.cleanup()

if __name__ == "__main__":
    asyncio.run(main())
