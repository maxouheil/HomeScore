#!/usr/bin/env python3
"""
Scraper Jinka pour extraire les donn√©es des appartements
"""

import asyncio
import json
import math
import os
import re
import aiohttp
import sys
import imaplib
import email
from email.header import decode_header
from datetime import datetime, timedelta
from playwright.async_api import async_playwright
from dotenv import load_dotenv
from extract_exposition import ExpositionExtractor

load_dotenv()

class JinkaScraper:
    def __init__(self):
        self.browser = None
        self.context = None
        self.page = None
        self.apartments = []
        self.exposition_extractor = ExpositionExtractor()
        
    async def setup(self):
        """Initialise le navigateur et la page"""
        playwright = await async_playwright().start()
        self.browser = await playwright.chromium.launch(headless=False)  # Mode visible
        
        # Cr√©er un contexte avec un user-agent r√©aliste pour √©viter les 403
        self.context = await self.browser.new_context(
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            viewport={'width': 1920, 'height': 1080},
            locale='fr-FR',
            timezone_id='Europe/Paris'
        )
        self.page = await self.context.new_page()
        
        # Gestionnaire pour d√©tecter les erreurs 429
        self.rate_limit_count = 0
        
        async def handle_response(response):
            if response.status == 429:
                self.rate_limit_count += 1
                print(f"\n‚ö†Ô∏è  Erreur 429 d√©tect√©e (#{self.rate_limit_count}) sur: {response.url[:80]}")
                wait_time = min(30 + (self.rate_limit_count * 10), 120)  # 30s, puis 40s, 50s... max 120s
                print(f"   Rate limiting activ√© - attente de {wait_time} secondes...")
                await asyncio.sleep(wait_time)  # asyncio.sleep attend des secondes
        
        self.page.on('response', handle_response)
        
    def get_activation_code_from_gmail(self, max_wait_seconds=120):
        """R√©cup√®re le code d'activation depuis Gmail"""
        print("üìß R√©cup√©ration du code d'activation depuis Gmail...")
        
        gmail_email = os.getenv('GMAIL_EMAIL') or os.getenv('JINKA_EMAIL')
        gmail_password = os.getenv('GMAIL_PASSWORD') or os.getenv('JINKA_PASSWORD')
        
        if not gmail_email or not gmail_password:
            print("‚ùå Identifiants Gmail non trouv√©s dans .env")
            print("   Variables cherch√©es:")
            print(f"      GMAIL_EMAIL: {'‚úÖ' if os.getenv('GMAIL_EMAIL') else '‚ùå'}")
            print(f"      GMAIL_PASSWORD: {'‚úÖ' if os.getenv('GMAIL_PASSWORD') else '‚ùå'}")
            print(f"      JINKA_EMAIL: {'‚úÖ' if os.getenv('JINKA_EMAIL') else '‚ùå'}")
            print(f"      JINKA_PASSWORD: {'‚úÖ' if os.getenv('JINKA_PASSWORD') else '‚ùå'}")
            print("\n   üí° Ajoutez dans votre .env:")
            print("      GMAIL_EMAIL=votre@gmail.com")
            print("      GMAIL_PASSWORD=votre_mot_de_passe_application")
            print("   (ou utilisez JINKA_EMAIL/JINKA_PASSWORD si c'est le m√™me compte)")
            return None
        
        print(f"   ‚úÖ Utilisation de l'email: {gmail_email}")
        
        try:
            # Connexion IMAP √† Gmail
            mail = imaplib.IMAP4_SSL("imap.gmail.com")
            mail.login(gmail_email, gmail_password)
            mail.select("inbox")
            
            # Chercher les emails r√©cents de Jinka (derni√®res 10 minutes)
            # Format IMAP: chercher depuis une date
            search_date = (datetime.now() - timedelta(minutes=10)).strftime("%d-%b-%Y")
            # Chercher les emails de Jinka avec "code" dans le sujet ou le corps
            status, messages = mail.search(None, f'(SINCE {search_date} FROM "noreply@jinka.fr")')
            
            # Si pas de r√©sultats avec FROM, chercher juste les emails r√©cents avec "code"
            if not messages[0]:
                status, messages = mail.search(None, f'(SINCE {search_date} SUBJECT "code")')
            
            # Si toujours rien, chercher tous les emails r√©cents
            if not messages[0]:
                status, messages = mail.search(None, f'(SINCE {search_date})')
            
            if status != "OK" or not messages[0]:
                print("‚ö†Ô∏è  Aucun email trouv√© dans la recherche initiale")
                # Essayer une recherche plus large : tous les emails r√©cents
                search_date = (datetime.now() - timedelta(minutes=10)).strftime("%d-%b-%Y")
                status, messages = mail.search(None, f'(SINCE {search_date})')
            
            if status != "OK" or not messages[0]:
                print("‚ö†Ô∏è  Aucun email r√©cent trouv√©")
                mail.close()
                mail.logout()
                return None
            
            email_ids = messages[0].split()
            if not email_ids:
                print("‚ö†Ô∏è  Aucun email trouv√©")
                mail.close()
                mail.logout()
                return None
            
            # Parcourir les emails les plus r√©cents en premier
            for email_id in reversed(email_ids[-5:]):  # Derniers 5 emails max
                status, msg_data = mail.fetch(email_id, "(RFC822)")
                
                if status != "OK":
                    continue
                
                email_body = msg_data[0][1]
                email_message = email.message_from_bytes(email_body)
                
                # V√©rifier le sujet
                subject = decode_header(email_message["Subject"])[0][0]
                if isinstance(subject, bytes):
                    subject = subject.decode()
                
                # V√©rifier que c'est bien un email de Jinka
                from_addr = email_message.get("From", "")
                if "jinka.fr" not in from_addr.lower():
                    continue
                
                # Chercher le code dans le corps de l'email
                body = ""
                if email_message.is_multipart():
                    for part in email_message.walk():
                        content_type = part.get_content_type()
                        if content_type == "text/plain" or content_type == "text/html":
                            try:
                                body_part = part.get_payload(decode=True)
                                if body_part:
                                    body += body_part.decode('utf-8', errors='ignore')
                            except:
                                pass
                else:
                    try:
                        body = email_message.get_payload(decode=True).decode('utf-8', errors='ignore')
                    except:
                        body = str(email_message.get_payload())
                
                # Chercher un code (format Jinka: "Jinka - XXXX est votre code de connexion")
                # D'abord chercher dans le sujet avec le format exact de Jinka
                subject_patterns = [
                    r'Jinka\s*-\s*(\d{4})\s+est votre code de connexion',  # "Jinka - 3709 est votre code de connexion"
                    r'(\d{4})\s+est votre code de connexion',  # "3709 est votre code de connexion"
                    r'(\d{4})\s+est votre code',  # "3709 est votre code"
                    r'code de connexion[:\s]+(\d{4})',  # "code de connexion: 3709"
                    r'votre code[:\s]+(\d{4})',  # "votre code: 3709"
                ]
                
                for pattern in subject_patterns:
                    matches = re.findall(pattern, subject, re.IGNORECASE)
                    if matches:
                        code = matches[0]
                        if len(code) == 4 and code.isdigit():
                            print(f"‚úÖ Code d'activation trouv√© dans le sujet: {code}")
                            mail.close()
                            mail.logout()
                            return code
                
                # Chercher aussi dans le corps avec patterns g√©n√©raux
                body_patterns = [
                    r'code[:\s]+(\d{4,6})',  # "code: 1234" ou "code: 123456"
                    r'code d\'activation[:\s]+(\d{4,6})',
                    r'votre code[:\s]+(\d{4,6})',
                    r'code de connexion[:\s]+(\d{4,6})',
                    r'\b(\d{4})\b',  # Code √† 4 chiffres isol√©
                    r'\b(\d{6})\b',  # Code √† 6 chiffres isol√©
                ]
                
                for pattern in body_patterns:
                    matches = re.findall(pattern, body, re.IGNORECASE)
                    if matches:
                        code = matches[0]
                        # V√©rifier que c'est bien un code (4 ou 6 chiffres)
                        if len(code) in [4, 6] and code.isdigit():
                            # V√©rifier que ce n'est pas une ann√©e (2000-2099)
                            if not (len(code) == 4 and 2000 <= int(code) <= 2099):
                                print(f"‚úÖ Code d'activation trouv√© dans le corps: {code}")
                                mail.close()
                                mail.logout()
                                return code
            
            mail.close()
            mail.logout()
            print("‚ö†Ô∏è  Aucun code d'activation trouv√© dans les emails r√©cents")
            return None
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la r√©cup√©ration du code depuis Gmail: {e}")
            return None
    
    async def login(self):
        """Se connecte √† Jinka via email avec code d'activation"""
        print("üîê Connexion √† Jinka par email...")
        print(f"üìç √âTAPE 1: D√©but de la fonction login()")
        
        try:
            # Aller directement sur la page email au lieu de cliquer sur le bouton
            print(f"üìç √âTAPE 3: Navigation directe vers la page email...")
            try:
                await self.page.goto('https://www.jinka.fr/sign/in/email', wait_until='domcontentloaded', timeout=30000)
                print(f"‚úÖ √âTAPE 3: Navigation r√©ussie vers /sign/in/email")
            except Exception as e:
                print(f"‚ùå √âTAPE 3: Erreur lors de la navigation: {e}")
                if '429' in str(e) or self.rate_limit_count > 0:
                    print("‚ö†Ô∏è  Rate limiting d√©tect√© lors de la navigation")
                    wait_time = 30 + (self.rate_limit_count * 10)
                    print(f"   Attente de {wait_time} secondes...")
                    await asyncio.sleep(wait_time)
                    # R√©essayer une fois
                    print(f"üìç √âTAPE 3b: Nouvelle tentative de navigation...")
                    await self.page.goto('https://www.jinka.fr/sign/in/email', wait_until='domcontentloaded', timeout=30000)
                    print(f"‚úÖ √âTAPE 3b: Navigation r√©ussie")
                else:
                    raise
            
            # V√©rifier l'URL actuelle
            current_url = self.page.url
            print(f"üìç √âTAPE 5: V√©rification de l'URL actuelle: {current_url}")
            
            # V√©rifier si on a re√ßu des erreurs 429
            if self.rate_limit_count > 0:
                print(f"‚ö†Ô∏è  {self.rate_limit_count} erreur(s) 429 d√©tect√©e(s) - attente suppl√©mentaire...")
                await asyncio.sleep(10)
            
            print(f"‚úÖ √âTAPE 5: Page charg√©e et pr√™te")
            
            # Saisir l'email - Utiliser wait_for_selector pour √™tre plus rapide
            print(f"\nüìç √âTAPE 8: Recherche du champ email...")
            
            email_input_selectors = [
                # S√©lecteurs les plus probables en premier
                'input[type="email"]',
                'input[type="text"]',
                'div input[type="text"]',
                'form input[type="text"]',
                'input[name="email"]',
                'input[autocomplete="email"]',
                'input:visible',  # Dernier recours
            ]
            
            email_input = None
            
            # Essayer d'attendre directement le s√©lecteur le plus probable
            try:
                await self.page.wait_for_selector('input[type="email"], input[type="text"]', timeout=5000, state='visible')
                print("   ‚úÖ Champ email d√©tect√© rapidement")
            except:
                print("   ‚è≥ Attente du champ email...")
            
            # Chercher le champ avec les s√©lecteurs optimis√©s
            for selector in email_input_selectors:
                try:
                    input_elem = self.page.locator(selector)
                    count = await input_elem.count()
                    if count > 0:
                        # V√©rifier que le champ est visible
                        is_visible = await input_elem.first.is_visible()
                        if is_visible:
                            print(f"   ‚úÖ Trouv√© {count} champ(s) email avec s√©lecteur: {selector}")
                            email_input = input_elem.first
                            break
                except:
                    continue
                
                if email_input:
                    break
            
            if not email_input:
                print(f"‚ö†Ô∏è  √âTAPE 8: Champ email non trouv√© avec les s√©lecteurs standards")
                print("   Recherche alternative : analyse de tous les inputs visibles...")
                
                # Recherche alternative : tous les inputs visibles
                try:
                    all_inputs = await self.page.locator('input:visible').all()
                    print(f"   Trouv√© {len(all_inputs)} input(s) visible(s) sur la page")
                    
                    for i, inp in enumerate(all_inputs[:10]):  # Limiter aux 10 premiers
                        try:
                            input_type = await inp.get_attribute('type') or 'text'
                            input_name = await inp.get_attribute('name') or ''
                            input_id = await inp.get_attribute('id') or ''
                            input_placeholder = await inp.get_attribute('placeholder') or ''
                            input_class = await inp.get_attribute('class') or ''
                            
                            print(f"   Input {i+1}: type={input_type}, name={input_name}, id={input_id[:30]}")
                            print(f"      placeholder={input_placeholder[:40]}, class={input_class[:40]}")
                            
                            # Si c'est un input de type text ou email, c'est probablement le champ email
                            if input_type in ['text', 'email'] and 'password' not in input_type:
                                # V√©rifier qu'il n'est pas un champ de recherche ou autre
                                if 'search' not in input_id.lower() and 'search' not in input_name.lower():
                                    # Reconstruire un s√©lecteur pour cet input
                                    if input_id:
                                        email_input = self.page.locator(f'input#{input_id}')
                                    elif input_name:
                                        email_input = self.page.locator(f'input[name="{input_name}"]')
                                    else:
                                        # Utiliser l'index
                                        email_input = self.page.locator(f'input:visible').nth(i)
                                    
                                    # V√©rifier qu'on peut bien l'utiliser
                                    if await email_input.count() > 0:
                                        email_input = email_input.first
                                        selector_info = f"input#{input_id}" if input_id else f"input[name='{input_name}']"
                                        print(f"   ‚úÖ Champ email probable trouv√©: input {i+1}")
                                        print(f"      S√©lecteur utilis√©: {selector_info}")
                                        break
                        except Exception as e:
                            print(f"   Erreur analyse input {i+1}: {e}")
                            continue
                except Exception as e:
                    print(f"   Erreur recherche alternative: {e}")
                
                if not email_input:
                    print(f"‚ùå √âTAPE 8: Champ email non trouv√© apr√®s toutes les tentatives")
                    print("   V√©rification de l'URL actuelle...")
                    current_url = self.page.url
                    print(f"   URL: {current_url}")
                    # Prendre un screenshot pour debug
                    try:
                        os.makedirs("data", exist_ok=True)
                        await self.page.screenshot(path="data/debug_no_email_field.png")
                        print("   üì∏ Screenshot sauvegard√©: data/debug_no_email_field.png")
                    except:
                        pass
                    return False
            
            print(f"‚úÖ √âTAPE 8: Champ email trouv√©")
            
            print(f"\nüìç √âTAPE 9: R√©cup√©ration de l'email depuis .env...")
            jinka_email = os.getenv('JINKA_EMAIL')
            if not jinka_email:
                print(f"‚ùå √âTAPE 9: JINKA_EMAIL non trouv√© dans .env")
                return False
            print(f"‚úÖ √âTAPE 9: Email trouv√©: {jinka_email}")
            
            print(f"\nüìç √âTAPE 10: Saisie de l'email...")
            await email_input.fill(jinka_email)
            print(f"‚úÖ √âTAPE 10: Email saisi")
            await asyncio.sleep(2)  # D√©lai plus long avant de continuer
            print(f"‚úÖ √âTAPE 10b: Attente termin√©e")
            
            # Chercher et cliquer sur le bouton "Continuer" ou "Suivant"
            continue_button_selectors = [
                'button:has-text("Continuer")',
                'button:has-text("Suivant")',
                'button[type="submit"]',
                'button:has-text("Envoyer")',
            ]
            
            for selector in continue_button_selectors:
                button = self.page.locator(selector)
                if await button.count() > 0:
                    await button.click()
                    break
            else:
                # Si pas de bouton, appuyer sur Enter
                await self.page.keyboard.press('Enter')
            
            print("‚è≥ Attente du code d'activation...")
            await asyncio.sleep(4)  # D√©lai plus long pour laisser le temps √† l'email d'arriver
            
            # Attendre que le champ de code apparaisse et r√©cup√©rer le code depuis Gmail
            # Le code peut √™tre dans plusieurs inputs avec maxlength="1" (un par chiffre)
            print(f"\nüìç √âTAPE 11: Recherche du champ de code...")
            print("   Le code peut √™tre dans plusieurs inputs (un par chiffre)...")
            
            code_inputs = None  # Peut √™tre une liste d'inputs ou un seul input
            max_attempts = 15  # 15 tentatives de 2 secondes = 30 secondes max
            
            for attempt in range(max_attempts):
                # Chercher d'abord les inputs avec maxlength="1" (format code par chiffre)
                inputs_maxlength_1 = await self.page.locator('input[type="text"][maxlength="1"]').all()
                if len(inputs_maxlength_1) >= 4:  # Au moins 4 inputs = probablement un code
                    print(f"   ‚úÖ Trouv√© {len(inputs_maxlength_1)} inputs avec maxlength='1' (format code par chiffre)")
                    code_inputs = inputs_maxlength_1[:6]  # Prendre les 6 premiers (code √† 6 chiffres)
                    break
                
                # Chercher un input unique avec maxlength="6" ou "8"
                code_input_selectors = [
                    'input[maxlength="6"]',
                    'input[maxlength="8"]',
                    'input[name="code"]',
                    'input[placeholder*="code"]',
                    'input[placeholder*="Code"]',
                ]
                
                for selector in code_input_selectors:
                    input_elem = self.page.locator(selector)
                    count = await input_elem.count()
                    if count > 0:
                        # V√©rifier que c'est bien le champ de code
                        placeholder = await input_elem.first.get_attribute('placeholder') or ''
                        if 'code' in placeholder.lower() or selector.startswith('input[maxlength'):
                            code_inputs = [input_elem.first]  # Un seul input
                            print(f"   ‚úÖ Champ de code trouv√© avec s√©lecteur: {selector}")
                            break
                
                if code_inputs:
                    break
                
                if attempt % 3 == 0:  # Log tous les 3 essais
                    print(f"   Tentative {attempt + 1}/{max_attempts}...")
                await asyncio.sleep(2)
            
            if not code_inputs:
                print("‚ùå √âTAPE 11: Champ de code non trouv√©")
                return False
            
            print(f"‚úÖ √âTAPE 11: Champ(s) de code trouv√©(s) - {len(code_inputs)} input(s)")
            print("   R√©cup√©ration du code depuis Gmail...")
            
            # R√©cup√©rer le code depuis Gmail
            print(f"\nüìç √âTAPE 12: R√©cup√©ration du code depuis Gmail...")
            activation_code = None
            for attempt in range(15):  # 15 tentatives de 3 secondes = 45 secondes max
                activation_code = self.get_activation_code_from_gmail()
                if activation_code:
                    break
                if attempt < 14:  # Ne pas attendre apr√®s la derni√®re tentative
                    await asyncio.sleep(3)
                    print(f"   Tentative {attempt + 1}/15 de r√©cup√©ration du code...")
            
            if not activation_code:
                print("‚ùå √âTAPE 12: Code d'activation non trouv√© dans Gmail")
                print("üí° V√©rifiez votre bo√Æte mail et entrez le code manuellement")
                print("‚è≥ Attente de 60 secondes pour saisie manuelle...")
                # Attendre que l'utilisateur entre le code manuellement (timeout 60s)
                await asyncio.sleep(60)
            else:
                print(f"‚úÖ √âTAPE 12: Code trouv√©: {activation_code}")
                print(f"üìç √âTAPE 13: Saisie du code...")
                
                # Si plusieurs inputs (format un chiffre par input)
                if len(code_inputs) > 1:
                    print(f"   Format multi-inputs d√©tect√©: {len(code_inputs)} inputs")
                    # Si le code fait 4 chiffres mais qu'on a 6 inputs, le compl√©ter avec des z√©ros ou utiliser les 4 premiers
                    code_to_use = activation_code[:len(code_inputs)]
                    # Si code √† 4 chiffres mais 6 inputs, r√©p√©ter ou ajouter des z√©ros au d√©but
                    if len(code_to_use) == 4 and len(code_inputs) == 6:
                        # Essayer de remplir les 4 premiers inputs avec le code
                        code_to_use = activation_code
                    
                    for i, digit in enumerate(code_to_use[:len(code_inputs)]):
                        try:
                            await code_inputs[i].fill(digit)
                            await asyncio.sleep(0.2)  # Petit d√©lai entre chaque chiffre
                            print(f"      Chiffre {i+1}: {digit}")
                        except Exception as e:
                            print(f"   Erreur saisie chiffre {i+1}: {e}")
                else:
                    # Un seul input (format complet)
                    print(f"   Format input unique")
                    await code_inputs[0].fill(activation_code)
                
                await asyncio.sleep(0.5)
                print(f"‚úÖ √âTAPE 13: Code saisi")
                
                # Cliquer sur le bouton de validation
                submit_button_selectors = [
                    'button:has-text("Valider")',
                    'button:has-text("Continuer")',
                    'button:has-text("Confirmer")',
                    'button[type="submit"]',
                ]
                
                for selector in submit_button_selectors:
                    button = self.page.locator(selector)
                    if await button.count() > 0:
                        await button.click()
                        break
                else:
                    await self.page.keyboard.press('Enter')
                
                await asyncio.sleep(10)  # Attendre plus longtemps apr√®s la saisie du code
            
            # V√©rifier que la connexion a r√©ussi
            print("üîç V√©rification de la connexion...")
            await asyncio.sleep(10)  # Attendre plus longtemps avant de v√©rifier
            current_url = self.page.url
            print(f"üìç URL actuelle: {current_url}")
            
            if "sign/in" not in current_url and "jinka.fr" in current_url:
                print("‚úÖ Connexion r√©ussie !")
                return True
            else:
                print("‚ö†Ô∏è  V√©rification suppl√©mentaire...")
                await asyncio.sleep(10)  # Attendre plus longtemps avant la v√©rification suppl√©mentaire
                current_url = self.page.url
                print(f"üìç URL apr√®s v√©rification: {current_url}")
                if "sign/in" not in current_url:
                    print("‚úÖ Connexion r√©ussie !")
                    return True
                else:
                    print("‚ùå Connexion √©chou√©e - toujours sur la page de connexion")
                    print("üí° V√©rifiez que le code a √©t√© correctement saisi")
                    return False
                
        except asyncio.TimeoutError as e:
            print(f"\n‚ùå TIMEOUT: La connexion a pris trop de temps")
            print(f"   Erreur: {e}")
            print(f"   V√©rifiez les logs ci-dessus pour voir √† quelle √©tape √ßa a bloqu√©")
            return False
        except Exception as e:
            print(f"\n‚ùå ERREUR G√âN√âRALE lors de la connexion")
            print(f"   Type d'erreur: {type(e).__name__}")
            print(f"   Message: {e}")
            print(f"   V√©rifiez les logs ci-dessus pour voir √† quelle √©tape √ßa a √©chou√©")
            import traceback
            print("\nüìã Traceback complet:")
            traceback.print_exc()
            return False
    
    async def scrape_alert_page(self, alert_url):
        """Scrape une page d'alerte Jinka"""
        print(f"üè† Scraping de l'alerte: {alert_url}")
        
        try:
            await self.page.goto(alert_url)
            await self.page.wait_for_load_state('networkidle')
            await self.page.wait_for_timeout(2000)
            
            # Attendre que la page se charge compl√®tement
            await self.page.wait_for_timeout(3000)
            
            # Essayer diff√©rents s√©lecteurs pour les cartes d'appartements
            selectors = [
                'a[href*="alert_result"][href*="ad="]',  # Liens avec alert_result ET ad=
                'a[href*="alert_result"]',
                'a[href*="ad="]',
                'a.sc-bdVaJa.csp.sc-cJSrbW.doPXAe',  # S√©lecteur exact d'apr√®s l'image
                'a.sc-bdVaJa',  # S√©lecteur plus large
                '.apartment-card',
                '[data-testid="apartment-card"]',
                'a[href*="/alert_result"]'
            ]
            
            apartment_links = None
            count = 0
            
            for selector in selectors:
                try:
                    apartment_links = self.page.locator(selector)
                    count = await apartment_links.count()
                    if count > 0:
                        print(f"üìã {count} appartements trouv√©s avec s√©lecteur: {selector}")
                        break
                except:
                    continue
            
            if count == 0:
                print("üîç Aucun appartement trouv√©, debug de la page...")
                # Debug: afficher le contenu de la page
                page_content = await self.page.content()
                print(f"üìÑ Taille de la page: {len(page_content)} caract√®res")
                
                # Chercher tous les liens
                all_links = self.page.locator('a')
                all_links_count = await all_links.count()
                print(f"üîó Total de liens sur la page: {all_links_count}")
                
                # Afficher les premiers liens trouv√©s
                for i in range(min(5, all_links_count)):
                    href = await all_links.nth(i).get_attribute('href')
                    print(f"   Lien {i+1}: {href}")
                
                return False
            
            # Extraire les URLs des appartements
            apartment_urls = []
            for i in range(count):
                href = await apartment_links.nth(i).get_attribute('href')
                print(f"   Lien {i+1}: href='{href}'")
                
                # Chercher les liens avec id= (format loueragile://) ou ad=
                if href and ('id=' in href or 'ad=' in href):
                    # Extraire l'ID de l'appartement
                    apartment_id = None
                    if 'id=' in href:
                        import re
                        match = re.search(r'id=(\d+)', href)
                        if match:
                            apartment_id = match.group(1)
                    elif 'ad=' in href:
                        import re
                        match = re.search(r'ad=(\d+)', href)
                        if match:
                            apartment_id = match.group(1)
                    
                    if apartment_id:
                        # Construire l'URL standard Jinka
                        full_url = f"https://www.jinka.fr/alert_result?token=26c2ec3064303aa68ffa43f7c6518733&ad={apartment_id}&from=dashboard_card&from_alert_filter=all&from_alert_page=1"
                        apartment_urls.append(full_url)
                        print(f"   ‚úÖ Appartement {i+1} (ID: {apartment_id}): {full_url}")
                    else:
                        print(f"   ‚ùå Lien {i+1} ignor√©: impossible d'extraire l'ID")
                else:
                    print(f"   ‚ùå Lien {i+1} ignor√©: pas de param√®tre 'id=' ou 'ad='")
            
            print(f"üîó {len(apartment_urls)} URLs d'appartements extraites")
            
            # Scraper chaque appartement
            for i, url in enumerate(apartment_urls):
                print(f"üè† Scraping appartement {i+1}/{len(apartment_urls)}")
                apartment_data = await self.scrape_apartment(url)
                if apartment_data:
                    self.apartments.append(apartment_data)
                    await self.save_apartment(apartment_data)
                
                # Pause entre les requ√™tes
                await self.page.wait_for_timeout(1000)
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur scraping alerte: {e}")
            return False
    
    async def scrape_apartment(self, url):
        """Scrape les d√©tails d'un appartement"""
        try:
            await self.page.goto(url)
            await self.page.wait_for_load_state('networkidle')
            await self.page.wait_for_timeout(2000)
            
            # Extraire l'ID de l'appartement
            apartment_id = self.extract_apartment_id(url)
            
            # Extraire les donn√©es
            description = await self.extract_description()
            caracteristiques = await self.extract_caracteristiques()
            photos = await self.extract_photos()
            etage = await self.extract_etage()
            if etage:
                print(f"   üè¢ √âtage trouv√©: {etage}")
            else:
                print(f"   ‚ö†Ô∏è √âtage non trouv√©")
            
            # T√©l√©charger les photos localement
            await self.download_apartment_photos(apartment_id, photos)
            
            data = {
                'id': apartment_id,
                'url': url,
                'scraped_at': datetime.now().isoformat(),
                'titre': await self.extract_titre(),
                'prix': await self.extract_prix(),
                'prix_m2': await self.extract_prix_m2(),
                'localisation': await self.extract_localisation(),
                'coordinates': await self.extract_coordinates(),
                'map_info': await self.extract_map_info(apartment_id),
                'surface': await self.extract_surface(),
                'pieces': await self.extract_pieces(),
                'date': await self.extract_date(),
                'transports': await self.extract_transports(),
                'description': description,
                'photos': photos,
                'caracteristiques': caracteristiques,
                'etage': etage,
                'agence': await self.extract_agence(),
                'style_haussmannien': await self.extract_style_haussmannien()
            }
            
            # Ajouter l'analyse d'exposition contextuelle
            data['exposition'] = self.exposition_extractor.extract_exposition_ultimate(data)
            
            print(f"‚úÖ Appartement {apartment_id} scrap√©")
            return data
            
        except Exception as e:
            print(f"‚ùå Erreur scraping appartement {url}: {e}")
            return None
    
    def extract_apartment_id(self, url):
        """Extrait l'ID de l'appartement depuis l'URL"""
        match = re.search(r'ad=(\d+)', url)
        return match.group(1) if match else "unknown"
    
    async def extract_titre(self):
        """Extrait le titre de l'appartement"""
        try:
            # Chercher le titre dans diff√©rents s√©lecteurs possibles
            selectors = ['h1', '.title', '[data-testid="title"]', 'h2']
            for selector in selectors:
                element = self.page.locator(selector).first
                if await element.count() > 0:
                    text = await element.text_content()
                    if text and len(text.strip()) > 5:
                        return text.strip()
            return "Titre non trouv√©"
        except:
            return "Titre non trouv√©"
    
    async def extract_prix(self):
        """Extrait le prix principal"""
        try:
            # S√©lecteur pour le prix principal
            price_element = self.page.locator('.hmmXKG, [class*="price"], .price').first
            if await price_element.count() > 0:
                text = await price_element.text_content()
                # Nettoyer le prix
                price = re.search(r'[\d\s]+‚Ç¨', text or '')
                return price.group(0).strip() if price else "Prix non trouv√©"
            return "Prix non trouv√©"
        except:
            return "Prix non trouv√©"
    
    async def extract_prix_m2(self):
        """Extrait le prix au m¬≤"""
        try:
            # Chercher le prix au m¬≤ pr√®s du prix principal
            price_elements = self.page.locator('text=/‚Ç¨\/m¬≤/')
            if await price_elements.count() > 0:
                text = await price_elements.first.text_content()
                if text:
                    # Extraire et formater le prix au m¬≤
                    match = re.search(r'([\d\s]+)\s*‚Ç¨\s*/?\s*m¬≤', text, re.IGNORECASE)
                    if match:
                        prix_clean = match.group(1).strip().replace(' ', ' ')
                        return f"{prix_clean} ‚Ç¨ / m¬≤"
            return None
        except:
            return None
    
    async def extract_etage(self):
        """Extrait l'√©tage de la page d'appartement"""
        try:
            # Chercher d'abord dans les caract√©ristiques (section d√©di√©e)
            try:
                # Chercher la section caract√©ristiques avec plusieurs s√©lecteurs possibles
                caracteristiques_selectors = [
                    'h3:has-text("Caract√©ristiques")',
                    'h2:has-text("Caract√©ristiques")',
                    '[class*="caracteristiques"]',
                    '[class*="Caract√©ristiques"]',
                ]
                
                caracteristiques_text = ""
                for selector in caracteristiques_selectors:
                    try:
                        char_header = self.page.locator(selector)
                        if await char_header.count() > 0:
                            # R√©cup√©rer tout le contenu de la section caract√©ristiques
                            # Chercher le parent ou le conteneur suivant
                            parent_elem = char_header.locator('..')
                            if await parent_elem.count() > 0:
                                caracteristiques_text = await parent_elem.first.text_content() or ""
                            else:
                                # Chercher l'√©l√©ment suivant
                                next_elem = self.page.locator(f'{selector} + *')
                                if await next_elem.count() > 0:
                                    caracteristiques_text = await next_elem.first.text_content() or ""
                                else:
                                    # Chercher tous les √©l√©ments dans le m√™me conteneur
                                    char_section = self.page.locator(f'{selector}').locator('..')
                                    if await char_section.count() > 0:
                                        caracteristiques_text = await char_section.first.text_content() or ""
                            
                            if caracteristiques_text:
                                break
                    except:
                        continue
                
                # Si pas trouv√© avec les s√©lecteurs, chercher dans toute la page autour du titre "Caract√©ristiques"
                if not caracteristiques_text:
                    try:
                        # Chercher tous les √©l√©ments contenant "Caract√©ristiques"
                        all_text = await self.page.text_content('body') or ""
                        # Extraire la section apr√®s "Caract√©ristiques"
                        match = re.search(r'Caract√©ristiques[:\s]*(.*?)(?:\n\n|\n[A-Z]|$)', all_text, re.IGNORECASE | re.DOTALL)
                        if match:
                            caracteristiques_text = match.group(1)
                    except:
                        pass
                
                if caracteristiques_text:
                    # PRIORIT√â 1: Chercher RDC d'abord (car peut √™tre mal interpr√©t√© comme √©tage)
                    if re.search(r'\bRDC\b|rez-de-chauss√©e|rez de chauss√©e|rez-de-jardin', caracteristiques_text, re.IGNORECASE):
                        return "RDC"
                    
                    # Patterns pour trouver l'√©tage dans les caract√©ristiques (plus complets)
                    etage_patterns = [
                        r'(\d+)(?:er?|e|√®me?)\s*√©tage',
                        r'√©tage\s*(\d+)',
                        r'(\d+)(?:er?|e|√®me?)\s*√©t\.',
                        r'√âtage[:\s]+(\d+)',
                        r'√©tage[:\s]+(\d+)',
                        r'(\d+)\s*√©tage',  # Format simple "2 √©tage"
                        r'√©tage\s*:\s*(\d+)',  # Format "√©tage: 2"
                    ]
                    
                    for pattern in etage_patterns:
                        matches = re.findall(pattern, caracteristiques_text, re.IGNORECASE)
                        if matches:
                            etage_num = matches[0]
                            # V√©rifier le contexte pour √©viter les faux positifs (arrondissements)
                            match_obj = re.search(pattern, caracteristiques_text, re.IGNORECASE)
                            if match_obj:
                                start = max(0, match_obj.start() - 20)
                                end = min(len(caracteristiques_text), match_obj.end() + 20)
                                context = caracteristiques_text[start:end].lower()
                                # Exclure si c'est un arrondissement
                                if not any(word in context for word in ['arrondissement', 'arr.', 'arr ', 'paris']):
                                    if etage_num == '1':
                                        return "1er √©tage"
                                    else:
                                        return f"{etage_num}e √©tage"
            except Exception as e:
                print(f"  ‚ö†Ô∏è Erreur extraction √©tage depuis caract√©ristiques: {e}")
                pass  # Continuer si l'extraction depuis caract√©ristiques √©choue
            
            # Chercher dans toute la page si pas trouv√© dans caract√©ristiques
            page_content = await self.page.content()
            page_text = await self.page.text_content('body') or ""
            
            # PRIORIT√â 1: Chercher RDC d'abord (car peut √™tre mal interpr√©t√© comme √©tage)
            if re.search(r'\bRDC\b|rez-de-chauss√©e|rez de chauss√©e|rez-de-jardin', page_text, re.IGNORECASE):
                return "RDC"
            
            # Patterns pour trouver l'√©tage (plus robustes)
            # Priorit√© aux patterns avec "√©tage" explicite
            etage_patterns = [
                r'(\d+)(?:er?|e|√®me?)\s*√©tage',
                r'√©tage\s*(\d+)',
                r'(\d+)(?:er?|e|√®me?)\s*√©t\.',
                r'au\s+(\d+)(?:er?|e|√®me?)\s*√©tage',
                r'(\d+)(?:er?|e|√®me?)\s*√©tage\s*(?:avec|sans)',
                r'√©tage\s*:\s*(\d+)',
                r'(\d+)\s*√©tage',  # Format simple "2 √©tage"
            ]
            
            for pattern in etage_patterns:
                matches = re.findall(pattern, page_content, re.IGNORECASE)
                if matches:
                    etage_num = matches[0]
                    # V√©rifier le contexte pour √©viter les faux positifs (arrondissements)
                    match_obj = re.search(pattern, page_text, re.IGNORECASE)
                    if match_obj:
                        start = max(0, match_obj.start() - 30)
                        end = min(len(page_text), match_obj.end() + 30)
                        context = page_text[start:end].lower()
                        # Exclure si c'est un arrondissement ou une zone g√©ographique
                        if not any(word in context for word in ['arrondissement', 'arr.', 'arr ', 'paris', '750']):
                            # Formater comme "4e √©tage" ou "1er √©tage"
                            if etage_num == '1':
                                return "1er √©tage"
                            else:
                                return f"{etage_num}e √©tage"
            
            # Chercher les formats courts comme "2e" dans la section Caract√©ristiques uniquement
            # (pour √©viter les faux positifs comme "10e arrondissement")
            try:
                caracteristiques_elem = self.page.locator('h3:has-text("Caract√©ristiques"), h2:has-text("Caract√©ristiques")')
                if await caracteristiques_elem.count() > 0:
                    # R√©cup√©rer le conteneur de la section caract√©ristiques
                    char_container = caracteristiques_elem.first.locator('..')
                    char_text = await char_container.text_content() or ""
                    
                    # Patterns pour formats courts dans caract√©ristiques
                    short_patterns = [
                        r'(\d+)(?:er|e|√®me)(?:\s|,|\.|$)',  # Format "2e" suivi d'espace/ponctuation
                    ]
                    
                    for pattern in short_patterns:
                        matches = re.findall(pattern, char_text, re.IGNORECASE)
                        if matches:
                            # Prendre le premier match qui est probablement l'√©tage
                            # Les caract√©ristiques listent g√©n√©ralement: pi√®ces, √©tage, exposition, etc.
                            for match in matches[:3]:  # V√©rifier les 3 premiers matches au cas o√π
                                etage_num = match if isinstance(match, str) else str(match)
                                # V√©rifier le contexte autour pour confirmer
                                match_obj = re.search(re.escape(etage_num) + r'(?:er|e|√®me)?', char_text, re.IGNORECASE)
                                if match_obj:
                                    start = max(0, match_obj.start() - 30)
                                    end = min(len(char_text), match_obj.end() + 30)
                                    context = char_text[start:end].lower()
                                    # Si le contexte sugg√®re un √©tage (pas un arrondissement ou autre)
                                    if any(word in context for word in ['√©tage', '√©t.', '√©t', 'ascenseur', 'rdc', 'rez']):
                                        # √âviter les faux positifs comme "10e arrondissement", "Paris 20e", "75020"
                                        if not any(word in context for word in ['arrondissement', 'arr.', 'arr ', 'paris', '750']):
                                            # Exclure les grands nombres qui sont probablement des arrondissements
                                            if int(etage_num) <= 10:  # Les √©tages normaux sont <= 10
                                                if etage_num == '1':
                                                    return "1er √©tage"
                                                else:
                                                    return f"{etage_num}e √©tage"
            except:
                pass
            
            # Chercher RDC (dernier recours)
            if re.search(r'\bRDC\b|rez-de-chauss√©e|rez de chauss√©e|rez-de-jardin', page_text, re.IGNORECASE):
                return "RDC"
            
            return None
        except Exception as e:
            print(f"  ‚ö†Ô∏è Erreur extraction √©tage: {e}")
            return None
    
    async def extract_style_for_photo(self):
        """Extrait le style de l'appartement pour la description de photo"""
        try:
            page_text = await self.page.text_content('body') or ""
            
            # Chercher des indices de style haussmannien
            style_keywords = {
                'haussmannien': 'Haussmannien',
                'haussmann': 'Haussmannien',
                'moulures': 'Haussmannien',
                'parquet': 'Haussmannien',
                'chemin√©e': 'Haussmannien',
                'restaur√©': 'Haussmannien',
                'contemporain': 'Contemporain',
                'moderne': 'Moderne',
                'ancien': 'Ancien',
                'neuf': 'Neuf'
            }
            
            for keyword, style in style_keywords.items():
                if re.search(keyword, page_text, re.IGNORECASE):
                    return style
            
            return "Style Inconnu"
        except Exception as e:
            print(f"  ‚ö†Ô∏è Erreur extraction style: {e}")
            return "Style Inconnu"
    
    def format_photo_description(self, surface=None, prix_m2=None, etage=None, style=None):
        """Formate la description de photo au format: 70 m¬≤ ¬∑ 3e √©tage ¬∑ Style Inconnu"""
        parts = []
        
        if surface:
            parts.append(surface)
        # Prix au m¬≤ masqu√© pour simplifier
        # if prix_m2:
        #     parts.append(prix_m2)
        if etage:
            parts.append(etage)
        if style:
            parts.append(style)
        
        return " ¬∑ ".join(parts) if parts else "Appartement"
    
    async def extract_localisation(self):
        """Extrait la localisation (adresse exacte si possible)"""
        try:
            # R√©cup√©rer tout le contenu de la page
            page_text = await self.page.text_content('body')
            
            # Chercher l'adresse exacte avec diff√©rents patterns
            address_patterns = [
                r'(\d+[,\s]*[a-zA-Z\s]*[Rr]ue[^,\n]*)',
                r'(\d+[,\s]*[a-zA-Z\s]*[Aa]venue[^,\n]*)',
                r'(\d+[,\s]*[a-zA-Z\s]*[Bb]oulevard[^,\n]*)',
                r'(\d+[,\s]*[a-zA-Z\s]*[Pp]lace[^,\n]*)',
                r'(\d+[,\s]*[a-zA-Z\s]*[Cc]ours[^,\n]*)',
                r'(\d+[,\s]*[a-zA-Z\s]*[Vv]illa[^,\n]*)',
                r'(\d+[,\s]*[a-zA-Z\s]*[Ii]mpasse[^,\n]*)',
                r'(\d+[,\s]*[a-zA-Z\s]*[Aa]ll√©e[^,\n]*)',
                r'(\d+[,\s]*[a-zA-Z\s]*[Pp]assage[^,\n]*)',
                r'(\d+[,\s]*[a-zA-Z\s]*[Cc]hemin[^,\n]*)'
            ]
            
            adresses_trouvees = []
            for pattern in address_patterns:
                matches = re.findall(pattern, page_text, re.IGNORECASE)
                for match in matches:
                    # Nettoyer l'adresse
                    clean_addr = re.sub(r'\s+', ' ', match.strip())
                    if len(clean_addr) > 5 and clean_addr not in adresses_trouvees:
                        adresses_trouvees.append(clean_addr)
            
            if adresses_trouvees:
                return adresses_trouvees[0]  # Retourner la premi√®re adresse trouv√©e
            
            # Fallback 1: chercher juste l'arrondissement
            selectors = ['text=/Paris \d+e/', 'text=/750\d+/', '[class*="location"]']
            for selector in selectors:
                element = self.page.locator(selector).first
                if await element.count() > 0:
                    text = await element.text_content()
                    if text and 'Paris' in text:
                        return text.strip()
            
            # Fallback 2: utiliser les stations de m√©tro comme localisation
            try:
                transports = await self.extract_transports()
                if transports:
                    # Prendre les 2 premi√®res stations comme localisation
                    stations_str = ", ".join(transports[:2])
                    return f"Proche de {stations_str}"
            except Exception as e:
                print(f"  ‚ö†Ô∏è Erreur fallback stations: {e}")
            
            return "Localisation non trouv√©e"
        except:
            return "Localisation non trouv√©e"
    
    async def extract_surface(self):
        """Extrait la surface"""
        try:
            # Chercher la surface dans diff√©rents formats
            surface_elements = self.page.locator('text=/\\d+\\s*m¬≤/')
            if await surface_elements.count() > 0:
                text = await surface_elements.first.text_content()
                if text:
                    # Extraire juste la partie "XX m¬≤"
                    match = re.search(r'(\d+(?:[.,]\d+)?)\s*m¬≤', text, re.IGNORECASE)
                    if match:
                        # Arrondir si d√©cimal et formater
                        surface_val = match.group(1).replace(',', '.')
                        try:
                            surface_num = float(surface_val)
                            return f"{int(surface_num)} m¬≤" if surface_num == int(surface_num) else f"{surface_num:.1f} m¬≤"
                        except:
                            return f"{match.group(1)} m¬≤"
            return None
        except:
            return None
    
    async def extract_pieces(self):
        """Extrait le nombre de pi√®ces"""
        try:
            # Chercher les pi√®ces dans diff√©rents formats
            pieces_elements = self.page.locator('text=/\d+\s*pi√®ces?/')
            if await pieces_elements.count() > 0:
                text = await pieces_elements.first.text_content()
                return text.strip() if text else "Pi√®ces non trouv√©es"
            return "Pi√®ces non trouv√©es"
        except:
            return "Pi√®ces non trouv√©es"
    
    async def extract_date(self):
        """Extrait la date de publication"""
        try:
            # Chercher la date
            date_elements = self.page.locator('text=/le \d+ \w+ √†/')
            if await date_elements.count() > 0:
                text = await date_elements.first.text_content()
                return text.strip() if text else "Date non trouv√©e"
            return "Date non trouv√©e"
        except:
            return "Date non trouv√©e"
    
    async def extract_transports(self):
        """Extrait les transports proches (stations de m√©tro)"""
        try:
            transports = []
            
            # M√©thode 1: Chercher la section "Proche des stations"
            try:
                # Chercher la div qui contient "Proche des stations"
                stations_div = self.page.locator('div.fz-16.sc-bdVaJa.bDXQKW:has(h3:has-text("Proche des stations"))')
                if await stations_div.count() > 0:
                    # Chercher tous les spans dans les li de la liste ul
                    station_spans = stations_div.locator('ul li span')
                    station_count = await station_spans.count()
                    
                    if station_count > 0:
                        for i in range(station_count):
                            station_text = await station_spans.nth(i).text_content()
                            if station_text and len(station_text.strip()) > 2:
                                transports.append(station_text.strip())
                    else:
                        # Fallback: utiliser les li directement
                        station_lis = stations_div.locator('ul li')
                        li_count = await station_lis.count()
                        for i in range(li_count):
                            station_text = await station_lis.nth(i).text_content()
                            if station_text:
                                # Nettoyer le texte (enlever les num√©ros de ligne)
                                station_name = re.sub(r'\s+\d+\s*$', '', station_text.strip())
                                if station_name and len(station_name) > 2:
                                    transports.append(station_name)
            except Exception as e:
                print(f"  ‚ö†Ô∏è Erreur extraction section stations: {e}")
            
            # M√©thode 2: Chercher les images de m√©tro et extraire les noms
            try:
                metro_images = await self.page.locator('img[src*="subway"], img[alt*="metro"]').all()
                for img in metro_images:
                    # Chercher le texte de la station dans le m√™me conteneur
                    parent = img.locator('..')
                    station_text = await parent.text_content()
                    if station_text:
                        # Extraire le nom de la station (avant les ic√¥nes)
                        station_name = re.split(r'\s+\d+\s*', station_text)[0].strip()
                        if station_name and len(station_name) > 2 and station_name not in transports:
                            transports.append(station_name)
            except Exception as e:
                print(f"  ‚ö†Ô∏è Erreur extraction images m√©tro: {e}")
            
            # M√©thode 3: Fallback - chercher les patterns de stations
            if not transports:
                try:
                    transport_elements = self.page.locator('text=/[A-Za-z]+\s+\d+/')
                    for i in range(await transport_elements.count()):
                        text = await transport_elements.nth(i).text_content()
                        if text and re.match(r'[A-Za-z]+\s+\d+', text.strip()):
                            transports.append(text.strip())
                except Exception as e:
                    print(f"  ‚ö†Ô∏è Erreur extraction fallback: {e}")
            
            # Nettoyer et d√©dupliquer
            transports = list(dict.fromkeys(transports))  # Supprimer les doublons
            return transports[:10]  # Limiter √† 10 transports
            
        except Exception as e:
            print(f"  ‚ö†Ô∏è Erreur extraction transports: {e}")
            return []
    
    async def extract_description(self):
        """Extrait la description d√©taill√©e"""
        try:
            # Essayer diff√©rents s√©lecteurs pour la description
            description_selectors = [
                '.fz-16.sc-bxivhb.fcnykg',
                '[class*="description"]',
                'p:has-text("Globalstone")',
                'text=/Globalstone/',
                'div:has-text("Globalstone")',
                'section:has-text("Globalstone")'
            ]
            
            for selector in description_selectors:
                try:
                    element = self.page.locator(selector).first
                    if await element.count() > 0:
                        text = await element.text_content()
                        if text and len(text.strip()) > 50:  # S'assurer qu'on a une vraie description
                            return text.strip()
                except:
                    continue
            
            return "Description non trouv√©e"
        except:
            return "Description non trouv√©e"
    
    async def extract_map_info(self, apartment_id=None):
        """Extrait les informations de la carte (rues, quartier, m√©tros)"""
        try:
            print("   üó∫Ô∏è Analyse de la carte...")
            
            # Initialiser screenshot_path
            screenshot_path = None
            
            # Prendre un screenshot de la carte pour analyse
            map_element = self.page.locator('.leaflet-container, [class*="map"], [class*="carte"]').first
            if await map_element.count() > 0:
                # Attendre que la carte se charge compl√®tement pour cet appartement
                # Attendre que les tuiles de la carte soient charg√©es
                await self.page.wait_for_timeout(1000)
                
                # Attendre que la carte soit visible et charg√©e
                try:
                    await map_element.wait_for(state='visible', timeout=5000)
                except:
                    pass
                
                # Attendre un peu plus pour que la carte se centre sur l'appartement
                await self.page.wait_for_timeout(2000)
                
                # Scroller vers la carte pour s'assurer qu'elle est visible
                try:
                    await map_element.scroll_into_view_if_needed()
                    await self.page.wait_for_timeout(1000)
                except:
                    pass
                
                # Prendre un screenshot de la carte avec l'ID de l'appartement dans le nom
                if apartment_id:
                    screenshot_path = f"data/screenshots/map_{apartment_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
                else:
                    screenshot_path = f"data/screenshots/map_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
                os.makedirs("data/screenshots", exist_ok=True)
                await map_element.screenshot(path=screenshot_path)
                print(f"   üì∏ Screenshot de la carte sauvegard√©: {screenshot_path}")
            
            # Extraire le texte visible sur la carte
            map_text = ""
            try:
                map_text = await map_element.text_content()
            except:
                pass
            
            # Chercher des noms de rues dans le contenu de la page
            page_content = await self.page.text_content('body')
            
            # Patterns pour identifier les rues et quartiers
            street_patterns = [
                r'Rue\s+[A-Za-z\s\-\']+',
                r'Avenue\s+[A-Za-z\s\-\']+',
                r'Boulevard\s+[A-Za-z\s\-\']+',
                r'Place\s+[A-Za-z\s\-\']+',
                r'Cours\s+[A-Za-z\s\-\']+',
                r'Villa\s+[A-Za-z\s\-\']+',
                r'Impasse\s+[A-Za-z\s\-\']+',
                r'All√©e\s+[A-Za-z\s\-\']+',
                r'Passage\s+[A-Za-z\s\-\']+',
                r'Chemin\s+[A-Za-z\s\-\']+'
            ]
            
            metro_patterns = [
                r'[A-Za-z\s\-\']+\s*\(m√©tro\)',
                r'Station\s+[A-Za-z\s\-\']+',
                r'M√©tro\s+[A-Za-z\s\-\']+'
            ]
            
            # Extraire les rues
            streets_found = []
            for pattern in street_patterns:
                matches = re.findall(pattern, page_content, re.IGNORECASE)
                for match in matches:
                    clean_street = re.sub(r'\s+', ' ', match.strip())
                    if len(clean_street) > 5 and clean_street not in streets_found:
                        streets_found.append(clean_street)
            
            # Extraire les m√©tros
            metros_found = []
            for pattern in metro_patterns:
                matches = re.findall(pattern, page_content, re.IGNORECASE)
                for match in matches:
                    clean_metro = re.sub(r'\s+', ' ', match.strip())
                    if len(clean_metro) > 3 and clean_metro not in metros_found:
                        metros_found.append(clean_metro)
            
            # Identifier le quartier bas√© sur les rues trouv√©es
            quartier = self.identify_quartier(streets_found, metros_found)
            
            map_info = {
                "streets": streets_found[:10],  # Limiter √† 10 rues
                "metros": metros_found[:5],     # Limiter √† 5 m√©tros
                "quartier": quartier,
                "screenshot": screenshot_path if 'screenshot_path' in locals() else None
            }
            
            print(f"   üèòÔ∏è Quartier identifi√©: {quartier}")
            print(f"   üõ£Ô∏è Rues trouv√©es: {len(streets_found)}")
            print(f"   üöá M√©tros trouv√©s: {len(metros_found)}")
            
            return map_info
            
        except Exception as e:
            print(f"   ‚ùå Erreur analyse carte: {e}")
            return {"streets": [], "metros": [], "quartier": "Non identifi√©", "error": str(e)}
    
    def identify_quartier(self, streets, metros):
        """Identifie le quartier bas√© sur les rues et m√©tros trouv√©s - TOUS les arrondissements"""
        # Quartiers du 19e avec leurs rues caract√©ristiques
        quartiers_19e = {
            "Buttes-Chaumont": ["Rue Botzaris", "Avenue Secr√©tan", "Rue Manin", "Rue de Crim√©e", "Botzaris", "Secr√©tan", "Manin", "Crim√©e"],
            "Place des F√™tes": ["Rue Carducci", "Rue M√©lingue", "Rue des Alouettes", "Rue de la Villette", "Carducci", "M√©lingue", "Alouettes", "Villette"],
            "Jourdain": ["Rue de Belleville", "Rue Pelleport", "Rue de Mouza√Øa", "Rue Compans", "Belleville", "Pelleport", "Mouza√Øa", "Compans"],
            "Pyr√©n√©es": ["Rue Pradier", "Rue Clavel", "Rue R√©beval", "Rue Levert", "Pradier", "Clavel", "R√©beval", "Levert"],
            "Belleville": ["Rue de Belleville", "Rue du Faubourg du Temple", "Boulevard de la Villette", "Belleville", "Faubourg du Temple", "Villette"],
            "Canal de l'Ourcq": ["Quai de la Loire", "Quai de la Seine", "Rue de l'Ourcq", "Loire", "Seine", "Ourcq"]
        }
        
        # Quartiers du 20e avec leurs rues caract√©ristiques
        quartiers_20e = {
            "M√©nilmontant": ["Rue de M√©nilmontant", "Rue Oberkampf", "Rue de la Folie-M√©ricourt", "Rue de la Roquette", "M√©nilmontant", "Oberkampf", "Folie-M√©ricourt", "Roquette"],
            "P√®re-Lachaise": ["Rue de la Roquette", "Rue de M√©nilmontant", "Rue du Repos", "Rue des Pyr√©n√©es", "Rue P√®re-Lachaise", "Roquette", "Repos", "P√®re-Lachaise"],
            "Belleville (20e)": ["Rue de Belleville", "Rue des Pyr√©n√©es", "Rue de M√©nilmontant", "Belleville", "Pyr√©n√©es"],
            "Charonne": ["Rue de Charonne", "Rue du Faubourg Saint-Antoine", "Charonne", "Faubourg Saint-Antoine"],
            "Gambetta": ["Place Gambetta", "Rue des Pyr√©n√©es", "Avenue Gambetta", "Gambetta"]
        }
        
        # Quartiers du 11e avec leurs rues caract√©ristiques
        quartiers_11e = {
            "Goncourt": ["Rue Oberkampf", "Rue de la Folie-M√©ricourt", "Rue Jean-Pierre Timbaud", "Oberkampf", "Folie-M√©ricourt", "Timbaud"],
            "R√©publique": ["Place de la R√©publique", "Boulevard Voltaire", "Rue du Faubourg du Temple", "R√©publique", "Voltaire"],
            "Nation": ["Place de la Nation", "Avenue du Tr√¥ne", "Rue du Faubourg Saint-Antoine", "Nation", "Tr√¥ne"],
            "Bastille": ["Place de la Bastille", "Rue de la Roquette", "Boulevard Richard-Lenoir", "Bastille", "Roquette", "Richard-Lenoir"]
        }
        
        # Quartiers du 10e avec leurs rues caract√©ristiques
        quartiers_10e = {
            "Rue des Boulets": ["Rue des Boulets", "Rue de Montreuil", "Boulets", "Montreuil"],
            "Gare du Nord": ["Rue du Faubourg Saint-Denis", "Boulevard de Magenta", "Faubourg Saint-Denis", "Magenta"],
            "Canal Saint-Martin": ["Quai de Valmy", "Quai de Jemmapes", "Rue du Faubourg du Temple", "Valmy", "Jemmapes"]
        }
        
        # Combiner tous les quartiers
        all_quartiers = {}
        all_quartiers.update(quartiers_19e)
        all_quartiers.update(quartiers_20e)
        all_quartiers.update(quartiers_11e)
        all_quartiers.update(quartiers_10e)
        
        # M√©tros caract√©ristiques par quartier
        metros_quartiers = {
            "Place des F√™tes": ["Place des F√™tes", "Place des Fetes"],
            "Jourdain": ["Jourdain"],
            "Pyr√©n√©es": ["Pyr√©n√©es", "Pyrenees"],
            "Buttes-Chaumont": ["Botzaris", "Crim√©e"],
            "Belleville": ["Belleville", "Couronnes"],
            "M√©nilmontant": ["M√©nilmontant", "P√®re-Lachaise", "Gambetta", "Philippe-Auguste"],
            "P√®re-Lachaise": ["P√®re-Lachaise", "Gambetta", "Philippe-Auguste", "M√©nilmontant"],
            "Goncourt": ["Goncourt", "Parmentier", "R√©publique"],
            "R√©publique": ["R√©publique", "Goncourt", "Parmentier"],
            "Nation": ["Nation", "Faidherbe-Chaligny"],
            "Bastille": ["Bastille", "Ledru-Rollin", "Br√©guet-Sabin"],
            "Rue des Boulets": ["Rue des Boulets", "Nation", "Faidherbe-Chaligny"]
        }
        
        # Compter les correspondances
        quartier_scores = {}
        
        # Score bas√© sur les rues
        for quartier, rues_quartier in all_quartiers.items():
            score = 0
            for rue in streets:
                for rue_quartier in rues_quartier:
                    if rue_quartier.lower() in rue.lower():
                        score += 1
            quartier_scores[quartier] = score
        
        # Ajouter les scores des m√©tros (score plus √©lev√© car plus fiable)
        for quartier, metros_quartier in metros_quartiers.items():
            for metro in metros:
                for metro_quartier in metros_quartier:
                    if metro_quartier.lower() in metro.lower():
                        quartier_scores[quartier] = quartier_scores.get(quartier, 0) + 2
        
        # Retourner le quartier avec le plus haut score
        if quartier_scores:
            best_quartier = max(quartier_scores, key=quartier_scores.get)
            if quartier_scores[best_quartier] > 0:
                return f"{best_quartier} (score: {quartier_scores[best_quartier]})"
        
        return "Quartier non identifi√©"
    
    def analyze_screenshot_for_quartier(self, screenshot_path):
        """Analyse le screenshot pour identifier le quartier (m√©thode basique)"""
        try:
            if not os.path.exists(screenshot_path):
                return "Screenshot non trouv√©"
            
            # Pour l'instant, on retourne une analyse bas√©e sur la description
            # Dans une version avanc√©e, on pourrait utiliser OCR ou vision par ordinateur
            return "Analyse manuelle requise - voir screenshot"
            
        except Exception as e:
            return f"Erreur analyse: {e}"
    
    async def extract_coordinates(self):
        """Extrait les coordonn√©es GPS depuis la carte Leaflet"""
        try:
            # Chercher les √©l√©ments de la carte Leaflet avec diff√©rents s√©lecteurs
            leaflet_selectors = [
                '.leaflet-proxy',
                '.leaflet-map-pane', 
                '.leaflet-container',
                '[class*="leaflet"]'
            ]
            
            coordinates = None
            for selector in leaflet_selectors:
                elements = self.page.locator(selector)
                count = await elements.count()
                
                for i in range(count):
                    element = elements.nth(i)
                    style = await element.get_attribute('style')
                    
                    if style and 'translate3d' in style:
                        print(f"   üîç Style trouv√©: {style[:100]}...")
                        
                        # Extraire les coordonn√©es du transform avec regex plus robuste
                        import re
                        patterns = [
                            r'translate3d\(([^,]+),\s*([^,]+),\s*([^)]+)\)',
                            r'translate3d\(([^,]+),\s*([^,]+),\s*([^)]+)\)',
                            r'transform:\s*translate3d\(([^,]+),\s*([^,]+),\s*([^)]+)\)'
                        ]
                        
                        for pattern in patterns:
                            match = re.search(pattern, style)
                            if match:
                                try:
                                    x_str = match.group(1).strip()
                                    y_str = match.group(2).strip()
                                    scale_str = match.group(3).strip()
                                    
                                    print(f"   üìç Coordonn√©es brutes: x={x_str}, y={y_str}, scale={scale_str}")
                                    
                                    # Nettoyer et convertir les valeurs
                                    x = float(x_str.replace('px', '').replace('e+', 'e'))
                                    y = float(y_str.replace('px', '').replace('e+', 'e'))
                                    scale = float(scale_str.replace('px', '')) if scale_str != '0px' else 1.0
                                    
                                    # V√©rifier que les valeurs sont valides (pas 0)
                                    if abs(x) > 1000 and abs(y) > 1000:  # Coordonn√©es Web Mercator valides
                                        # Convertir les coordonn√©es Web Mercator en lat/lng
                                        lon = (x / 20037508.34) * 180
                                        lat = (y / 20037508.34) * 180
                                        lat = 180 / 3.14159265359 * (2 * math.atan(math.exp(lat * 3.14159265359 / 180)) - 3.14159265359 / 2)
                                        
                                        coordinates = {
                                            "latitude": round(lat, 6),
                                            "longitude": round(lon, 6),
                                            "raw_x": x,
                                            "raw_y": y,
                                            "scale": scale
                                        }
                                        print(f"   ‚úÖ Coordonn√©es converties: {lat:.6f}, {lon:.6f}")
                                        break
                                    else:
                                        print(f"   ‚ö†Ô∏è Coordonn√©es invalides (trop petites): x={x}, y={y}")
                                        
                                except ValueError as ve:
                                    print(f"   ‚ùå Erreur de conversion: {ve}")
                                    continue
                        
                        if coordinates:
                            break
                
                if coordinates:
                    break
            
            if not coordinates:
                print("   ‚ùå Aucune coordonn√©e valide trouv√©e")
                return {"latitude": None, "longitude": None, "error": "No valid coordinates found"}
            
            return coordinates
            
        except Exception as e:
            print(f"   ‚ùå Erreur g√©n√©rale: {e}")
            return {"latitude": None, "longitude": None, "error": str(e)}
    
    async def extract_style_haussmannien(self):
        """Extrait les √©l√©ments de style haussmannien"""
        try:
            # R√©cup√©rer la description
            description = await self.extract_description()
            if description == "Description non trouv√©e":
                return {"score": 0, "elements": [], "keywords": []}
            
            # Mots-cl√©s haussmanniens √©tendus
            haussmann_keywords = {
                'architectural': [
                    'haussmannien', 'haussmannienne', 'haussmann',
                    'moulures', 'moulure', 'moulur√©', 'moulur√©e',
                    'chemin√©e', 'chemin√©es', 'chemin√©e de marbre',
                    'parquet', 'parquets', 'parquet d\'origine', 'parquet ancien',
                    'corniches', 'corniche', 'corniche moulur√©e',
                    'rosaces', 'rosace', 'rosace de plafond',
                    'balcon', 'balcons', 'balcon en fer forg√©', 'balcon forg√©',
                    'fer forg√©', 'fer forg√©e', 'grille en fer forg√©',
                    'hauteur sous plafond', 'haut plafond', 'plafond haut',
                    'escalier', 'escaliers', 'escalier d\'honneur'
                ],
                'caract√®re': [
                    'caract√®re', 'caract√®res', 'caract√©ristique',
                    'restaur√©', 'restaur√©e', 'r√©nov√©', 'r√©nov√©e',
                    'authentique', 'authentiques', 'original', 'originale',
                    '√©poque', 'p√©riode', '√©poque haussmannienne',
                    'ancien', 'ancienne', 'ancien immeuble',
                    'vieux', 'vieille', 'vieux immeuble',
                    'charme', 'charmant', 'charmante',
                    'prestige', 'prestigieux', 'prestigieuse',
                    'noble', 'noblesse', 'noblesse des mat√©riaux'
                ],
                'mat√©riaux': [
                    'marbre', 'marbres', 'marbre de carrare',
                    'bois', 'bois noble', 'bois pr√©cieux',
                    'pierre', 'pierres', 'pierre de taille',
                    'stuc', 'stucs', 'stuc d√©coratif',
                    'pl√¢tre', 'pl√¢tres', 'pl√¢tre moul√©',
                    'm√©tal', 'm√©taux', 'm√©tal forg√©'
                ],
                'd√©tails': [
                    'moulure', 'moulures', 'moulure de plafond',
                    'd√©coration', 'd√©coratif', 'd√©corative',
                    'ornement', 'ornements', 'ornemental',
                    'd√©tail', 'd√©tails', 'd√©tail architectural',
                    'finesse', 'finesses', 'finitions',
                    '√©l√©gance', '√©l√©gant', '√©l√©gante'
                ]
            }
            
            # Chercher les mots-cl√©s par cat√©gorie
            found_by_category = {}
            total_found = 0
            all_keywords = []
            
            for category, keywords in haussmann_keywords.items():
                found_in_category = []
                for keyword in keywords:
                    if keyword.lower() in description.lower():
                        found_in_category.append(keyword)
                        all_keywords.append(keyword)
                        total_found += 1
                
                if found_in_category:
                    found_by_category[category] = found_in_category
            
            # Calculer un score de style
            style_score = min(100, (total_found * 10) + 20)  # 10 points par mot-cl√© + 20 de base
            
            return {
                "score": style_score,
                "elements": found_by_category,
                "keywords": all_keywords,
                "total_found": total_found
            }
            
        except Exception as e:
            return {"score": 0, "elements": [], "keywords": [], "error": str(e)}
    
    async def extract_photos(self):
        """Extrait les URLs des photos d'appartement depuis la div sp√©cifique"""
        try:
            print("   üì∏ Extraction des photos d'appartement...")
            
            # Extraire les informations pour la description des photos
            etage = await self.extract_etage()
            surface = await self.extract_surface()
            prix_m2 = await self.extract_prix_m2()
            style = await self.extract_style_for_photo()
            
            if etage:
                print(f"      üè¢ √âtage trouv√©: {etage}")
            if surface:
                print(f"      üìê Surface trouv√©e: {surface}")
            if prix_m2:
                print(f"      üí∞ Prix au m¬≤ trouv√©: {prix_m2}")
            if style:
                print(f"      üé® Style trouv√©: {style}")
            
            photos = []
            
            # Attendre un peu plus longtemps pour le chargement des images lazy
            await asyncio.sleep(1)
            
            # Scroller un peu pour d√©clencher le chargement lazy si n√©cessaire
            await self.page.evaluate('window.scrollTo(0, 200)')
            await asyncio.sleep(0.5)
            await self.page.evaluate('window.scrollTo(0, 0)')
            await asyncio.sleep(0.5)
            
            # M√©thode 1: Cibler la div galerie principale (sc-cJSrbW juBoVb ou sc-gPEVay jnWxBz)
            # Aussi chercher dans les divs cach√©es avec display="none" qui contiennent toutes les photos
            gallery_selectors = [
                'div.sc-cJSrbW.juBoVb',  # Structure actuelle visible dans l'image
                'div.sc-gPEVay.jnWxBz',  # Ancienne structure
                '[class*="sc-cJSrbW"][class*="juBoVb"]',  # S√©lecteurs partiels
                '[class*="sc-gPEVay"][class*="jnWxBz"]',
                'div.sc-bdVaJa.InsofV',  # Div cach√©e avec toutes les photos (display="none")
                '[class*="sc-bdVaJa"][class*="InsofV"]',  # S√©lecteur partiel
                'div[style*="display: none"]',  # Toute div cach√©e
            ]
            
            gallery_found = False
            for selector in gallery_selectors:
                try:
                    gallery_div = self.page.locator(selector)
                    if await gallery_div.count() > 0:
                        print(f"      üéØ Div galerie trouv√©e ({selector}), extraction des images visibles...")
                        gallery_found = True
                        
                        # Extraire toutes les images de la galerie (visibles ET cach√©es avec preloader)
                        gallery_element = await gallery_div.first.element_handle()
                        img_elements = await gallery_element.evaluate('''
                            el => {
                                // Obtenir toutes les images dans l'ordre exact du DOM (m√™me cach√©es)
                                const allImgs = Array.from(el.querySelectorAll('img'));
                                
                                // Extraire les infos avec position visuelle pour tri correct
                                return allImgs.map((img, domIndex) => {
                                    const rect = img.getBoundingClientRect();
                                    const computedStyle = window.getComputedStyle(img);
                                    return {
                                        domIndex: domIndex,  // Index dans le DOM
                                        src: img.src || img.getAttribute('data-src') || img.getAttribute('data-lazy-src') || '',
                                        alt: img.alt || '',
                                        width: img.naturalWidth || img.width || 0,
                                        height: img.naturalHeight || img.height || 0,
                                        display: computedStyle.display,
                                        visibility: computedStyle.visibility,
                                        top: rect.top,  // Position top pour tri visuel
                                        left: rect.left  // Position left pour tri visuel
                                    };
                                }).filter(img => {
                                    // Garder toutes les images avec une URL valide
                                    if (!img.src) return false;
                                    
                                    const srcLower = img.src.toLowerCase();
                                    const altLower = img.alt.toLowerCase();
                                    
                                    // V√©rifier si l'image est visible (pas display:none et position non-0,0)
                                    const isVisible = img.display !== 'none' && (img.top !== 0 || img.left !== 0);
                                    const hasGoodDimensions = img.width > 200 && img.height > 200;
                                    
                                    // 1. Exclure les placeholders explicites (toujours)
                                    if (srcLower.includes('placeholder')) return false;
                                    
                                    // 2. LOGIQUE AM√âLIOR√âE : Accepter les images VISIBLES m√™me si FNAIM
                                    // Si l'image est visible ET a de bonnes dimensions, c'est probablement une vraie photo
                                    if (isVisible && hasGoodDimensions) {
                                        // Accepter les images visibles m√™me si elles utilisent FNAIM
                                        // Car elles sont affich√©es sur la page
                                        return true;
                                    }
                                    
                                    // 3. Pour les images cach√©es ou petites, filtrer les placeholders FNAIM
                                    const placeholderUrlPatterns = [
                                        'imagesv2.fnaim.fr/images1/img/',  // Placeholder FNAIM
                                        'placeholder',
                                        'placeholder.jpg',
                                        'placeholder.png',
                                        'no-image',
                                        'default-image',
                                        'missing-image',
                                    ];
                                    const isPlaceholderUrl = placeholderUrlPatterns.some(pattern => srcLower.includes(pattern));
                                    if (isPlaceholderUrl && !isVisible) {
                                        // Si c'est un placeholder ET que l'image n'est pas visible, exclure
                                        return false;
                                    }
                                    
                                    // 4. Exclure les images avec alt="preloader" SI cach√©es ET placeholder FNAIM
                                    if ((altLower.includes('preloader') || altLower === 'preloader') && 
                                        srcLower.includes('imagesv2.fnaim.fr/images1/img/') && 
                                        !isVisible) {
                                        return false;
                                    }
                                    
                                    // 5. D√©tecter les vraies photos d'appartements (patterns √©tendus)
                                    const photoPatterns = [
                                        'loueragile', 
                                        'upload_pro_ad', 
                                        'media.apimo.pro', 
                                        'studio-net.fr', 
                                        'images.century21.fr', 
                                        'biens', 
                                        'apartement', 
                                        'transopera', 
                                        'staticlbi', 
                                        'uploadcaregdc', 
                                        'uploadcare', 
                                        's3.amazonaws.com', 
                                        'googleusercontent.com', 
                                        'cdn.safti.fr', 
                                        'safti.fr', 
                                        'paruvendu.fr', 
                                        'immo-facile.com', 
                                        'mms.seloger.com', 
                                        'seloger.com',
                                        'api.jinka.fr/apiv2/media/imgsrv',  // Proxy Jinka pour vraies photos
                                        'photos.ubif',  // Photos originales via proxy Jinka
                                        'res.cloudinary.com',  // Cloudinary (souvent utilis√© pour photos immo)
                                        'cloudinary.com',
                                        'photos.',  // Pattern g√©n√©rique pour photos (mais pas "placeholder")
                                        'imagesv2.fnaim.fr',  // Accepter FNAIM si image visible avec bonnes dimensions
                                    ];
                                    const hasValidPhotoPattern = photoPatterns.some(pattern => srcLower.includes(pattern));
                                    
                                    // 6. Si c'est une vraie photo (pattern valide), on la garde
                                    // OU si c'est une image visible avec bonnes dimensions (m√™me FNAIM)
                                    if (hasValidPhotoPattern || (isVisible && hasGoodDimensions)) {
                                        return true;
                                    }
                                    
                                    return false;
                                });
                            }
                        ''')
                        
                        # Extraire les photos avec leur index DOM pour pr√©server l'ordre de Jinka
                        photos_with_position = []
                        for img_data in img_elements:
                            try:
                                src_to_use = img_data.get('src', '')
                                if not src_to_use:
                                    continue
                                
                                # V√©rifier que c'est une vraie photo (pas un logo)
                                src_lower = src_to_use.lower()
                                alt_lower = img_data.get('alt', '').lower()
                                
                                if 'logo' in src_lower or 'source_logos' in src_lower:
                                    continue
                                
                                # V√©rifier si l'image est visible (position non-0,0 et bonnes dimensions)
                                position_top = img_data.get('position_top', 0)
                                position_left = img_data.get('position_left', 0)
                                width = img_data.get('width', 0)
                                height = img_data.get('height', 0)
                                is_visible = (position_top != 0 or position_left != 0)
                                has_good_dimensions = width > 200 and height > 200
                                
                                # LOGIQUE AM√âLIOR√âE : Accepter les images VISIBLES m√™me si FNAIM
                                # Si l'image est visible ET a de bonnes dimensions, c'est probablement une vraie photo
                                if is_visible and has_good_dimensions:
                                    # Accepter les images visibles m√™me si elles utilisent FNAIM
                                    # Car elles sont affich√©es sur la page
                                    pass  # Continuer pour ajouter la photo
                                else:
                                    # Pour les images cach√©es ou petites, filtrer les placeholders FNAIM
                                    placeholder_patterns = [
                                        'imagesv2.fnaim.fr/images1/img/',  # Placeholder FNAIM
                                        'placeholder',
                                        'placeholder.jpg',
                                        'no-image',
                                        'default-image',
                                    ]
                                    if any(pattern in src_lower for pattern in placeholder_patterns):
                                        continue
                                    
                                    # Si alt="preloader" ET placeholder FNAIM ET pas visible, exclure
                                    if 'preloader' in alt_lower and 'imagesv2.fnaim.fr/images1/img/' in src_lower:
                                        continue
                                
                                # Accepter les URLs de vraies photos d'appartements (patterns √©tendus)
                                # OU accepter les images visibles avec bonnes dimensions (m√™me FNAIM)
                                photo_patterns = [
                                    'loueragile', 
                                    'upload_pro_ad', 
                                    'media.apimo.pro', 
                                    'studio-net.fr', 
                                    'images.century21.fr', 
                                    'biens', 
                                    'apartement', 
                                    'transopera', 
                                    'staticlbi', 
                                    'uploadcaregdc', 
                                    'uploadcare', 
                                    's3.amazonaws.com', 
                                    'googleusercontent.com', 
                                    'cdn.safti.fr', 
                                    'safti.fr', 
                                    'paruvendu.fr', 
                                    'immo-facile.com', 
                                    'mms.seloger.com', 
                                    'seloger.com',
                                    'api.jinka.fr/apiv2/media/imgsrv',  # Proxy Jinka
                                    'photos.ubif',  # Photos via proxy Jinka
                                    'res.cloudinary.com',
                                    'cloudinary.com',
                                    'photos.',
                                    'imagesv2.fnaim.fr',  # Accepter FNAIM si image visible
                                ]
                                has_valid_pattern = any(pattern in src_lower for pattern in photo_patterns)
                                
                                # Accepter si pattern valide OU si image visible avec bonnes dimensions
                                if not has_valid_pattern and not (is_visible and has_good_dimensions):
                                    continue
                                
                                # V√©rifier les dimensions de l'image (exclure les tr√®s petites comme les logos)
                                width = img_data.get('width', 0)
                                height = img_data.get('height', 0)
                                
                                # Les logos font g√©n√©ralement ~128x128px, les vraies photos sont beaucoup plus grandes
                                # On exclut seulement les images tr√®s petites (< 200px)
                                if width > 0 and height > 0:
                                    if width < 200 or height < 200:
                                        # Probablement un logo ou ic√¥ne (ex: logo immobilier 128x128), on skip
                                        continue
                                
                                # Formater la description compl√®te avec toutes les infos
                                alt = self.format_photo_description(surface, prix_m2, etage, style)
                                
                                position_top = img_data.get('top', 0)
                                position_left = img_data.get('left', 0)
                                
                                # Garder toutes les photos valides, m√™me si cach√©es (display="none")
                                # Les photos avec alt="preloader" dans des divs cach√©es sont souvent les vraies photos
                                
                                photos_with_position.append({
                                    'url': src_to_use,
                                    'alt': alt or 'appartement',
                                    'selector': 'gallery_div_visible',
                                    'width': width,
                                    'height': height,
                                    'dom_index': img_data.get('domIndex', 0),
                                    'position_top': position_top,
                                    'position_left': position_left
                                })
                            except Exception as e:
                                continue
                        
                        # D√©dupliquer par URL, en gardant la photo avec la meilleure position (visible de pr√©f√©rence)
                        url_to_photo = {}
                        for photo in photos_with_position:
                            url = photo['url']
                            top = photo.get('position_top', 0)
                            left = photo.get('position_left', 0)
                            
                            # Si on a d√©j√† cette URL
                            if url in url_to_photo:
                                existing_top = url_to_photo[url].get('position_top', 0)
                                existing_left = url_to_photo[url].get('position_left', 0)
                                
                                # Pr√©f√©rer la photo avec position non-0,0 (visible)
                                if (top != 0 or left != 0) and (existing_top == 0 and existing_left == 0):
                                    # Nouvelle photo est visible, remplacer
                                    url_to_photo[url] = photo
                                elif (top == 0 and left == 0) and (existing_top != 0 or existing_left != 0):
                                    # Photo existante est visible, garder celle-l√†
                                    pass
                                else:
                                    # Les deux ont m√™me type de position, garder la premi√®re
                                    pass
                            else:
                                # Premi√®re occurrence de cette URL
                                url_to_photo[url] = photo
                        
                        photos_with_position = list(url_to_photo.values())
                        
                        # S√©parer les photos visibles (position != 0,0) des photos cach√©es (0,0)
                        visible_photos = [p for p in photos_with_position if p.get('position_top', 0) != 0 or p.get('position_left', 0) != 0]
                        hidden_photos = [p for p in photos_with_position if p.get('position_top', 0) == 0 and p.get('position_left', 0) == 0]
                        
                        # Trier les photos visibles par position (top puis left) pour l'ordre visuel
                        visible_photos.sort(key=lambda x: (x.get('position_top', 0), x.get('position_left', 0)))
                        
                        # Trier les photos cach√©es par index DOM pour pr√©server l'ordre de Jinka
                        hidden_photos.sort(key=lambda x: x.get('dom_index', 0))
                        
                        # Combiner : photos visibles d'abord, puis photos cach√©es dans l'ordre DOM
                        photos_with_position = visible_photos + hidden_photos
                        print(f"      ‚úÖ {len(visible_photos)} photos visibles + {len(hidden_photos)} photos cach√©es = {len(photos_with_position)} photos au total")
                        
                        # Ajouter les photos dans l'ordre correct (ordre visuel de Jinka)
                        for photo_with_pos in photos_with_position:
                            photo = {k: v for k, v in photo_with_pos.items() if k not in ['dom_index', 'position_top', 'position_left']}
                            photos.append(photo)
                            print(f"      üì∏ Photo galerie (top: {photo_with_pos.get('position_top', 0):.0f}, left: {photo_with_pos.get('position_left', 0):.0f}, {photo_with_pos['width']}x{photo_with_pos['height']}): {photo_with_pos['url'][:60]}...")
                        
                        if len(photos) > 0:
                            # Ne pas break, continuer √† chercher dans d'autres s√©lecteurs pour accumuler toutes les photos
                            pass
                except Exception as e:
                    continue
            
            # Apr√®s avoir cherch√© dans toutes les galeries, d√©dupliquer
            if len(photos) > 0:
                unique_photos_temp = []
                seen_urls_temp = set()
                for photo in photos:
                    if photo['url'] not in seen_urls_temp:
                        unique_photos_temp.append(photo)
                        seen_urls_temp.add(photo['url'])
                photos = unique_photos_temp
                print(f"      ‚úÖ {len(photos)} photos uniques trouv√©es apr√®s d√©duplication")
            
            # M√©thode 2: Si pas de photos dans la galerie, chercher les images visibles avec URLs d'appartement
            if len(photos) == 0:
                print("      ‚ö†Ô∏è Aucune photo dans la galerie, recherche d'images visibles...")
                
                # Attendre un peu pour que les images lazy-loaded se chargent
                await asyncio.sleep(2)
                
                # Chercher UNIQUEMENT les images visibles avec URLs d'appartement
                all_visible_images = await self.page.locator('img:visible').all()
                print(f"      üîç {len(all_visible_images)} images visibles totales sur la page")
                
                # M√©thode 2a: Chercher dans les images visibles
                for img in all_visible_images:
                    try:
                        # V√©rifier que l'image est vraiment visible
                        display = await img.evaluate('el => window.getComputedStyle(el).display')
                        if display == 'none':
                            continue
                        
                        # V√©rifier les dimensions de l'image (exclure les tr√®s petites comme les logos)
                        width = await img.evaluate('el => el.naturalWidth || el.width || 0')
                        height = await img.evaluate('el => el.naturalHeight || el.height || 0')
                        
                        # Les logos font g√©n√©ralement ~128x128px, les vraies photos sont beaucoup plus grandes
                        # On exclut seulement les images tr√®s petites (< 200px)
                        if width > 0 and height > 0:
                            if width < 200 or height < 200:
                                # Probablement un logo ou ic√¥ne (ex: logo immobilier 128x128), on skip
                                continue
                        
                        src = await img.get_attribute('src')
                        # Chercher aussi dans data-src (lazy loading)
                        data_src = await img.get_attribute('data-src')
                        src_to_use = src or data_src
                        
                        # V√©rifier si l'image est visible et a de bonnes dimensions
                        src_lower = src_to_use.lower()
                        alt_attr = await img.get_attribute('alt') or ''
                        alt_lower = alt_attr.lower()
                        
                        # V√©rifier la visibilit√© r√©elle de l'image
                        is_visible_element = display != 'none'
                        bounding_box = await img.bounding_box()
                        is_in_viewport = bounding_box is not None and bounding_box['width'] > 0 and bounding_box['height'] > 0
                        is_visible = is_visible_element and is_in_viewport
                        
                        # LOGIQUE AM√âLIOR√âE : Accepter les images VISIBLES m√™me si FNAIM
                        # Si l'image est visible ET a de bonnes dimensions, c'est probablement une vraie photo
                        if is_visible and width > 200 and height > 200:
                            # Accepter les images visibles m√™me si elles utilisent FNAIM
                            # Car elles sont affich√©es sur la page
                            pass  # Continuer pour ajouter la photo
                        else:
                            # Pour les images cach√©es ou petites, filtrer les placeholders FNAIM
                            placeholder_patterns = [
                                'imagesv2.fnaim.fr/images1/img/',  # Placeholder FNAIM
                                'placeholder',
                                'placeholder.jpg',
                                'no-image',
                                'default-image',
                            ]
                            if any(pattern in src_lower for pattern in placeholder_patterns):
                                continue
                            
                            # Si alt="preloader" ET placeholder FNAIM ET pas visible, exclure
                            if 'preloader' in alt_lower and 'imagesv2.fnaim.fr/images1/img/' in src_lower:
                                continue
                        
                        # Accepter les URLs de vraies photos d'appartements (patterns √©tendus)
                        photo_patterns = [
                            'loueragile', 
                            'upload_pro_ad', 
                            'media.apimo.pro', 
                            'studio-net.fr', 
                            'images.century21.fr', 
                            'biens', 
                            'apartement', 
                            'transopera', 
                            'staticlbi', 
                            'uploadcaregdc', 
                            'uploadcare', 
                            's3.amazonaws.com', 
                            'googleusercontent.com', 
                            'cdn.safti.fr', 
                            'safti.fr', 
                            'paruvendu.fr', 
                            'immo-facile.com', 
                            'mms.seloger.com', 
                            'seloger.com',
                            'api.jinka.fr/apiv2/media/imgsrv',  # Proxy Jinka
                            'photos.ubif',  # Photos via proxy Jinka
                            'res.cloudinary.com',
                            'cloudinary.com',
                            'photos.',
                            'imagesv2.fnaim.fr',  # Accepter FNAIM si image visible
                        ]
                        if src_to_use and any(pattern in src_lower for pattern in photo_patterns):
                            # Exclure les logos (mais pas si image visible avec bonnes dimensions)
                            if 'logo' in src_lower or 'source_logos' in src_lower:
                                if not (is_visible and width > 200 and height > 200):
                                    continue
                            
                            # Formater la description compl√®te avec toutes les infos
                            alt = self.format_photo_description(surface, prix_m2, etage, style)
                            
                            photos.append({
                                'url': src_to_use,
                                'alt': alt or 'appartement',
                                'selector': 'global_search_visible',
                                'width': width,
                                'height': height
                            })
                            print(f"      üì∏ Photo visible ({width}x{height}): {src_to_use[:60]}...")
                    except Exception as e:
                        continue
                
                # M√©thode 2b: Si toujours rien, chercher dans toutes les images (m√™me cach√©es, au cas o√π)
                if len(photos) == 0:
                    print("      üîç Recherche alternative dans toutes les images (y compris lazy-loaded)...")
                    all_images = await self.page.locator('img').all()
                    
                    for img in all_images:
                        try:
                            # R√©cup√©rer src et data-src (pour lazy loading)
                            src = await img.get_attribute('src')
                            data_src = await img.get_attribute('data-src')
                            data_lazy = await img.get_attribute('data-lazy-src')
                            src_to_use = src or data_src or data_lazy
                            
                            if not src_to_use:
                                continue
                            
                            # V√©rifier les dimensions si l'image est charg√©e
                            width = 0
                            height = 0
                            try:
                                width = await img.evaluate('el => el.naturalWidth || el.width || 0')
                                height = await img.evaluate('el => el.naturalHeight || el.height || 0')
                            except:
                                pass  # Si l'image n'est pas encore charg√©e, on garde quand m√™me
                            
                            # V√©rifier si l'image est visible et a de bonnes dimensions
                            src_lower = src_to_use.lower()
                            alt_attr = await img.get_attribute('alt') or ''
                            alt_lower = alt_attr.lower()
                            
                            # V√©rifier la visibilit√© et les dimensions
                            try:
                                bounding_box = await img.bounding_box()
                                is_visible = bounding_box is not None and bounding_box['width'] > 0 and bounding_box['height'] > 0
                            except:
                                is_visible = False
                            
                            # LOGIQUE AM√âLIOR√âE : Accepter les images VISIBLES m√™me si FNAIM
                            if is_visible and width > 200 and height > 200:
                                # Accepter les images visibles m√™me si elles utilisent FNAIM
                                pass  # Continuer pour ajouter la photo
                            else:
                                # Pour les images cach√©es ou petites, filtrer les placeholders FNAIM
                                placeholder_patterns = [
                                    'imagesv2.fnaim.fr/images1/img/',  # Placeholder FNAIM
                                    'placeholder',
                                    'placeholder.jpg',
                                    'no-image',
                                    'default-image',
                                ]
                                if any(pattern in src_lower for pattern in placeholder_patterns):
                                    continue
                                
                                # Si alt="preloader" ET placeholder FNAIM ET pas visible, exclure
                                if 'preloader' in alt_lower and 'imagesv2.fnaim.fr/images1/img/' in src_lower:
                                    continue
                            
                            # Filtrer par URL (patterns √©tendus) OU accepter si visible avec bonnes dimensions
                            photo_patterns = [
                                'loueragile', 
                                'upload_pro_ad', 
                                'media.apimo.pro', 
                                'studio-net.fr', 
                                'images.century21.fr', 
                                'biens', 
                                'apartement', 
                                'transopera', 
                                'staticlbi', 
                                'uploadcaregdc', 
                                'uploadcare', 
                                's3.amazonaws.com', 
                                'googleusercontent.com', 
                                'cdn.safti.fr', 
                                'safti.fr', 
                                'paruvendu.fr', 
                                'immo-facile.com', 
                                'mms.seloger.com', 
                                'seloger.com',
                                'api.jinka.fr/apiv2/media/imgsrv',  # Proxy Jinka
                                'photos.ubif',  # Photos via proxy Jinka
                                'res.cloudinary.com',
                                'cloudinary.com',
                                'photos.',
                                'imagesv2.fnaim.fr',  # Accepter FNAIM si image visible
                            ]
                            has_valid_pattern = any(pattern in src_lower for pattern in photo_patterns)
                            
                            # Accepter si pattern valide OU si image visible avec bonnes dimensions
                            if not has_valid_pattern and not (is_visible and width > 200 and height > 200):
                                continue
                            
                            # Exclure les logos (mais pas si image visible avec bonnes dimensions)
                            if 'logo' in src_lower or 'source_logos' in src_lower:
                                if not (is_visible and width > 200 and height > 200):
                                    continue
                            
                            # V√©rifier les dimensions finales (exclure les tr√®s petites sauf si visibles)
                            if width > 0 and height > 0:
                                if width < 200 or height < 200:
                                    # Si l'image est visible malgr√© sa petite taille, on l'accepte quand m√™me
                                    if not is_visible:
                                        continue
                            
                            photos.append({
                                'url': src_to_use,
                                'alt': await img.get_attribute('alt') or 'appartement',
                                'selector': 'global_search_all',
                                'width': width,
                                'height': height
                            })
                            print(f"      üì∏ Photo trouv√©e (lazy-loaded?): {src_to_use[:60]}...")
                        except Exception as e:
                            continue
            
            # D√©dupliquer
            unique_photos = []
            seen_urls = set()
            for photo in photos:
                if photo['url'] not in seen_urls:
                    unique_photos.append(photo)
                    seen_urls.add(photo['url'])
            
            print(f"   ‚úÖ {len(unique_photos)} photos d'appartement trouv√©es")
            return unique_photos  # Retourner toutes les photos disponibles
            
        except Exception as e:
            print(f"   ‚ùå Erreur extraction photos: {e}")
            return []
    
    async def extract_caracteristiques(self):
        """Extrait les caract√©ristiques"""
        try:
            # Chercher la section caract√©ristiques
            char_elements = self.page.locator('h3:has-text("Caract√©ristiques") + *')
            if await char_elements.count() > 0:
                text = await char_elements.first.text_content()
                return text.strip() if text else "Caract√©ristiques non trouv√©es"
            return "Caract√©ristiques non trouv√©es"
        except:
            return "Caract√©ristiques non trouv√©es"
    
    async def extract_agence(self):
        """Extrait les informations de l'agence"""
        try:
            # Chercher le nom de l'agence
            agence_elements = self.page.locator('text=/[A-Z][A-Z\s]+/')
            for i in range(await agence_elements.count()):
                text = await agence_elements.nth(i).text_content()
                if text and len(text.strip()) > 3 and text.isupper():
                    return text.strip()
            return "Agence non trouv√©e"
        except:
            return "Agence non trouv√©e"
    
    async def save_apartment(self, apartment_data, skip_if_exists=False):
        """Sauvegarde les donn√©es d'un appartement
        
        Args:
            apartment_data: Donn√©es de l'appartement √† sauvegarder
            skip_if_exists: Si True, ne pas √©craser un fichier existant
        """
        try:
            os.makedirs('data/appartements', exist_ok=True)
            filename = f"data/appartements/{apartment_data['id']}.json"
            
            # V√©rifier si le fichier existe d√©j√†
            if skip_if_exists and os.path.exists(filename):
                print(f"‚è≠Ô∏è  Appartement {apartment_data['id']} d√©j√† sauvegard√© - SKIP")
                return False
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(apartment_data, f, ensure_ascii=False, indent=2)
            
            print(f"üíæ Appartement {apartment_data['id']} sauvegard√©")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur sauvegarde: {e}")
            return False
    
    async def download_apartment_photos(self, apartment_id, photos):
        """T√©l√©charge les photos d'un appartement localement avec filtrage par taille"""
        try:
            if not photos:
                return
                
            # Cr√©er le dossier pour les photos
            photos_dir = f"data/photos/{apartment_id}"
            os.makedirs(photos_dir, exist_ok=True)
            
            # Supprimer toutes les photos existantes
            if os.path.exists(photos_dir):
                existing_files = [f for f in os.listdir(photos_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]
                for existing_file in existing_files:
                    file_path = os.path.join(photos_dir, existing_file)
                    try:
                        os.remove(file_path)
                        print(f"      üóëÔ∏è Photo existante supprim√©e: {existing_file}")
                    except Exception as e:
                        print(f"      ‚ö†Ô∏è Erreur suppression {existing_file}: {e}")
            
            # T√©l√©charger et filtrer les photos
            valid_photos = []
            async with aiohttp.ClientSession() as session:
                for i, photo in enumerate(photos):  # T√©l√©charger toutes les photos disponibles
                    url = photo['url']
                    temp_filename = f"{photos_dir}/temp_photo_{i+1}.jpg"
                    
                    try:
                        async with session.get(url) as response:
                            if response.status == 200:
                                content = await response.read()
                                
                                # Sauvegarder temporairement pour analyser
                                with open(temp_filename, 'wb') as f:
                                    f.write(content)
                                
                                # V√©rifier si c'est une vraie photo d'appartement
                                if self.is_valid_apartment_photo(temp_filename, content):
                                    # Renommer avec format simple: photo1.jpg, photo2.jpg, etc.
                                    photo_number = len(valid_photos) + 1
                                    final_filename = f"{photos_dir}/photo{photo_number}.jpg"
                                    os.rename(temp_filename, final_filename)
                                    valid_photos.append(final_filename)
                                    print(f"      üì∏ Photo {photo_number} t√©l√©charg√©e: {final_filename} ({len(content)} bytes)")
                                else:
                                    # Supprimer la photo invalide
                                    os.remove(temp_filename)
                                    print(f"      ‚ùå Photo {i+1} rejet√©e: {len(content)} bytes (logo/ic√¥ne)")
                            else:
                                print(f"      ‚ùå Erreur photo {i+1}: HTTP {response.status}")
                    except Exception as e:
                        print(f"      ‚ùå Erreur t√©l√©chargement photo {i+1}: {e}")
                        if os.path.exists(temp_filename):
                            os.remove(temp_filename)
            
            print(f"      ‚úÖ {len(valid_photos)} photos d'appartement t√©l√©charg√©es dans {photos_dir}/")
                        
        except Exception as e:
            print(f"‚ùå Erreur t√©l√©chargement photos: {e}")
    
    def is_valid_apartment_photo(self, filepath, content):
        """V√©rifie si une photo est une vraie photo d'appartement"""
        try:
            # V√©rifier la taille du fichier (pas trop petit, pas trop grand)
            if len(content) < 20000 or len(content) > 500000:  # 20KB - 500KB
                return False
            
            # V√©rifier le type de fichier
            if not (content.startswith(b'\xff\xd8\xff') or  # JPEG
                    content.startswith(b'\x89PNG')):  # PNG
                return False
            
            # Pour les PNG, v√©rifier qu'ils ne sont pas des logos (carr√©s petits)
            if content.startswith(b'\x89PNG'):
                # Lire les dimensions PNG
                if len(content) >= 24:
                    width = int.from_bytes(content[16:20], 'big')
                    height = int.from_bytes(content[20:24], 'big')
                    # Rejeter les images carr√©es petites (logos)
                    if width == height and width < 600:
                        return False
                    # Rejeter les images trop petites
                    if width < 400 or height < 300:
                        return False
            
            return True
            
        except Exception as e:
            return False
    
    async def cleanup(self):
        """Ferme le navigateur"""
        if self.browser:
            await self.browser.close()

async def main():
    """Fonction principale"""
    if len(sys.argv) < 2:
        print("Usage: python scrape_jinka.py <URL_ALERTE>")
        print("Exemple: python scrape_jinka.py 'https://www.jinka.fr/alert_result?token=...'")
        return
    
    alert_url = sys.argv[1]
    
    scraper = JinkaScraper()
    
    try:
        await scraper.setup()
        
        if await scraper.login():
            await scraper.scrape_alert_page(alert_url)
            print(f"‚úÖ Scraping termin√©: {len(scraper.apartments)} appartements")
        else:
            print("‚ùå √âchec de la connexion")
    
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
    
    finally:
        await scraper.cleanup()

if __name__ == "__main__":
    asyncio.run(main())
