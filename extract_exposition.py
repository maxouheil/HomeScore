#!/usr/bin/env python3
"""
Module d'extraction de l'exposition des appartements
Phase 1: Analyse textuelle
Phase 2: Analyse des photos (√† venir)
"""

import re
import json
import os
import requests
import unicodedata
from typing import Dict, List, Optional, Tuple
from collections import Counter
from analyze_photos import PhotoAnalyzer
from analyze_contextual_exposition import ContextualExpositionAnalyzer
from analyze_text_ai import TextAIAnalyzer
from dotenv import load_dotenv

load_dotenv()

class ExpositionExtractor:
    """Extracteur d'exposition pour les appartements"""
    
    def __init__(self):
        self.photo_analyzer = PhotoAnalyzer()
        self.contextual_analyzer = ContextualExpositionAnalyzer()
        self.text_ai_analyzer = TextAIAnalyzer()
        self.use_ai_validation = True  # Activer la validation IA pour √©viter faux positifs
        
        # Mots-cl√©s d'exposition avec leurs scores (ordre de sp√©cificit√©)
        self.expositions = {
            'sud_ouest': {
                'keywords': ['sud-ouest', 'sud ouest', 'so', 'ouest-sud'],
                'score': 10,
                'tier': 'tier1',
                'description': 'Excellente exposition Sud-Ouest'
            },
            'nord_est': {
                'keywords': ['nord-est', 'nord est', 'ne', 'nord-est'],
                'score': 3,
                'tier': 'tier3',
                'description': 'Exposition Nord-Est limit√©e'
            },
            'sud': {
                'keywords': ['exposition sud', 'plein sud', 'orientation sud', 'sud'],
                'score': 10,
                'tier': 'tier1',
                'description': 'Excellente exposition Sud'
            },
            'nord': {
                'keywords': ['exposition nord', 'nord'],
                'score': 3,
                'tier': 'tier3',
                'description': 'Exposition Nord limit√©e'
            },
            'ouest': {
                'keywords': ['exposition ouest', 'ouest', 'couchant'],
                'score': 7,
                'tier': 'tier2',
                'description': 'Bonne exposition Ouest'
            },
            'est': {
                'keywords': ['exposition est', 'est', 'levant'],
                'score': 7,
                'tier': 'tier2',
                'description': 'Bonne exposition Est'
            }
        }
        
        # Mots-cl√©s de luminosit√©
        self.luminosite_keywords = {
            'excellent': ['tr√®s lumineux', 'tr√®s clair', 'plein de lumi√®re', 'tr√®s ensoleill√©', 'lumineux toute la journ√©e'],
            'bon': ['lumineux', 'clair', 'bien √©clair√©', 'ensoleill√©', 'bien expos√©'],
            'moyen': ['assez lumineux', 'correctement √©clair√©', 'luminosit√© correcte'],
            'faible': ['peu lumineux', 'sombre', 'peu √©clair√©', 'manque de lumi√®re']
        }
        
        # Mots-cl√©s de vue
        self.vue_keywords = {
            'excellent': ['vue d√©gag√©e', 'vue panoramique', 'vue sur parc', 'vue sur cour', 'pas de vis-√†-vis', 'vue libre'],
            'bon': ['vue correcte', 'vue agr√©able', 'vue sur rue calme', 'vue d√©gag√©e partiellement'],
            'moyen': ['vue limit√©e', 'vue sur cour', 'vue partiellement obstru√©e'],
            'faible': ['vis-√†-vis', 'vue obstru√©e', 'pas de vue', 'vue sur mur']
        }
    
    def _add_brightness_to_result(self, result: Dict, photos: List[str]) -> Dict:
        """Ajoute brightness_value aux d√©tails d'un r√©sultat, m√™me si exposition d√©j√† trouv√©e"""
        if not photos or not result:
            return result
        
        try:
            photo_result = self.extract_exposition_photos(photos)
            if photo_result and photo_result.get('photos_analyzed', 0) > 0:
                photo_details = photo_result.get('details', {})
                brightness_value = photo_details.get('brightness_value')
                if brightness_value is not None:
                    if 'details' not in result:
                        result['details'] = {}
                    result['details']['brightness_value'] = brightness_value
                    result['details']['image_brightness'] = brightness_value
        except Exception:
            # En cas d'erreur, continuer sans brightness_value
            pass
        
        return result
    
    def extract_exposition_textuelle(self, description: str, caracteristiques: str = "", etage: str = "") -> Dict:
        """Extrait l'exposition depuis le texte (Phase 1)"""
        try:
            # Combiner tous les textes
            text = f"{description} {caracteristiques} {etage}".lower()
            
            # Chercher l'exposition
            exposition_trouvee = None
            score_exposition = 0
            tier = 'tier3'
            justification = "Exposition non sp√©cifi√©e"
            exposition_explicite = False
            
            # Chercher l'exposition en priorit√© (ordre d'importance)
            # D'abord chercher les expositions compos√©es, puis les simples
            potential_expositions = []
            for expo, details in self.expositions.items():
                for keyword in details['keywords']:
                    # Utiliser des word boundaries pour √©viter les faux positifs
                    pattern = r'\b' + re.escape(keyword) + r'\b'
                    if re.search(pattern, text, re.IGNORECASE):
                        potential_expositions.append({
                            'exposition': expo,
                            'keyword': keyword,
                            'score': details['score'],
                            'tier': details['tier'],
                            'description': details['description']
                        })
                        break
            
            # Variables pour stocker les infos IA (initialis√©es par d√©faut)
            ai_result = None
            confiance_globale = 0.0
            confiance_exposition = 0.0
            etage_analyse = {}
            vue_mentionnee = {}
            indices_trouves = []
            
            # Si exposition(s) trouv√©e(s), valider avec IA pour √©viter faux positifs
            if potential_expositions and self.use_ai_validation and self.text_ai_analyzer.openai_api_key:
                ai_result = self.text_ai_analyzer.analyze_exposition(description, caracteristiques, etage)
                
                if ai_result.get('available', False):
                    exposition_ia = ai_result.get('exposition')
                    est_faux_positif = ai_result.get('est_faux_positif', False)
                    confiance_globale = ai_result.get('confiance_globale', 0.0)
                    confiance_exposition = ai_result.get('confiance_exposition', 0.0)
                    
                    # Extraire les informations suppl√©mentaires
                    etage_analyse = ai_result.get('etage_analyse', {})
                    vue_mentionnee = ai_result.get('vue_mentionnee', {})
                    indices_trouves = ai_result.get('indices_trouves', [])
                    
                    # NOUVELLE LOGIQUE : Si mention explicite √©tage ET/OU exposition ‚Üí confiance 70%
                    etage_trouve = etage_analyse.get('etage_trouve')
                    exposition_explicite_detectee = bool(exposition_ia and not est_faux_positif)
                    
                    if (etage_trouve or exposition_explicite_detectee):
                        # Monter √† 70% de confiance si √©tage ET/OU exposition mentionn√©s
                        confiance_globale = max(confiance_globale, 0.7)
                    
                    if not est_faux_positif and exposition_ia:
                        # Trouver l'exposition valid√©e dans la liste
                        for exp in potential_expositions:
                            if exp['exposition'] == exposition_ia:
                                exposition_trouvee = exp['exposition']
                                score_exposition = exp['score']
                                tier = exp['tier']
                                
                                # Construire une justification enrichie avec toutes les infos
                                justification_parts = [f"Analyse IA globale (confiance: {confiance_globale:.0%})"]
                                justification_parts.append(ai_result.get('justification', exp['description']))
                                
                                if etage_analyse.get('etage_trouve'):
                                    impact_etage = etage_analyse.get('impact_luminosite', 'neutre')
                                    if impact_etage == 'positif':
                                        justification_parts.append(f"√âtage {etage_analyse.get('etage_trouve')} favorable (+)")
                                    elif impact_etage == 'negatif':
                                        justification_parts.append(f"√âtage {etage_analyse.get('etage_trouve')} limitant (-)")
                                
                                if vue_mentionnee.get('vue_trouvee'):
                                    type_vue = vue_mentionnee.get('type_vue', '')
                                    impact_vue = vue_mentionnee.get('impact_luminosite', 'neutre')
                                    if impact_vue == 'positif':
                                        justification_parts.append(f"Vue {type_vue} favorable (+)")
                                    elif impact_vue == 'negatif':
                                        justification_parts.append(f"Vue {type_vue} limitante (-)")
                                
                                if indices_trouves:
                                    justification_parts.append(f"Indices: {', '.join(indices_trouves[:3])}")
                                
                                justification = " | ".join(justification_parts)
                                exposition_explicite = True
                                
                                # Ajuster le score si confiance globale √©lev√©e (>0.8) et score actuel moyen
                                if confiance_globale > 0.8 and score_exposition < 8:
                                    score_exposition = min(10, score_exposition + 1)
                                    if score_exposition >= 10:
                                        tier = 'tier1'
                                    elif score_exposition >= 7:
                                        tier = 'tier2'
                                
                                break
                    else:
                        # IA n'a pas confirm√© ‚Üí pas d'exposition explicite
                        # Mais on peut quand m√™me utiliser les infos sur √©tage/vue pour ajuster
                        if confiance_globale > 0.5 and not est_faux_positif:
                            # Pas d'exposition explicite mais bonnes indications (√©tage √©lev√© + vue)
                            # On garde une exposition None mais on note les indices positifs
                            justification = f"Pas d'exposition explicite mais indices positifs (confiance: {confiance_globale:.0%})"
                            if etage_analyse.get('impact_luminosite') == 'positif':
                                justification += f" | √âtage {etage_analyse.get('etage_trouve')} favorable"
                            if vue_mentionnee.get('impact_luminosite') == 'positif':
                                justification += f" | Vue {vue_mentionnee.get('type_vue')} favorable"
                        else:
                            exposition_trouvee = None
                else:
                    # Erreur IA ‚Üí utiliser la premi√®re trouv√©e avec warning
                    first_match = potential_expositions[0]
                    exposition_trouvee = first_match['exposition']
                    score_exposition = first_match['score']
                    tier = first_match['tier']
                    justification = f"{first_match['description']} (validation IA indisponible)"
                    exposition_explicite = True
            elif potential_expositions:
                # Pas de validation IA disponible ‚Üí utiliser la premi√®re trouv√©e
                first_match = potential_expositions[0]
                exposition_trouvee = first_match['exposition']
                score_exposition = first_match['score']
                tier = first_match['tier']
                justification = first_match['description']
                exposition_explicite = True
            
            # Analyser la luminosit√©
            luminosite_score = self._analyze_luminosite(text)
            
            # Analyser la vue
            vue_score = self._analyze_vue(text)
            
            # Calculer le bonus √©tage >=4
            bonus_etage = self._calculate_etage_bonus(caracteristiques, etage)
            
            # Calculer le score total (max entre exposition, luminosit√©, vue)
            score_base = max(score_exposition, luminosite_score, vue_score)
            
            # Ajouter le bonus √©tage (max 10)
            score_total = min(10, score_base + bonus_etage)
            
            # Mettre √† jour le tier si n√©cessaire apr√®s bonus
            if score_total >= 10:
                tier = 'tier1'
            elif score_total >= 7:
                tier = 'tier2'
            else:
                tier = 'tier3'
            
            return {
                'exposition': exposition_trouvee,
                'score': score_total,
                'tier': tier,
                'justification': justification,
                'luminosite': self._get_luminosite_level(text),
                'vue': self._get_vue_level(text),
                'exposition_explicite': exposition_explicite,
                'bonus_etage': bonus_etage,
                'details': {
                    'exposition_score': score_exposition,
                    'luminosite_score': luminosite_score,
                    'vue_score': vue_score,
                    'score_base': score_base,
                    'bonus_etage': bonus_etage,
                    'ai_analysis': {
                        'available': ai_result is not None and ai_result.get('available', False),
                        'confiance_globale': confiance_globale,
                        'confiance_exposition': confiance_exposition,
                        'etage_analyse': etage_analyse,
                        'vue_mentionnee': vue_mentionnee,
                        'indices_trouves': indices_trouves
                    } if ai_result else None
                }
            }
            
        except Exception as e:
            return {
                'exposition': None,
                'score': 3,
                'tier': 'tier3',
                'justification': f"Erreur extraction: {e}",
                'luminosite': 'inconnue',
                'vue': 'inconnue',
                'exposition_explicite': False,
                'bonus_etage': 0,
                'details': {}
            }
    
    def _calculate_etage_bonus(self, caracteristiques: str, etage: str = "") -> int:
        """Calcule le bonus √©tage >=4"""
        text = f"{caracteristiques} {etage}".lower()
        
        # Patterns pour d√©tecter √©tage >= 4
        patterns = [
            r'\b(4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20)[√®e]?me?\s*√©tage',
            r'\b√©tage\s*(4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20)',
            r'\b(4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20)[√®e]?\s*√©tage',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                try:
                    etage_num = int(match.group(1))
                    if etage_num >= 4:
                        return 1  # Bonus de +1 point pour √©tage >= 4
                except (ValueError, IndexError):
                    continue
        
        return 0  # Pas de bonus
    
    def _analyze_luminosite(self, text: str) -> int:
        """Analyse la luminosit√© mentionn√©e"""
        for level, keywords in self.luminosite_keywords.items():
            if any(keyword in text for keyword in keywords):
                if level == 'excellent':
                    return 10
                elif level == 'bon':
                    return 7
                elif level == 'moyen':
                    return 5
                else:  # faible
                    return 3
        return 5  # Score par d√©faut
    
    def _analyze_vue(self, text: str) -> int:
        """Analyse la qualit√© de la vue"""
        for level, keywords in self.vue_keywords.items():
            if any(keyword in text for keyword in keywords):
                if level == 'excellent':
                    return 10
                elif level == 'bon':
                    return 7
                elif level == 'moyen':
                    return 5
                else:  # faible
                    return 3
        return 5  # Score par d√©faut
    
    def _get_luminosite_level(self, text: str) -> str:
        """Retourne le niveau de luminosit√©"""
        for level, keywords in self.luminosite_keywords.items():
            if any(keyword in text for keyword in keywords):
                return level
        return 'inconnue'
    
    def _get_vue_level(self, text: str) -> str:
        """Retourne le niveau de vue"""
        for level, keywords in self.vue_keywords.items():
            if any(keyword in text for keyword in keywords):
                return level
        return 'inconnue'
    
    def extract_exposition_photos(self, photos_urls: List[str]) -> Dict:
        """Extrait l'exposition depuis les photos (Phase 2)"""
        return self.photo_analyzer.analyze_photos_exposition(photos_urls)
    
    def get_exposition_score(self, exposition_data: Dict) -> int:
        """Retourne le score d'exposition final"""
        return exposition_data.get('score', 3)
    
    def get_exposition_tier(self, exposition_data: Dict) -> str:
        """Retourne le tier d'exposition"""
        return exposition_data.get('tier', 'tier3')
    
    def get_exposition_justification(self, exposition_data: Dict) -> str:
        """Retourne la justification de l'exposition"""
        return exposition_data.get('justification', 'Exposition non d√©termin√©e')
    
    def extract_exposition_complete(self, description: str, caracteristiques: str = "", photos_urls: List[str] = None, etage: str = "") -> Dict:
        """Extrait l'exposition en combinant analyse textuelle et photos (Phase 1 + 2)
        
        NOUVELLE LOGIQUE:
        1. PRIORIT√â 1: Analyse textuelle - Si mention explicite √©tage ET/OU exposition ‚Üí confiance 70%
        2. PRIORIT√â 2: Si confiance < 70% ‚Üí analyser les photos (top 5) pour mesurer la luminosit√© moyenne
        3. Agr√©gation bas√©e sur la luminosit√© moyenne des photos (brightness)
        """
        # Phase 1: Analyse textuelle (avec bonus √©tage)
        text_result = self.extract_exposition_textuelle(description, caracteristiques, etage)
        
        # V√©rifier si confiance >= 70% (mention explicite d√©tect√©e)
        confiance_textuelle = 0.0
        if text_result and isinstance(text_result, dict):
            ai_analysis = text_result.get('details', {}).get('ai_analysis')
            if ai_analysis:
                confiance_textuelle = ai_analysis.get('confiance_globale', 0.0)
        
        # M√™me si confiance >= 70%, analyser les photos pour obtenir brightness_value
        # Si confiance >= 70% ‚Üí retourner directement (mais avec brightness_value si disponible)
        if text_result and isinstance(text_result, dict) and confiance_textuelle >= 0.7:
            # Toujours analyser les photos pour obtenir brightness_value
            text_result = self._add_brightness_to_result(text_result, photos_urls)
            return text_result
        
        # Phase 2: Si confiance < 70% ‚Üí analyser les photos
        photo_result = None
        if photos_urls:
            # Analyser les 5 premi√®res photos pour d√©tection pr√©cise
            photos_to_analyze = photos_urls[:5]
            photo_result = self.extract_exposition_photos(photos_to_analyze)
        
        # Phase 3: Si photos analys√©es ‚Üí combiner avec r√©sultat textuel
        if photo_result and photo_result.get('photos_analyzed', 0) > 0:
            if text_result and isinstance(text_result, dict):
                validation = self.photo_analyzer.validate_text_with_photos(text_result, photo_result, 'exposition')
                
                # Utiliser la confiance ajust√©e
                ai_analysis = text_result.get('details', {}).get('ai_analysis')
                confiance_textuelle_base = ai_analysis.get('confiance_globale', 0.5) if ai_analysis else 0.5
                confiance_ajustee = validation.get('confidence_adjusted', confiance_textuelle_base)
                validation_status = validation.get('validation_status', 'text_only')
                
                # Construire r√©sultat final enrichi
                final_result = text_result.copy()
            else:
                # Pas de r√©sultat textuel ‚Üí utiliser uniquement les photos
                final_result = photo_result.copy()
                confiance_ajustee = photo_result.get('confidence', 0.5)
                validation_status = 'photo_only'
            
            # Mettre √† jour la justification avec info de validation
            if validation_status == 'validated':
                final_result['justification'] += f" | ‚úÖ Valid√© par photos (confiance: {confiance_ajustee:.0%})"
            elif validation_status == 'conflict':
                final_result['justification'] += f" | ‚ö†Ô∏è Conflit texte/photos (confiance: {confiance_ajustee:.0%})"
            
            # Ajouter les infos de validation dans les d√©tails
            if 'details' not in final_result:
                final_result['details'] = {}
            final_result['details']['photo_validation'] = validation.get('cross_validation')
            
            # Initialiser ai_analysis si n√©cessaire
            if 'ai_analysis' not in final_result['details'] or final_result['details']['ai_analysis'] is None:
                final_result['details']['ai_analysis'] = {}
            final_result['details']['ai_analysis']['confiance_globale'] = confiance_ajustee
            final_result['details']['ai_analysis']['validation_status'] = validation_status
            
            # brightness_value est d√©j√† dans photo_result.details, le copier si n√©cessaire
            if 'brightness_value' not in final_result.get('details', {}):
                photo_brightness = photo_result.get('details', {}).get('brightness_value')
                if photo_brightness is not None:
                    if 'details' not in final_result:
                        final_result['details'] = {}
                    final_result['details']['brightness_value'] = photo_brightness
                    final_result['details']['image_brightness'] = photo_brightness
            
            return final_result
        
        # Pas de photos ‚Üí retourner r√©sultat textuel uniquement (brightness_value d√©j√† ajout√© si disponible)
        return text_result
    
    def extract_exposition_contextual(self, apartment_data: Dict) -> Dict:
        """Extrait l'exposition en utilisant l'analyse contextuelle (Phase 3)"""
        return self.contextual_analyzer.analyze_contextual_exposition(apartment_data)
    
    def extract_exposition_ultimate(self, apartment_data: Dict) -> Dict:
        """Extrait l'exposition en combinant toutes les m√©thodes (Phase 1 + 2 + 3)
        
        Nouvelle logique selon CHANGELOG:
        1. Si exposition explicite trouv√©e ‚Üí retourner directement
        2. Sinon ‚Üí analyser les photos
        3. Si photos analys√©es ‚Üí utiliser r√©sultat photos
        4. Sinon ‚Üí analyser contextuel (dernier recours)
        5. Sinon ‚Üí retourner inconnu
        """
        description = apartment_data.get('description', '')
        caracteristiques = apartment_data.get('caracteristiques', '')
        etage = apartment_data.get('etage', '')
        photos = apartment_data.get('photos', [])
        
        # Phase 1: Analyse textuelle (avec bonus √©tage)
        text_result = self.extract_exposition_textuelle(description, caracteristiques, etage)
        
        # Si exposition explicite trouv√©e ‚Üí analyser quand m√™me les photos pour brightness_value
        if text_result.get('exposition_explicite', False) and text_result.get('exposition'):
            # Toujours analyser les photos pour obtenir brightness_value
            text_result = self._add_brightness_to_result(text_result, photos)
            return text_result
        
        # Phase 2: Analyse des photos (si pas d'exposition explicite)
        photo_result = None
        if photos:
            photo_result = self.extract_exposition_photos(photos)
        
        # Si photos analys√©es avec succ√®s ‚Üí utiliser r√©sultat photos
        if photo_result and photo_result.get('photos_analyzed', 0) > 0:
            return photo_result
        
        # Phase 3: Analyse contextuelle (dernier recours)
        contextual_result = self.extract_exposition_contextual(apartment_data)
        
        # Si contextuel confiant ‚Üí combiner avec textuel
        if contextual_result.get('confidence', 0) > 0.5:
            combined = self._combine_results(contextual_result, text_result)
            # Toujours ajouter brightness_value si photos disponibles
            combined = self._add_brightness_to_result(combined, photos)
            return combined
        
        # Sinon ‚Üí retourner r√©sultat textuel (peut √™tre None si aucune info)
        # Toujours ajouter brightness_value si photos disponibles
        if text_result:
            text_result = self._add_brightness_to_result(text_result, photos)
        return text_result
    
    def _combine_all_results(self, text_result: Dict, photo_result: Optional[Dict], contextual_result: Dict) -> Dict:
        """Combine les r√©sultats de toutes les m√©thodes d'analyse
        
        NOTE: Cette m√©thode n'est plus utilis√©e dans extract_exposition_ultimate()
        mais conserv√©e pour compatibilit√© avec extract_exposition_complete()
        """
        # Priorit√©: Photos > Contextuel > Textuel
        if photo_result and photo_result.get('photos_analyzed', 0) > 0:
            # Photos disponibles - priorit√© aux photos
            if contextual_result.get('confidence', 0) > 0.7:
                # Contextuel tr√®s confiant - combiner photos + contextuel
                return self._combine_results(photo_result, contextual_result)
            else:
                # Utiliser uniquement les photos
                return photo_result
        elif contextual_result.get('confidence', 0) > 0.5:
            # Contextuel confiant - combiner contextuel + textuel
            return self._combine_results(contextual_result, text_result)
        else:
            # Utiliser uniquement l'analyse textuelle
            return text_result
    
    def _combine_results(self, photo_result: Dict, text_result: Dict) -> Dict:
        """Combine les r√©sultats de l'analyse textuelle et des photos"""
        # Priorit√© aux photos pour l'exposition
        exposition = photo_result.get('exposition') or text_result.get('exposition')
        
        # Score combin√© (moyenne pond√©r√©e)
        photo_score = photo_result.get('score', 0)
        text_score = text_result.get('score', 0)
        
        # Poids: 70% photos, 30% texte
        combined_score = int(photo_score * 0.7 + text_score * 0.3)
        
        # D√©terminer le tier
        if combined_score >= 10:
            tier = 'tier1'
        elif combined_score >= 7:
            tier = 'tier2'
        else:
            tier = 'tier3'
        
        return {
            'exposition': exposition,
            'score': combined_score,
            'tier': tier,
            'justification': f"Analyse combin√©e: {photo_result.get('justification', '')} + {text_result.get('justification', '')}",
            'luminosite': photo_result.get('luminosite', text_result.get('luminosite', 'inconnue')),
            'vue': photo_result.get('vue', text_result.get('vue', 'inconnue')),
            'photos_analyzed': photo_result.get('photos_analyzed', 0),
            'details': {
                'photo_score': photo_score,
                'text_score': text_score,
                'combined_score': combined_score,
                'photo_details': photo_result.get('details', {}),
                'text_details': text_result.get('details', {})
            }
        }
    
    def _normalize_orientation(self, text: str) -> str:
        """Normalise l'orientation: minuscules, sans accents, sans espaces/traits"""
        # Enlever accents
        text = unicodedata.normalize('NFD', text.lower())
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        # Enlever espaces et traits
        text = text.replace(' ', '').replace('-', '').replace('_', '')
        return text
    
    def _classify_orientation(self, orientation_text: str) -> Optional[str]:
        """Classe l'orientation: Lumineux, Moyen, ou Sombre"""
        if not orientation_text:
            return None
        
        normalized = self._normalize_orientation(orientation_text)
        
        # Lumineux: sud, sudouest, sudest
        if 'sudouest' in normalized or normalized == 'sudouest':
            return 'Lumineux'
        if 'sudest' in normalized or normalized == 'sudest':
            return 'Lumineux'
        if normalized == 'sud':
            return 'Lumineux'
        
        # Sombre: nord, nordouest, nordest (v√©rifier AVANT est/ouest)
        if 'nordouest' in normalized or normalized == 'nordouest':
            return 'Sombre'
        if 'nordest' in normalized or normalized == 'nordest':
            return 'Sombre'
        if normalized == 'nord':
            return 'Sombre'
        
        # Moyen: est, ouest (seulement si pas de sud/nord)
        if normalized == 'est':
            return 'Moyen'
        if normalized == 'ouest':
            return 'Moyen'
        
        return None
    
    def _extract_etage_number(self, caracteristiques: str, etage: str = "") -> Optional[int]:
        """Extrait le num√©ro d'√©tage depuis le texte"""
        text = f"{caracteristiques} {etage}".lower()
        
        # Patterns pour d√©tecter √©tage
        patterns = [
            r'\b(\d+)[√®e]?me?\s*√©tage',
            r'\b√©tage\s*(\d+)',
            r'\b(\d+)[√®e]?\s*√©tage',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                try:
                    return int(match.group(1))
                except (ValueError, IndexError):
                    continue
        
        # V√©rifier RDC
        if re.search(r'\b(rdc|rez[\s-]de[\s-]chauss√©e|rez[\s-]de[\s-]chaussee)\b', text, re.IGNORECASE):
            return 0
        
        return None
    
    def _classify_etage(self, etage_num: Optional[int]) -> Optional[str]:
        """Classe l'√©tage: Lumineux, Moyen, ou Sombre"""
        if etage_num is None:
            return None
        
        if etage_num >= 5:
            return 'Lumineux'
        elif 2 <= etage_num <= 4:
            return 'Moyen'
        else:  # <= 1 ou RDC (0)
            return 'Sombre'
    
    def _classify_image_brightness(self, brightness_value: float) -> Optional[str]:
        """Classe l'exposition image: Lumineux, Moyen, ou Sombre"""
        if brightness_value is None:
            return None
        
        if brightness_value >= 0.70:
            return 'Lumineux'
        elif brightness_value >= 0.40:
            return 'Moyen'
        else:
            return 'Sombre'
    
    def _get_image_intensity(self, brightness_value: float) -> str:
        """D√©termine l'intensit√© du signal image: Fort, Faible, ou Normal"""
        if brightness_value is None:
            return 'Normal'
        
        if brightness_value >= 0.85 or brightness_value <= 0.25:
            return 'Fort'
        elif 0.45 <= brightness_value <= 0.55:
            return 'Faible'
        else:
            return 'Normal'
    
    def extract_exposition_voting(self, description: str, caracteristiques: str = "", 
                                   etage: str = "", photos_urls: List[str] = None) -> Dict:
        """Extrait l'exposition avec syst√®me de vote selon r√®gles explicites
        
        R√®gles:
        1. Classification par signal (orientation, √©tage, image)
        2. Vote majoritaire pour d√©cision finale
        3. Calcul de confiance selon r√®gles pr√©cises
        """
        try:
            # 1. CLASSIFICATION PAR SIGNAL
            
            # Signal orientation
            text = f"{description} {caracteristiques} {etage}".lower()
            orientation_class = None
            orientation_found = None
            
            # Chercher orientation dans le texte
            for expo, details in self.expositions.items():
                for keyword in details['keywords']:
                    pattern = r'\b' + re.escape(keyword) + r'\b'
                    if re.search(pattern, text, re.IGNORECASE):
                        orientation_found = expo
                        orientation_class = self._classify_orientation(expo)
                        break
                if orientation_class:
                    break
            
            # Signal √©tage
            etage_num = self._extract_etage_number(caracteristiques, etage)
            etage_class = self._classify_etage(etage_num)
            
            # Signal image
            image_class = None
            image_brightness = None
            image_intensity = 'Normal'
            
            if photos_urls:
                photo_result = self.extract_exposition_photos(photos_urls[:5])
                if photo_result and photo_result.get('photos_analyzed', 0) > 0:
                    details = photo_result.get('details', {})
                    image_brightness = details.get('brightness_value')
                    if image_brightness is not None:
                        image_class = self._classify_image_brightness(image_brightness)
                        image_intensity = self._get_image_intensity(image_brightness)
            
            # 2. D√âCISION FINALE (vote majoritaire)
            signals = []
            if orientation_class:
                signals.append(('orientation', orientation_class))
            if etage_class:
                signals.append(('etage', etage_class))
            if image_class:
                signals.append(('image', image_class))
            
            if not signals:
                # Aucun signal ‚Üí Moyen, 50%
                return {
                    'exposition': None,
                    'score': 10,  # Moyen = 10 points
                    'tier': 'tier2',
                    'justification': 'Aucun signal disponible',
                    'luminosite': 'moyen',
                    'vue': 'inconnue',
                    'confidence': 50,
                    'details': {
                        'method': 'voting',
                        'signals': [],
                        'final_class': 'Moyen',
                        'vote_result': {}
                    }
                }
            
            # Compter les votes
            votes = Counter([cls for _, cls in signals])
            final_class = votes.most_common(1)[0][0] if votes else 'Moyen'
            
            # En cas d'√©galit√© parfaite, tranche avec l'image
            if len(votes) > 1 and len(set(votes.values())) == 1:  # √âgalit√© parfaite
                if image_class:
                    final_class = image_class
                    if image_intensity == 'Faible':
                        final_class = 'Moyen'
                else:
                    final_class = 'Moyen'
            
            # Points selon classe finale
            points_map = {'Lumineux': 20, 'Moyen': 10, 'Sombre': 0}
            score = points_map.get(final_class, 10)
            
            # 3. CALCUL DE CONFIANCE
            
            # Base: 60% si un seul signal
            if len(signals) == 1:
                confidence = 60
            else:
                # Base: 60% pour plusieurs signaux
                confidence = 60
                # +20% pour chaque signal d'accord avec la classe finale
                # -15% pour chaque signal en d√©saccord
                for signal_name, signal_class in signals:
                    if signal_class == final_class:
                        confidence += 20
                    else:
                        confidence -= 15
            
            # +10% si image forte et d'accord avec classe finale
            if image_intensity == 'Fort' and image_class == final_class:
                confidence += 10
            
            # -10% si image faible (quelle que soit la classe)
            if image_intensity == 'Faible':
                confidence -= 10
            
            # Bornes: min 50%, max 95%
            confidence = max(50, min(95, confidence))
            
            # Construire justification
            justification_parts = []
            if orientation_class:
                justification_parts.append(f"Orientation: {orientation_class}")
            if etage_class:
                justification_parts.append(f"√âtage: {etage_class}")
            if image_class:
                justification_parts.append(f"Image: {image_class} (brightness: {image_brightness:.2f}, intensity: {image_intensity})")
            justification_parts.append(f"Vote: {final_class} ({confidence}% confiance)")
            
            justification = " | ".join(justification_parts)
            
            # D√©terminer tier
            if final_class == 'Lumineux':
                tier = 'tier1'
            elif final_class == 'Moyen':
                tier = 'tier2'
            else:
                tier = 'tier3'
            
            return {
                'exposition': orientation_found,
                'score': score,
                'tier': tier,
                'justification': justification,
                'luminosite': final_class.lower(),
                'vue': 'inconnue',
                'confidence': confidence,
                'details': {
                    'method': 'voting',
                    'signals': [
                        {'name': name, 'class': cls} for name, cls in signals
                    ],
                    'final_class': final_class,
                    'vote_result': dict(votes),
                    'image_brightness': image_brightness,
                    'image_intensity': image_intensity,
                    'etage_num': etage_num
                }
            }
            
        except Exception as e:
            return {
                'exposition': None,
                'score': 10,
                'tier': 'tier2',
                'justification': f"Erreur extraction voting: {e}",
                'luminosite': 'moyen',
                'vue': 'inconnue',
                'confidence': 50,
                'details': {'error': str(e)}
            }

def test_exposition_extraction():
    """Test de l'extraction d'exposition"""
    extractor = ExpositionExtractor()
    
    # Test avec diff√©rentes descriptions
    test_cases = [
        {
            'description': 'Appartement tr√®s lumineux avec exposition Sud, vue d√©gag√©e sur le parc',
            'caracteristiques': 'Balcon, terrasse'
        },
        {
            'description': 'Duplex avec orientation Ouest, bien √©clair√©',
            'caracteristiques': 'Ascenseur'
        },
        {
            'description': 'Appartement au 4e √©tage, exposition Nord',
            'caracteristiques': 'Vis-√†-vis'
        },
        {
            'description': 'Magnifique appartement haussmannien',
            'caracteristiques': 'Parking'
        }
    ]
    
    print("üß≠ TEST D'EXTRACTION D'EXPOSITION")
    print("=" * 50)
    
    for i, case in enumerate(test_cases, 1):
        print(f"\n{i}. Test case:")
        print(f"   Description: {case['description']}")
        print(f"   Caract√©ristiques: {case['caracteristiques']}")
        
        result = extractor.extract_exposition_textuelle(
            case['description'], 
            case['caracteristiques']
        )
        
        print(f"   R√©sultat:")
        print(f"      Exposition: {result['exposition']}")
        print(f"      Score: {result['score']}/10")
        print(f"      Tier: {result['tier']}")
        print(f"      Justification: {result['justification']}")
        print(f"      Luminosit√©: {result['luminosite']}")
        print(f"      Vue: {result['vue']}")

if __name__ == "__main__":
    test_exposition_extraction()
