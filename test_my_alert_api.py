#!/usr/bin/env python3
"""
Test du scraper API avec votre alerte
"""

import asyncio
import json
from scrape_jinka_api import JinkaAPIScraper


async def test_my_alert():
    """Test du scraper API avec votre alerte"""
    print("ğŸš€ TEST DU SCRAPER API AVEC VOTRE ALERTE")
    print("=" * 60)
    
    # URL de votre alerte (dashboard)
    alert_url = "https://www.jinka.fr/asrenter/alert/dashboard/26c2ec3064303aa68ffa43f7c6518733"
    
    scraper = JinkaAPIScraper()
    
    try:
        print("\n1ï¸âƒ£ Initialisation du client API...")
        await scraper.setup()
        print("âœ… Client API initialisÃ©")
        
        print("\n2ï¸âƒ£ Connexion Ã  Jinka...")
        if not await scraper.login():
            print("âŒ Ã‰chec de la connexion")
            return
        
        print("\n3ï¸âƒ£ Scraping de l'alerte (toutes les pages)...")
        apartments = await scraper.scrape_alert_page(alert_url, max_pages=10)  # Augmenter pour rÃ©cupÃ©rer toutes les pages
        
        print(f"\nğŸ“Š RÃ‰SULTATS:")
        print(f"   {len(apartments)} appartements rÃ©cupÃ©rÃ©s")
        
        if apartments:
            print(f"\nğŸ“‹ DÃ©tails des appartements:")
            for i, apt in enumerate(apartments[:5], 1):  # Afficher les 5 premiers
                print(f"\n   {i}. Appartement {apt.get('id')}")
                print(f"      Titre: {apt.get('titre', 'N/A')}")
                print(f"      Prix: {apt.get('prix', 'N/A')}")
                print(f"      Surface: {apt.get('surface', 'N/A')}")
                print(f"      PiÃ¨ces: {apt.get('pieces', 'N/A')}")
                print(f"      Localisation: {apt.get('localisation', 'N/A')}")
                print(f"      Photos: {len(apt.get('photos', []))} photos")
                print(f"      URL: {apt.get('url', 'N/A')[:80]}...")
            
            # Sauvegarder les rÃ©sultats
            output_file = 'data/test_api_my_alert.json'
            import os
            os.makedirs('data', exist_ok=True)
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(apartments, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"\nğŸ’¾ RÃ©sultats sauvegardÃ©s dans {output_file}")
            
            # Tester le scraping d'un appartement en dÃ©tail
            if apartments:
                print(f"\n4ï¸âƒ£ Test du scraping dÃ©taillÃ© d'un appartement...")
                first_apt_url = apartments[0].get('url')
                if first_apt_url:
                    print(f"   URL: {first_apt_url}")
                    detailed_apt = await scraper.scrape_apartment(first_apt_url)
                    if detailed_apt:
                        print(f"   âœ… DÃ©tails rÃ©cupÃ©rÃ©s:")
                        print(f"      Description: {detailed_apt.get('description', 'N/A')[:100]}...")
                        print(f"      CaractÃ©ristiques: {detailed_apt.get('caracteristiques', 'N/A')[:100]}...")
                        print(f"      Ã‰tage: {detailed_apt.get('etage', 'N/A')}")
                        print(f"      Agence: {detailed_apt.get('agence', 'N/A')}")
        else:
            print("âš ï¸  Aucun appartement trouvÃ©")
        
        print("\nâœ… Test terminÃ© avec succÃ¨s!")
        
    except Exception as e:
        print(f"\nâŒ Erreur: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        print("\nğŸ§¹ Nettoyage...")
        await scraper.cleanup()


if __name__ == "__main__":
    asyncio.run(test_my_alert())

