#!/usr/bin/env python3
"""
Module d'analyse des photos pour l'exposition
Phase 2: Analyse des photos avec OpenAI Vision
"""

import base64
import json
import os
import requests
from typing import Dict, List, Optional
from io import BytesIO
from PIL import Image
import numpy as np
from dotenv import load_dotenv
from cache_api import get_cache

load_dotenv()

class PhotoAnalyzer:
    """Analyseur de photos pour l'exposition"""
    
    def __init__(self):
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.openai_base_url = "https://api.openai.com/v1"
        self.cache = get_cache()
        
    def analyze_photos_exposition(self, photos_urls: List[str]) -> Dict:
        """Analyse les photos pour d√©terminer l'exposition"""
        if not photos_urls:
            return {
                'exposition': None,
                'score': 0,
                'tier': 'tier3',
                'justification': 'Aucune photo disponible',
                'photos_analyzed': 0,
                'details': {}
            }
        
        try:
            # Analyser les premi√®res photos (max 3 pour √©conomiser les tokens)
            photos_to_analyze = photos_urls[:3]
            analysis_results = []
            
            for i, photo_url in enumerate(photos_to_analyze):
                print(f"   üì∏ Analyse photo {i+1}/{len(photos_to_analyze)}: {photo_url[:50]}...")
                result = self._analyze_single_photo(photo_url)
                if result:
                    analysis_results.append(result)
            
            # Agr√©ger les r√©sultats
            return self._aggregate_photo_results(analysis_results)
            
        except Exception as e:
            return {
                'exposition': None,
                'score': 0,
                'tier': 'tier3',
                'justification': f'Erreur analyse photos: {e}',
                'photos_analyzed': 0,
                'details': {}
            }
    
    def _analyze_single_photo(self, photo_url: str) -> Optional[Dict]:
        """Analyse une photo individuelle avec cache"""
        # V√©rifier le cache d'abord
        cached_result = self.cache.get('exposition_photo', photo_url)
        if cached_result:
            # Si le cache n'a pas brightness_value, le calculer maintenant
            if cached_result.get('brightness_value') is None:
                try:
                    response = requests.get(photo_url, timeout=5)
                    if response.status_code == 200:
                        brightness = self._calculate_photo_brightness(response.content)
                        cached_result['brightness_value'] = brightness
                except:
                    pass
            return cached_result
        
        try:
            # T√©l√©charger l'image
            response = requests.get(photo_url, timeout=5)
            if response.status_code != 200:
                print(f"   ‚ùå Erreur t√©l√©chargement: {response.status_code}")
                return None
            
            # Sauvegarder le contenu pour calcul brightness
            image_content = response.content
            
            # Encoder en base64
            image_base64 = base64.b64encode(image_content).decode('utf-8')
            
            # Appel √† OpenAI Vision
            headers = {
                'Authorization': f'Bearer {self.openai_api_key}',
                'Content-Type': 'application/json'
            }
            
            payload = {
                'model': 'gpt-4o-mini',  # Optimis√© pour r√©duire les co√ªts
                'messages': [
                    {
                        'role': 'user',
                        'content': [
                            {
                                'type': 'text',
                                'text': """Analyse cette photo d'appartement pour d√©terminer la luminosit√© relative.

## T√ÇCHE PRINCIPALE : √âvaluer la luminosit√© globale de la photo

### INDICES √Ä D√âTECTER :

- Luminosit√© relative (tr√®s_lumineux, lumineux, moyen, faible)
- Balcon/Terrasse visible (optionnel)

R√©ponds UNIQUEMENT au format JSON (pas de texte avant/apr√®s):
{
    "luminosite_relative": "tres_lumineux|lumineux|moyen|faible",
    "score_luminosite": 0-10,
    "confidence": 0.0-1.0,
    "details": "description d√©taill√©e de ce que tu vois"
}"""
                            },
                            {
                                'type': 'image_url',
                                'image_url': {
                                    'url': f'data:image/jpeg;base64,{image_base64}'
                                }
                            }
                        ]
                    }
                ],
                'max_tokens': 800  # Augment√© pour les indices pr√©cis d√©taill√©s
            }
            
            response = requests.post(
                f"{self.openai_base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=15
            )
            
            if response.status_code != 200:
                print(f"   ‚ùå Erreur API OpenAI: {response.status_code}")
                return None
            
            result = response.json()
            content = result['choices'][0]['message']['content']
            
            # Parser le JSON
            try:
                # Nettoyer le contenu (enlever les blocs markdown)
                if '```json' in content:
                    content = content.split('```json')[1].split('```')[0].strip()
                elif '```' in content:
                    content = content.split('```')[1].split('```')[0].strip()
                
                analysis = json.loads(content)
                
                # Calculer la luminosit√© moyenne de la photo
                brightness = self._calculate_photo_brightness(image_content)
                analysis['brightness_value'] = brightness
                
                print(f"   ‚úÖ Photo analys√©e: luminosit√© {analysis.get('luminosite_relative', 'N/A')} (brightness: {brightness:.2f})")
                
                # Mettre en cache avant de retourner
                self.cache.set('exposition_photo', photo_url, analysis)
                
                return analysis
            except json.JSONDecodeError:
                print(f"   ‚ùå Erreur parsing JSON: {content[:100]}...")
                return None
                
        except requests.exceptions.Timeout:
            print(f"   ‚è±Ô∏è Timeout lors de l'analyse de la photo (limite 15s)")
            return None
        except requests.exceptions.RequestException as e:
            print(f"   ‚ùå Erreur r√©seau: {e}")
            return None
        except Exception as e:
            print(f"   ‚ùå Erreur analyse photo: {e}")
            return None
    
    def _calculate_photo_brightness(self, image_data: bytes) -> float:
        """Calcule la luminosit√© moyenne d'une photo (0.0 = sombre, 1.0 = tr√®s lumineux)"""
        try:
            # V√©rifier que ce sont bien des bytes
            if not isinstance(image_data, bytes):
                return 0.5
            
            # Ouvrir l'image depuis les bytes
            image_bytes_io = BytesIO(image_data)
            image = Image.open(image_bytes_io)
            
            # Convertir en RGB si n√©cessaire
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # Redimensionner si trop grande (pour performance)
            max_size = 1000
            if image.size[0] > max_size or image.size[1] > max_size:
                image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
            
            # Convertir en numpy array
            img_array = np.array(image)
            
            # V√©rifier les dimensions
            if len(img_array.shape) != 3 or img_array.shape[2] != 3:
                return 0.5
            
            # Calculer la luminance moyenne (formule standard: 0.299*R + 0.587*G + 0.114*B)
            # Normaliser entre 0 et 1
            luminance = (0.299 * img_array[:, :, 0] + 
                        0.587 * img_array[:, :, 1] + 
                        0.114 * img_array[:, :, 2]) / 255.0
            
            # Moyenne de la luminance
            brightness = float(np.mean(luminance))
            
            return brightness
        except Exception as e:
            print(f"   ‚ö†Ô∏è Erreur calcul brightness: {e}")
            import traceback
            traceback.print_exc()
            return 0.5  # Valeur par d√©faut si erreur
    
    def _aggregate_photo_results(self, results: List[Dict]) -> Dict:
        """Agr√®ge les r√©sultats de plusieurs photos avec luminosit√© moyenne
        
        NOUVELLE LOGIQUE:
        - Calcule la luminosit√© moyenne des photos (brightness)
        - Utilise la luminosit√© IA si disponible, sinon utilise brightness_value
        - Score bas√© sur luminosit√© moyenne
        """
        if not results:
            return {
                'exposition': None,
                'score': 0,
                'tier': 'tier3',
                'justification': 'Aucune photo analys√©e avec succ√®s',
                'photos_analyzed': 0,
                'details': {}
            }
        
        # Calculer la luminosit√© moyenne des photos
        brightness_values = [r.get('brightness_value') for r in results if r.get('brightness_value') is not None]
        avg_brightness = sum(brightness_values) / len(brightness_values) if brightness_values else 0.5
        
        # Convertir brightness (0.0-1.0) en score (0-10)
        # √âchelle: <0.3 = sombre (3), 0.3-0.5 = moyen (5), 0.5-0.7 = lumineux (7), >0.7 = tr√®s lumineux (10)
        if avg_brightness < 0.3:
            brightness_score = 3
            brightness_level = 'faible'
        elif avg_brightness < 0.5:
            brightness_score = 5
            brightness_level = 'moyen'
        elif avg_brightness < 0.7:
            brightness_score = 7
            brightness_level = 'bon'
        else:
            brightness_score = 10
            brightness_level = 'excellent'
        
        # Utiliser aussi les scores IA de luminosit√© si disponibles (pour combiner)
        luminosite_scores_list = []
        for r in results:
            if 'score_luminosite' in r and r['score_luminosite'] is not None:
                luminosite_scores_list.append(r['score_luminosite'])
            elif 'luminosite_relative' in r:
                luminosite_map = {'tres_lumineux': 10, 'lumineux': 7, 'moyen': 5, 'faible': 3}
                luminosite_scores_list.append(luminosite_map.get(r['luminosite_relative'], 5))
        
        # Combiner brightness_score et scores IA (moyenne pond√©r√©e: 70% brightness, 30% IA)
        if luminosite_scores_list:
            avg_ia_luminosite = sum(luminosite_scores_list) / len(luminosite_scores_list)
            combined_luminosite_score = brightness_score * 0.7 + avg_ia_luminosite * 0.3
        else:
            combined_luminosite_score = brightness_score
        
        # Score total bas√© uniquement sur la luminosit√© moyenne
        total_score = min(10, combined_luminosite_score)
        
        # D√©terminer le tier
        if total_score >= 9:
            tier = 'tier1'
        elif total_score >= 7:
            tier = 'tier2'
        else:
            tier = 'tier3'
        
        # Construire la justification
        justification_parts = []
        justification_parts.append(f"Luminosit√© moyenne: {avg_brightness:.2f} ({brightness_level})")
        if brightness_values:
            justification_parts.append(f"{len(brightness_values)} photos analys√©es")
        
        justification = f"Analyse de {len(results)} photos: {', '.join(justification_parts)}"
        
        return {
            'exposition': None,  # Plus de d√©tection d'exposition depuis photos
            'score': int(total_score),
            'tier': tier,
            'justification': justification,
            'photos_analyzed': len(results),
            'luminosite': brightness_level,
            'vue': 'inconnue',  # Plus de d√©tection de vue
            'details': {
                'brightness_value': avg_brightness,
                'brightness_score': brightness_score,
                'luminosite_score': combined_luminosite_score,
                'confidence': sum(r.get('confidence', 0.5) for r in results) / len(results) if results else 0.5
            }
        }
    
    def _get_luminosite_level_from_score(self, score: float) -> str:
        """Convertit un score de luminosit√© en niveau"""
        if score >= 9:
            return 'excellent'
        elif score >= 7:
            return 'bon'
        elif score >= 5:
            return 'moyen'
        else:
            return 'faible'
    
    def _get_vue_level_from_score(self, score: float) -> str:
        """Convertit un score de vue en niveau"""
        if score >= 9:
            return 'excellent'
        elif score >= 7:
            return 'bon'
        elif score >= 5:
            return 'moyen'
        else:
            return 'faible'
    
    def analyze_photos_baignoire(self, photos_urls: List[str]) -> Dict:
        """Analyse les photos pour d√©tecter la pr√©sence de baignoire"""
        if not photos_urls:
            return {
                'has_baignoire': None,
                'has_douche': None,
                'confidence': 0.0,
                'justification': 'Aucune photo disponible',
                'photos_analyzed': 0,
                'detected_photos': []
            }
        
        try:
            # Analyser les top 10 photos (comme pour la cuisine)
            photos_to_analyze = photos_urls[:10]
            analysis_results = []
            
            for i, photo_url in enumerate(photos_to_analyze):
                print(f"   üì∏ Analyse photo baignoire {i+1}/{len(photos_to_analyze)}: {photo_url[:50]}...")
                result = self._analyze_single_photo_baignoire(photo_url)
                if result:
                    # Ajouter le num√©ro de la photo (1-indexed)
                    result['photo_number'] = i + 1
                    analysis_results.append(result)
            
            # Agr√©ger les r√©sultats
            return self._aggregate_baignoire_results(analysis_results)
            
        except Exception as e:
            return {
                'has_baignoire': None,
                'has_douche': None,
                'confidence': 0.0,
                'justification': f'Erreur analyse photos: {e}',
                'photos_analyzed': 0,
                'detected_photos': []
            }
    
    def _analyze_single_photo_baignoire(self, photo_url: str) -> Optional[Dict]:
        """Analyse une photo pour d√©tecter baignoire/douche avec cache"""
        # V√©rifier le cache d'abord
        cached_result = self.cache.get('baignoire_photo', photo_url)
        if cached_result:
            return cached_result
        
        try:
            response = requests.get(photo_url, timeout=5)
            if response.status_code != 200:
                return None
            
            image_base64 = base64.b64encode(response.content).decode('utf-8')
            
            headers = {
                'Authorization': f'Bearer {self.openai_api_key}',
                'Content-Type': 'application/json'
            }
            
            payload = {
                'model': 'gpt-4o-mini',
                'messages': [
                    {
                        'role': 'user',
                        'content': [
                            {
                                'type': 'text',
                                'text': """Analyse cette photo et d√©termine si une BAIGNOIRE ou une DOUCHE est visible.

Crit√®res:
- Baignoire: baignoire visible (rectangulaire, ovale, ronde)
- Douche: cabine de douche, douche italienne, douche √† l'italienne, pommeau de douche visible
- Ambigu: salle de bain visible mais pas de baignoire ni douche clairement identifiable

R√©ponds UNIQUEMENT au format JSON (pas de texte avant/apr√®s):
{
    "baignoire_visible": true|false,
    "douche_visible": true|false,
    "type_douche": "cabine|italienne|pommeau|null",
    "confidence": 0.0-1.0,
    "details": "description de ce que tu vois"
}"""
                            },
                            {
                                'type': 'image_url',
                                'image_url': {
                                    'url': f'data:image/jpeg;base64,{image_base64}'
                                }
                            }
                        ]
                    }
                ],
                'max_tokens': 300
            }
            
            response = requests.post(
                f"{self.openai_base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=15
            )
            
            if response.status_code != 200:
                return None
            
            result = response.json()
            content = result['choices'][0]['message']['content']
            
            # Parser le JSON
            try:
                if '```json' in content:
                    content = content.split('```json')[1].split('```')[0].strip()
                elif '```' in content:
                    content = content.split('```')[1].split('```')[0].strip()
                
                analysis = json.loads(content)
                
                # Mettre en cache avant de retourner
                self.cache.set('baignoire_photo', photo_url, analysis)
                
                return analysis
            except json.JSONDecodeError:
                return None
                
        except Exception as e:
            return None
    
    def _aggregate_baignoire_results(self, results: List[Dict]) -> Dict:
        """Agr√®ge les r√©sultats de plusieurs photos pour baignoire"""
        if not results:
            return {
                'has_baignoire': None,
                'has_douche': None,
                'confidence': 0.0,
                'justification': 'Aucune photo analys√©e avec succ√®s',
                'photos_analyzed': 0,
                'detected_photos': []
            }
        
        # Compter les d√©tections avec num√©ros d'images
        baignoires_photos = []
        douches_photos = []
        
        for r in results:
            photo_number = r.get('photo_number', 0)
            baignoire_visible = r.get('baignoire_visible', False)
            douche_visible = r.get('douche_visible', False)
            
            if baignoire_visible:
                baignoires_photos.append(photo_number)
            elif douche_visible:
                douches_photos.append(photo_number)
        
        has_baignoire = len(baignoires_photos) > 0
        has_douche = len(douches_photos) > 0 and not has_baignoire  # Si baignoire trouv√©e, on ignore douche
        
        # Confiance moyenne
        confidences = [r.get('confidence', 0.5) for r in results]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0.5
        
        # D√©terminer les photos d√©tect√©es
        if has_baignoire:
            detected_photos = sorted(baignoires_photos)
            justification = f"Baignoire d√©tect√©e sur {len(baignoires_photos)}/{len(results)} photos analys√©es"
        elif has_douche:
            detected_photos = sorted(douches_photos)
            justification = f"Douche d√©tect√©e sur {len(douches_photos)}/{len(results)} photos analys√©es"
        else:
            detected_photos = []
            justification = f"Aucune baignoire ni douche clairement visible sur {len(results)} photos"
        
        return {
            'has_baignoire': has_baignoire,
            'has_douche': has_douche,
            'confidence': avg_confidence,
            'justification': justification,
            'photos_analyzed': len(results),
            'detected_photos': detected_photos
        }
    
    def analyze_photos_cuisine(self, photos_urls: List[str]) -> Dict:
        """Analyse les photos pour d√©tecter si la cuisine est ouverte"""
        if not photos_urls:
            return {
                'ouverte': None,
                'confidence': 0.0,
                'justification': 'Aucune photo disponible',
                'photos_analyzed': 0,
                'detected_photos': []
            }
        
        try:
            # Analyser les 5 premi√®res photos
            photos_to_analyze = photos_urls[:5]
            analysis_results = []
            
            for i, photo_url in enumerate(photos_to_analyze):
                print(f"   üì∏ Analyse photo cuisine {i+1}/{len(photos_to_analyze)}: {photo_url[:50]}...")
                result = self._analyze_single_photo_cuisine(photo_url)
                if result:
                    # Ajouter le num√©ro de la photo (1-indexed)
                    result['photo_number'] = i + 1
                    analysis_results.append(result)
            
            # Agr√©ger les r√©sultats
            return self._aggregate_cuisine_results(analysis_results)
            
        except Exception as e:
            return {
                'ouverte': None,
                'confidence': 0.0,
                'justification': f'Erreur analyse photos: {e}',
                'photos_analyzed': 0,
                'detected_photos': []
            }
    
    def _analyze_single_photo_cuisine(self, photo_url: str) -> Optional[Dict]:
        """Analyse une photo pour d√©tecter cuisine ouverte/ferm√©e avec cache"""
        # V√©rifier le cache d'abord
        cached_result = self.cache.get('cuisine_photo', photo_url)
        if cached_result:
            return cached_result
        
        try:
            response = requests.get(photo_url, timeout=5)
            if response.status_code != 200:
                return None
            
            image_base64 = base64.b64encode(response.content).decode('utf-8')
            
            headers = {
                'Authorization': f'Bearer {self.openai_api_key}',
                'Content-Type': 'application/json'
            }
            
            payload = {
                'model': 'gpt-4o-mini',
                'messages': [
                    {
                        'role': 'user',
                        'content': [
                            {
                                'type': 'text',
                                'text': """Analyse cette photo et d√©termine si la CUISINE EST OUVERTE sur le salon/s√©jour.

Crit√®res:
- Cuisine ouverte: cuisine visible depuis le salon/s√©jour, pas de s√©paration murale, cuisine int√©gr√©e au s√©jour
- Cuisine ferm√©e: cuisine s√©par√©e par un mur, porte visible, espace clos
- Ambigu: cuisine non visible ou impossible √† d√©terminer

R√©ponds UNIQUEMENT au format JSON (pas de texte avant/apr√®s):
{
    "cuisine_ouverte": true|false|null,
    "cuisine_visible": true|false,
    "separation_murale": true|false,
    "confidence": 0.0-1.0,
    "details": "description de ce que tu vois"
}"""
                            },
                            {
                                'type': 'image_url',
                                'image_url': {
                                    'url': f'data:image/jpeg;base64,{image_base64}'
                                }
                            }
                        ]
                    }
                ],
                'max_tokens': 300
            }
            
            response = requests.post(
                f"{self.openai_base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=15
            )
            
            if response.status_code != 200:
                return None
            
            result = response.json()
            content = result['choices'][0]['message']['content']
            
            # Parser le JSON
            try:
                if '```json' in content:
                    content = content.split('```json')[1].split('```')[0].strip()
                elif '```' in content:
                    content = content.split('```')[1].split('```')[0].strip()
                
                analysis = json.loads(content)
                
                # Mettre en cache avant de retourner
                self.cache.set('cuisine_photo', photo_url, analysis)
                
                return analysis
            except json.JSONDecodeError:
                return None
                
        except Exception as e:
            return None
    
    def _aggregate_cuisine_results(self, results: List[Dict]) -> Dict:
        """Agr√®ge les r√©sultats de plusieurs photos pour cuisine"""
        if not results:
            return {
                'ouverte': None,
                'confidence': 0.0,
                'justification': 'Aucune photo analys√©e avec succ√®s',
                'photos_analyzed': 0,
                'detected_photos': []
            }
        
        # Compter les d√©tections avec num√©ros d'images
        cuisines_ouvertes = []
        cuisines_fermees = []
        
        for r in results:
            cuisine_ouverte = r.get('cuisine_ouverte')
            photo_number = r.get('photo_number', 0)
            
            if cuisine_ouverte is True:
                cuisines_ouvertes.append(photo_number)
            elif cuisine_ouverte is False:
                cuisines_fermees.append(photo_number)
        
        if not cuisines_ouvertes and not cuisines_fermees:
            return {
                'ouverte': None,
                'confidence': 0.0,
                'justification': 'Cuisine non visible sur les photos analys√©es',
                'photos_analyzed': len(results),
                'detected_photos': []
            }
        
        # D√©terminer si ouverte (majorit√©)
        count_ouverte = len(cuisines_ouvertes)
        count_fermee = len(cuisines_fermees)
        
        if count_ouverte > count_fermee:
            ouverte = True
            detected_photos = sorted(cuisines_ouvertes)
        elif count_fermee > count_ouverte:
            ouverte = False
            detected_photos = sorted(cuisines_fermees)
        else:
            ouverte = None  # Ambigu
            detected_photos = sorted(cuisines_ouvertes + cuisines_fermees)
        
        # Confiance moyenne
        confidences = [r.get('confidence', 0.5) for r in results]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0.5
        
        # Justification
        if ouverte is True:
            justification = f"Cuisine ouverte d√©tect√©e sur {count_ouverte}/{len(results)} photos"
        elif ouverte is False:
            justification = f"Cuisine ferm√©e d√©tect√©e sur {count_fermee}/{len(results)} photos"
        else:
            justification = f"R√©sultat ambigu: {count_ouverte} ouvertes vs {count_fermee} ferm√©es"
        
        return {
            'ouverte': ouverte,
            'confidence': avg_confidence,
            'justification': justification,
            'photos_analyzed': len(results),
            'detected_photos': detected_photos
        }
    
    def validate_text_with_photos(self, text_result: Dict, photo_result: Dict, criterion: str) -> Dict:
        """Valide un r√©sultat textuel avec un r√©sultat photo pour ajuster la confiance
        
        Args:
            text_result: R√©sultat de l'analyse textuelle
            photo_result: R√©sultat de l'analyse photo
            criterion: Type de crit√®re ('exposition', 'baignoire', 'cuisine', 'style')
        
        Returns:
            Dict avec confiance ajust√©e et validation crois√©e
        """
        if not photo_result or photo_result.get('photos_analyzed', 0) == 0:
            # Pas de photos ‚Üí utiliser texte uniquement
            return {
                'final_result': text_result,
                'confidence_adjusted': text_result.get('confidence', text_result.get('confiance_globale', 0.5)),
                'validation_status': 'text_only',
                'cross_validation': None
            }
        
        text_confidence = text_result.get('confidence', text_result.get('confiance_globale', 0.5))
        photo_confidence = photo_result.get('confidence', 0.5)
        
        # V√©rifier la coh√©rence selon le crit√®re
        is_consistent = self._check_consistency(text_result, photo_result, criterion)
        
        if is_consistent:
            # Coh√©rent ‚Üí augmenter la confiance
            # Moyenne pond√©r√©e: 60% texte + 40% photo (texte plus fiable g√©n√©ralement)
            adjusted_confidence = min(1.0, (text_confidence * 0.6 + photo_confidence * 0.4) + 0.1)
            validation_status = 'validated'
        else:
            # Incoh√©rent ‚Üí r√©duire la confiance
            adjusted_confidence = max(0.3, (text_confidence + photo_confidence) / 2 - 0.2)
            validation_status = 'conflict'
        
        return {
            'final_result': text_result,
            'confidence_adjusted': adjusted_confidence,
            'validation_status': validation_status,
            'cross_validation': {
                'text_confidence': text_confidence,
                'photo_confidence': photo_confidence,
                'is_consistent': is_consistent,
                'photo_result': photo_result
            }
        }
    
    def _check_consistency(self, text_result: Dict, photo_result: Dict, criterion: str) -> bool:
        """V√©rifie la coh√©rence entre texte et photo"""
        if criterion == 'exposition':
            # Plus de d√©tection d'exposition depuis photos, on compare la luminosit√©
            text_luminosite = text_result.get('luminosite', 'inconnue')
            photo_luminosite = photo_result.get('luminosite', 'inconnue')
            
            # Mapping des niveaux de luminosit√© pour comparaison
            luminosite_map = {
                'excellent': 10,
                'bon': 7,
                'moyen': 5,
                'faible': 3,
                'inconnue': 5  # Par d√©faut
            }
            
            text_score = luminosite_map.get(text_luminosite, 5)
            photo_score = luminosite_map.get(photo_luminosite, 5)
            
            # Coh√©rent si diff√©rence de score <= 2 points
            return abs(text_score - photo_score) <= 2
        
        elif criterion == 'baignoire':
            text_has = text_result.get('has_baignoire')
            photo_has = photo_result.get('has_baignoire')
            return text_has == photo_has or text_has is None or photo_has is None
        
        elif criterion == 'cuisine':
            text_ouverte = text_result.get('ouverte')
            photo_ouverte = photo_result.get('ouverte')
            return text_ouverte == photo_ouverte or text_ouverte is None or photo_ouverte is None
        
        elif criterion == 'style':
            text_style = text_result.get('type', text_result.get('style', ''))
            photo_style = photo_result.get('type', photo_result.get('style', ''))
            # Normaliser pour comparaison
            text_style_norm = text_style.lower() if text_style else ''
            photo_style_norm = photo_style.lower() if photo_style else ''
            return text_style_norm == photo_style_norm or not text_style_norm or not photo_style_norm
        
        return True  # Par d√©faut, consid√©rer coh√©rent

def test_photo_analysis():
    """Test de l'analyse de photos"""
    analyzer = PhotoAnalyzer()
    
    # Test avec des URLs d'exemple
    test_photos = [
        "https://example.com/photo1.jpg",
        "https://example.com/photo2.jpg"
    ]
    
    print("üì∏ TEST D'ANALYSE DE PHOTOS")
    print("=" * 50)
    
    result = analyzer.analyze_photos_exposition(test_photos)
    
    print(f"Exposition: {result['exposition']}")
    print(f"Score: {result['score']}/10")
    print(f"Tier: {result['tier']}")
    print(f"Justification: {result['justification']}")
    print(f"Photos analys√©es: {result['photos_analyzed']}")

if __name__ == "__main__":
    test_photo_analysis()
